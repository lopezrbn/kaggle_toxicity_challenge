[
  {
    "loss": 0.6274,
    "grad_norm": 1.482984185218811,
    "learning_rate": 9.991645781119465e-06,
    "epoch": 0.002506265664160401,
    "step": 10
  },
  {
    "loss": 0.551,
    "grad_norm": 1.7741426229476929,
    "learning_rate": 9.983291562238932e-06,
    "epoch": 0.005012531328320802,
    "step": 20
  },
  {
    "loss": 0.4384,
    "grad_norm": 1.6437052488327026,
    "learning_rate": 9.974937343358396e-06,
    "epoch": 0.007518796992481203,
    "step": 30
  },
  {
    "loss": 0.324,
    "grad_norm": 1.527538537979126,
    "learning_rate": 9.966583124477862e-06,
    "epoch": 0.010025062656641603,
    "step": 40
  },
  {
    "loss": 0.2494,
    "grad_norm": 1.2678484916687012,
    "learning_rate": 9.958228905597328e-06,
    "epoch": 0.012531328320802004,
    "step": 50
  },
  {
    "loss": 0.2033,
    "grad_norm": 0.8909110426902771,
    "learning_rate": 9.949874686716793e-06,
    "epoch": 0.015037593984962405,
    "step": 60
  },
  {
    "loss": 0.1775,
    "grad_norm": 1.107073426246643,
    "learning_rate": 9.941520467836257e-06,
    "epoch": 0.017543859649122806,
    "step": 70
  },
  {
    "loss": 0.1583,
    "grad_norm": 0.5991473197937012,
    "learning_rate": 9.933166248955723e-06,
    "epoch": 0.020050125313283207,
    "step": 80
  },
  {
    "loss": 0.1435,
    "grad_norm": 0.9504511952400208,
    "learning_rate": 9.924812030075189e-06,
    "epoch": 0.022556390977443608,
    "step": 90
  },
  {
    "loss": 0.1157,
    "grad_norm": 0.6808973550796509,
    "learning_rate": 9.916457811194654e-06,
    "epoch": 0.02506265664160401,
    "step": 100
  },
  {
    "loss": 0.1419,
    "grad_norm": 0.615769624710083,
    "learning_rate": 9.908103592314118e-06,
    "epoch": 0.02756892230576441,
    "step": 110
  },
  {
    "loss": 0.1362,
    "grad_norm": 0.594153881072998,
    "learning_rate": 9.899749373433584e-06,
    "epoch": 0.03007518796992481,
    "step": 120
  },
  {
    "loss": 0.1178,
    "grad_norm": 1.1027209758758545,
    "learning_rate": 9.89139515455305e-06,
    "epoch": 0.03258145363408521,
    "step": 130
  },
  {
    "loss": 0.0858,
    "grad_norm": 0.5266253352165222,
    "learning_rate": 9.883040935672515e-06,
    "epoch": 0.03508771929824561,
    "step": 140
  },
  {
    "loss": 0.0991,
    "grad_norm": 0.8235928416252136,
    "learning_rate": 9.87468671679198e-06,
    "epoch": 0.03759398496240601,
    "step": 150
  },
  {
    "loss": 0.095,
    "grad_norm": 0.5646476745605469,
    "learning_rate": 9.866332497911447e-06,
    "epoch": 0.040100250626566414,
    "step": 160
  },
  {
    "loss": 0.0916,
    "grad_norm": 0.8888848423957825,
    "learning_rate": 9.85797827903091e-06,
    "epoch": 0.042606516290726815,
    "step": 170
  },
  {
    "loss": 0.0897,
    "grad_norm": 0.797810435295105,
    "learning_rate": 9.849624060150376e-06,
    "epoch": 0.045112781954887216,
    "step": 180
  },
  {
    "loss": 0.0907,
    "grad_norm": 1.5470746755599976,
    "learning_rate": 9.841269841269842e-06,
    "epoch": 0.047619047619047616,
    "step": 190
  },
  {
    "loss": 0.0726,
    "grad_norm": 0.3527282476425171,
    "learning_rate": 9.832915622389308e-06,
    "epoch": 0.05012531328320802,
    "step": 200
  },
  {
    "loss": 0.0792,
    "grad_norm": 2.2126286029815674,
    "learning_rate": 9.824561403508772e-06,
    "epoch": 0.05263157894736842,
    "step": 210
  },
  {
    "loss": 0.0778,
    "grad_norm": 0.9221018552780151,
    "learning_rate": 9.816207184628238e-06,
    "epoch": 0.05513784461152882,
    "step": 220
  },
  {
    "loss": 0.0597,
    "grad_norm": 0.3297000527381897,
    "learning_rate": 9.807852965747703e-06,
    "epoch": 0.05764411027568922,
    "step": 230
  },
  {
    "loss": 0.0659,
    "grad_norm": 0.4736606180667877,
    "learning_rate": 9.799498746867169e-06,
    "epoch": 0.06015037593984962,
    "step": 240
  },
  {
    "loss": 0.0638,
    "grad_norm": 1.864740014076233,
    "learning_rate": 9.791144527986633e-06,
    "epoch": 0.06265664160401002,
    "step": 250
  },
  {
    "eval_loss": 0.06084582582116127,
    "eval_roc_auc_macro": 0.957684117866395,
    "eval_runtime": 39.9741,
    "eval_samples_per_second": 798.393,
    "eval_steps_per_second": 24.966,
    "epoch": 0.06265664160401002,
    "step": 250
  },
  {
    "train_loss": 0.06023477762937546,
    "train_roc_auc_macro": 0.9450578702622402,
    "train_runtime": 159.7296,
    "train_samples_per_second": 799.201,
    "train_steps_per_second": 24.98,
    "epoch": 0.06265664160401002,
    "step": 250
  },
  {
    "loss": 0.0731,
    "grad_norm": 0.4189132750034332,
    "learning_rate": 9.782790309106099e-06,
    "epoch": 0.06516290726817042,
    "step": 260
  },
  {
    "loss": 0.0631,
    "grad_norm": 1.6908855438232422,
    "learning_rate": 9.774436090225564e-06,
    "epoch": 0.06766917293233082,
    "step": 270
  },
  {
    "loss": 0.0636,
    "grad_norm": 1.6537243127822876,
    "learning_rate": 9.76608187134503e-06,
    "epoch": 0.07017543859649122,
    "step": 280
  },
  {
    "loss": 0.0668,
    "grad_norm": 0.4546230435371399,
    "learning_rate": 9.757727652464496e-06,
    "epoch": 0.07268170426065163,
    "step": 290
  },
  {
    "loss": 0.0592,
    "grad_norm": 0.44782716035842896,
    "learning_rate": 9.749373433583961e-06,
    "epoch": 0.07518796992481203,
    "step": 300
  },
  {
    "loss": 0.0908,
    "grad_norm": 1.24931001663208,
    "learning_rate": 9.741019214703425e-06,
    "epoch": 0.07769423558897243,
    "step": 310
  },
  {
    "loss": 0.0669,
    "grad_norm": 1.073407530784607,
    "learning_rate": 9.732664995822891e-06,
    "epoch": 0.08020050125313283,
    "step": 320
  },
  {
    "loss": 0.0577,
    "grad_norm": 0.7432106733322144,
    "learning_rate": 9.724310776942357e-06,
    "epoch": 0.08270676691729323,
    "step": 330
  },
  {
    "loss": 0.0666,
    "grad_norm": 1.9382226467132568,
    "learning_rate": 9.715956558061822e-06,
    "epoch": 0.08521303258145363,
    "step": 340
  },
  {
    "loss": 0.0592,
    "grad_norm": 0.5685853362083435,
    "learning_rate": 9.707602339181286e-06,
    "epoch": 0.08771929824561403,
    "step": 350
  },
  {
    "loss": 0.0586,
    "grad_norm": 1.116076946258545,
    "learning_rate": 9.699248120300752e-06,
    "epoch": 0.09022556390977443,
    "step": 360
  },
  {
    "loss": 0.0488,
    "grad_norm": 0.37043920159339905,
    "learning_rate": 9.690893901420218e-06,
    "epoch": 0.09273182957393483,
    "step": 370
  },
  {
    "loss": 0.0626,
    "grad_norm": 2.1535627841949463,
    "learning_rate": 9.682539682539683e-06,
    "epoch": 0.09523809523809523,
    "step": 380
  },
  {
    "loss": 0.0498,
    "grad_norm": 1.1108096837997437,
    "learning_rate": 9.674185463659147e-06,
    "epoch": 0.09774436090225563,
    "step": 390
  },
  {
    "loss": 0.0632,
    "grad_norm": 0.6369789838790894,
    "learning_rate": 9.665831244778615e-06,
    "epoch": 0.10025062656641603,
    "step": 400
  },
  {
    "loss": 0.0625,
    "grad_norm": 0.23951119184494019,
    "learning_rate": 9.657477025898079e-06,
    "epoch": 0.10275689223057644,
    "step": 410
  },
  {
    "loss": 0.0724,
    "grad_norm": 0.6681098937988281,
    "learning_rate": 9.649122807017545e-06,
    "epoch": 0.10526315789473684,
    "step": 420
  },
  {
    "loss": 0.0457,
    "grad_norm": 0.3320644497871399,
    "learning_rate": 9.64076858813701e-06,
    "epoch": 0.10776942355889724,
    "step": 430
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.544693112373352,
    "learning_rate": 9.632414369256476e-06,
    "epoch": 0.11027568922305764,
    "step": 440
  },
  {
    "loss": 0.0575,
    "grad_norm": 0.7466706037521362,
    "learning_rate": 9.62406015037594e-06,
    "epoch": 0.11278195488721804,
    "step": 450
  },
  {
    "loss": 0.0452,
    "grad_norm": 0.2369242161512375,
    "learning_rate": 9.615705931495406e-06,
    "epoch": 0.11528822055137844,
    "step": 460
  },
  {
    "loss": 0.0587,
    "grad_norm": 0.7177965641021729,
    "learning_rate": 9.607351712614871e-06,
    "epoch": 0.11779448621553884,
    "step": 470
  },
  {
    "loss": 0.0611,
    "grad_norm": 1.3941066265106201,
    "learning_rate": 9.598997493734337e-06,
    "epoch": 0.12030075187969924,
    "step": 480
  },
  {
    "loss": 0.0442,
    "grad_norm": 0.6315375566482544,
    "learning_rate": 9.590643274853801e-06,
    "epoch": 0.12280701754385964,
    "step": 490
  },
  {
    "loss": 0.0567,
    "grad_norm": 0.2997637391090393,
    "learning_rate": 9.582289055973267e-06,
    "epoch": 0.12531328320802004,
    "step": 500
  },
  {
    "eval_loss": 0.052218493074178696,
    "eval_roc_auc_macro": 0.9645795118895517,
    "eval_runtime": 40.0127,
    "eval_samples_per_second": 797.621,
    "eval_steps_per_second": 24.942,
    "epoch": 0.12531328320802004,
    "step": 500
  },
  {
    "train_loss": 0.05109359696507454,
    "train_roc_auc_macro": 0.9534036717532332,
    "train_runtime": 159.7916,
    "train_samples_per_second": 798.89,
    "train_steps_per_second": 24.97,
    "epoch": 0.12531328320802004,
    "step": 500
  },
  {
    "loss": 0.0515,
    "grad_norm": 0.4718031883239746,
    "learning_rate": 9.573934837092732e-06,
    "epoch": 0.12781954887218044,
    "step": 510
  },
  {
    "loss": 0.0544,
    "grad_norm": 0.37105175852775574,
    "learning_rate": 9.565580618212198e-06,
    "epoch": 0.13032581453634084,
    "step": 520
  },
  {
    "loss": 0.0406,
    "grad_norm": 1.0539906024932861,
    "learning_rate": 9.557226399331662e-06,
    "epoch": 0.13283208020050125,
    "step": 530
  },
  {
    "loss": 0.0373,
    "grad_norm": 0.4813307225704193,
    "learning_rate": 9.54887218045113e-06,
    "epoch": 0.13533834586466165,
    "step": 540
  },
  {
    "loss": 0.058,
    "grad_norm": 1.1606658697128296,
    "learning_rate": 9.540517961570593e-06,
    "epoch": 0.13784461152882205,
    "step": 550
  },
  {
    "loss": 0.0399,
    "grad_norm": 0.1507493108510971,
    "learning_rate": 9.532163742690059e-06,
    "epoch": 0.14035087719298245,
    "step": 560
  },
  {
    "loss": 0.0597,
    "grad_norm": 0.5373964905738831,
    "learning_rate": 9.523809523809525e-06,
    "epoch": 0.14285714285714285,
    "step": 570
  },
  {
    "loss": 0.0619,
    "grad_norm": 0.7021671533584595,
    "learning_rate": 9.51545530492899e-06,
    "epoch": 0.14536340852130325,
    "step": 580
  },
  {
    "loss": 0.0534,
    "grad_norm": 0.5095971822738647,
    "learning_rate": 9.507101086048454e-06,
    "epoch": 0.14786967418546365,
    "step": 590
  },
  {
    "loss": 0.0532,
    "grad_norm": 0.48222050070762634,
    "learning_rate": 9.49874686716792e-06,
    "epoch": 0.15037593984962405,
    "step": 600
  },
  {
    "loss": 0.0317,
    "grad_norm": 0.26901376247406006,
    "learning_rate": 9.490392648287386e-06,
    "epoch": 0.15288220551378445,
    "step": 610
  },
  {
    "loss": 0.0552,
    "grad_norm": 0.621252715587616,
    "learning_rate": 9.482038429406851e-06,
    "epoch": 0.15538847117794485,
    "step": 620
  },
  {
    "loss": 0.0567,
    "grad_norm": 0.2784407138824463,
    "learning_rate": 9.473684210526315e-06,
    "epoch": 0.15789473684210525,
    "step": 630
  },
  {
    "loss": 0.0428,
    "grad_norm": 0.29383131861686707,
    "learning_rate": 9.465329991645781e-06,
    "epoch": 0.16040100250626566,
    "step": 640
  },
  {
    "loss": 0.0478,
    "grad_norm": 0.74506676197052,
    "learning_rate": 9.456975772765247e-06,
    "epoch": 0.16290726817042606,
    "step": 650
  },
  {
    "loss": 0.0434,
    "grad_norm": 0.7411165833473206,
    "learning_rate": 9.448621553884713e-06,
    "epoch": 0.16541353383458646,
    "step": 660
  },
  {
    "loss": 0.0608,
    "grad_norm": 0.9469978213310242,
    "learning_rate": 9.440267335004177e-06,
    "epoch": 0.16791979949874686,
    "step": 670
  },
  {
    "loss": 0.0541,
    "grad_norm": 0.532622754573822,
    "learning_rate": 9.431913116123644e-06,
    "epoch": 0.17042606516290726,
    "step": 680
  },
  {
    "loss": 0.042,
    "grad_norm": 0.581325888633728,
    "learning_rate": 9.423558897243108e-06,
    "epoch": 0.17293233082706766,
    "step": 690
  },
  {
    "loss": 0.0507,
    "grad_norm": 0.345852792263031,
    "learning_rate": 9.415204678362574e-06,
    "epoch": 0.17543859649122806,
    "step": 700
  },
  {
    "loss": 0.0476,
    "grad_norm": 0.6714624762535095,
    "learning_rate": 9.40685045948204e-06,
    "epoch": 0.17794486215538846,
    "step": 710
  },
  {
    "loss": 0.0515,
    "grad_norm": 0.47546958923339844,
    "learning_rate": 9.398496240601505e-06,
    "epoch": 0.18045112781954886,
    "step": 720
  },
  {
    "loss": 0.0475,
    "grad_norm": 0.66962730884552,
    "learning_rate": 9.390142021720969e-06,
    "epoch": 0.18295739348370926,
    "step": 730
  },
  {
    "loss": 0.0447,
    "grad_norm": 0.19920296967029572,
    "learning_rate": 9.381787802840435e-06,
    "epoch": 0.18546365914786966,
    "step": 740
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.5511735081672668,
    "learning_rate": 9.3734335839599e-06,
    "epoch": 0.18796992481203006,
    "step": 750
  },
  {
    "eval_loss": 0.04759262129664421,
    "eval_roc_auc_macro": 0.9748341693713347,
    "eval_runtime": 39.9832,
    "eval_samples_per_second": 798.211,
    "eval_steps_per_second": 24.961,
    "epoch": 0.18796992481203006,
    "step": 750
  },
  {
    "train_loss": 0.046628836542367935,
    "train_roc_auc_macro": 0.9679019887324825,
    "train_runtime": 160.0433,
    "train_samples_per_second": 797.634,
    "train_steps_per_second": 24.931,
    "epoch": 0.18796992481203006,
    "step": 750
  },
  {
    "loss": 0.0391,
    "grad_norm": 0.26366257667541504,
    "learning_rate": 9.365079365079366e-06,
    "epoch": 0.19047619047619047,
    "step": 760
  },
  {
    "loss": 0.0586,
    "grad_norm": 1.309801697731018,
    "learning_rate": 9.35672514619883e-06,
    "epoch": 0.19298245614035087,
    "step": 770
  },
  {
    "loss": 0.0524,
    "grad_norm": 0.23237670958042145,
    "learning_rate": 9.348370927318296e-06,
    "epoch": 0.19548872180451127,
    "step": 780
  },
  {
    "loss": 0.066,
    "grad_norm": 1.1063731908798218,
    "learning_rate": 9.340016708437761e-06,
    "epoch": 0.19799498746867167,
    "step": 790
  },
  {
    "loss": 0.0479,
    "grad_norm": 0.7916935682296753,
    "learning_rate": 9.331662489557227e-06,
    "epoch": 0.20050125313283207,
    "step": 800
  },
  {
    "loss": 0.0598,
    "grad_norm": 0.34512385725975037,
    "learning_rate": 9.323308270676693e-06,
    "epoch": 0.20300751879699247,
    "step": 810
  },
  {
    "loss": 0.0408,
    "grad_norm": 0.29841700196266174,
    "learning_rate": 9.314954051796158e-06,
    "epoch": 0.20551378446115287,
    "step": 820
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.21604099869728088,
    "learning_rate": 9.306599832915622e-06,
    "epoch": 0.20802005012531327,
    "step": 830
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.3094629645347595,
    "learning_rate": 9.298245614035088e-06,
    "epoch": 0.21052631578947367,
    "step": 840
  },
  {
    "loss": 0.0503,
    "grad_norm": 0.5944390296936035,
    "learning_rate": 9.289891395154554e-06,
    "epoch": 0.21303258145363407,
    "step": 850
  },
  {
    "loss": 0.0467,
    "grad_norm": 0.12593169510364532,
    "learning_rate": 9.28153717627402e-06,
    "epoch": 0.21553884711779447,
    "step": 860
  },
  {
    "loss": 0.0529,
    "grad_norm": 0.4589369297027588,
    "learning_rate": 9.273182957393484e-06,
    "epoch": 0.21804511278195488,
    "step": 870
  },
  {
    "loss": 0.0432,
    "grad_norm": 1.079545497894287,
    "learning_rate": 9.26482873851295e-06,
    "epoch": 0.22055137844611528,
    "step": 880
  },
  {
    "loss": 0.0467,
    "grad_norm": 0.4389764964580536,
    "learning_rate": 9.256474519632415e-06,
    "epoch": 0.22305764411027568,
    "step": 890
  },
  {
    "loss": 0.0537,
    "grad_norm": 0.4553028345108032,
    "learning_rate": 9.24812030075188e-06,
    "epoch": 0.22556390977443608,
    "step": 900
  },
  {
    "loss": 0.0415,
    "grad_norm": 0.6774314641952515,
    "learning_rate": 9.239766081871345e-06,
    "epoch": 0.22807017543859648,
    "step": 910
  },
  {
    "loss": 0.0477,
    "grad_norm": 1.0304675102233887,
    "learning_rate": 9.231411862990812e-06,
    "epoch": 0.23057644110275688,
    "step": 920
  },
  {
    "loss": 0.0537,
    "grad_norm": 0.384685754776001,
    "learning_rate": 9.223057644110276e-06,
    "epoch": 0.23308270676691728,
    "step": 930
  },
  {
    "loss": 0.0279,
    "grad_norm": 0.2942875027656555,
    "learning_rate": 9.214703425229742e-06,
    "epoch": 0.23558897243107768,
    "step": 940
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.21383419632911682,
    "learning_rate": 9.206349206349207e-06,
    "epoch": 0.23809523809523808,
    "step": 950
  },
  {
    "loss": 0.0471,
    "grad_norm": 0.36198586225509644,
    "learning_rate": 9.197994987468673e-06,
    "epoch": 0.24060150375939848,
    "step": 960
  },
  {
    "loss": 0.0461,
    "grad_norm": 0.3819322884082794,
    "learning_rate": 9.189640768588137e-06,
    "epoch": 0.24310776942355888,
    "step": 970
  },
  {
    "loss": 0.0461,
    "grad_norm": 0.23470360040664673,
    "learning_rate": 9.181286549707603e-06,
    "epoch": 0.24561403508771928,
    "step": 980
  },
  {
    "loss": 0.0523,
    "grad_norm": 0.6498666405677795,
    "learning_rate": 9.172932330827068e-06,
    "epoch": 0.24812030075187969,
    "step": 990
  },
  {
    "loss": 0.039,
    "grad_norm": 0.7461150288581848,
    "learning_rate": 9.164578111946534e-06,
    "epoch": 0.2506265664160401,
    "step": 1000
  },
  {
    "eval_loss": 0.05037428066134453,
    "eval_roc_auc_macro": 0.9751824783739634,
    "eval_runtime": 40.065,
    "eval_samples_per_second": 796.582,
    "eval_steps_per_second": 24.91,
    "epoch": 0.2506265664160401,
    "step": 1000
  },
  {
    "train_loss": 0.048718202859163284,
    "train_roc_auc_macro": 0.9667737925519898,
    "train_runtime": 159.858,
    "train_samples_per_second": 798.559,
    "train_steps_per_second": 24.96,
    "epoch": 0.2506265664160401,
    "step": 1000
  },
  {
    "loss": 0.0498,
    "grad_norm": 0.6235153675079346,
    "learning_rate": 9.156223893065998e-06,
    "epoch": 0.2531328320802005,
    "step": 1010
  },
  {
    "loss": 0.041,
    "grad_norm": 0.2771163582801819,
    "learning_rate": 9.147869674185464e-06,
    "epoch": 0.2556390977443609,
    "step": 1020
  },
  {
    "loss": 0.0452,
    "grad_norm": 0.8781773447990417,
    "learning_rate": 9.13951545530493e-06,
    "epoch": 0.2581453634085213,
    "step": 1030
  },
  {
    "loss": 0.0752,
    "grad_norm": 0.9280188083648682,
    "learning_rate": 9.131161236424395e-06,
    "epoch": 0.2606516290726817,
    "step": 1040
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.5748857855796814,
    "learning_rate": 9.12280701754386e-06,
    "epoch": 0.2631578947368421,
    "step": 1050
  },
  {
    "loss": 0.0557,
    "grad_norm": 0.49877169728279114,
    "learning_rate": 9.114452798663327e-06,
    "epoch": 0.2656641604010025,
    "step": 1060
  },
  {
    "loss": 0.0417,
    "grad_norm": 0.2534656822681427,
    "learning_rate": 9.10609857978279e-06,
    "epoch": 0.2681704260651629,
    "step": 1070
  },
  {
    "loss": 0.0426,
    "grad_norm": 1.2045273780822754,
    "learning_rate": 9.097744360902256e-06,
    "epoch": 0.2706766917293233,
    "step": 1080
  },
  {
    "loss": 0.034,
    "grad_norm": 0.2148391604423523,
    "learning_rate": 9.089390142021722e-06,
    "epoch": 0.2731829573934837,
    "step": 1090
  },
  {
    "loss": 0.0501,
    "grad_norm": 1.1396980285644531,
    "learning_rate": 9.081035923141188e-06,
    "epoch": 0.2756892230576441,
    "step": 1100
  },
  {
    "loss": 0.0499,
    "grad_norm": 0.8584966063499451,
    "learning_rate": 9.072681704260652e-06,
    "epoch": 0.2781954887218045,
    "step": 1110
  },
  {
    "loss": 0.0437,
    "grad_norm": 0.18214912712574005,
    "learning_rate": 9.064327485380117e-06,
    "epoch": 0.2807017543859649,
    "step": 1120
  },
  {
    "loss": 0.0499,
    "grad_norm": 0.3905806839466095,
    "learning_rate": 9.055973266499583e-06,
    "epoch": 0.2832080200501253,
    "step": 1130
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.5673012733459473,
    "learning_rate": 9.047619047619049e-06,
    "epoch": 0.2857142857142857,
    "step": 1140
  },
  {
    "loss": 0.0632,
    "grad_norm": 0.36501917243003845,
    "learning_rate": 9.039264828738513e-06,
    "epoch": 0.2882205513784461,
    "step": 1150
  },
  {
    "loss": 0.0586,
    "grad_norm": 0.38103413581848145,
    "learning_rate": 9.030910609857978e-06,
    "epoch": 0.2907268170426065,
    "step": 1160
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.34934696555137634,
    "learning_rate": 9.022556390977444e-06,
    "epoch": 0.2932330827067669,
    "step": 1170
  },
  {
    "loss": 0.0511,
    "grad_norm": 0.759579598903656,
    "learning_rate": 9.01420217209691e-06,
    "epoch": 0.2957393483709273,
    "step": 1180
  },
  {
    "loss": 0.0366,
    "grad_norm": 0.4097888171672821,
    "learning_rate": 9.005847953216374e-06,
    "epoch": 0.2982456140350877,
    "step": 1190
  },
  {
    "loss": 0.0413,
    "grad_norm": 0.8026910424232483,
    "learning_rate": 8.997493734335841e-06,
    "epoch": 0.3007518796992481,
    "step": 1200
  },
  {
    "loss": 0.0478,
    "grad_norm": 0.22639860212802887,
    "learning_rate": 8.989139515455305e-06,
    "epoch": 0.3032581453634085,
    "step": 1210
  },
  {
    "loss": 0.0452,
    "grad_norm": 0.31109747290611267,
    "learning_rate": 8.98078529657477e-06,
    "epoch": 0.3057644110275689,
    "step": 1220
  },
  {
    "loss": 0.0456,
    "grad_norm": 0.3215135931968689,
    "learning_rate": 8.972431077694236e-06,
    "epoch": 0.3082706766917293,
    "step": 1230
  },
  {
    "loss": 0.067,
    "grad_norm": 0.6403502225875854,
    "learning_rate": 8.964076858813702e-06,
    "epoch": 0.3107769423558897,
    "step": 1240
  },
  {
    "loss": 0.0586,
    "grad_norm": 0.38050296902656555,
    "learning_rate": 8.955722639933166e-06,
    "epoch": 0.3132832080200501,
    "step": 1250
  },
  {
    "eval_loss": 0.04737754911184311,
    "eval_roc_auc_macro": 0.9798511613139951,
    "eval_runtime": 40.0278,
    "eval_samples_per_second": 797.321,
    "eval_steps_per_second": 24.933,
    "epoch": 0.3132832080200501,
    "step": 1250
  },
  {
    "train_loss": 0.046075087040662766,
    "train_roc_auc_macro": 0.9784184882026837,
    "train_runtime": 159.8587,
    "train_samples_per_second": 798.555,
    "train_steps_per_second": 24.96,
    "epoch": 0.3132832080200501,
    "step": 1250
  },
  {
    "loss": 0.0572,
    "grad_norm": 0.6369947195053101,
    "learning_rate": 8.947368421052632e-06,
    "epoch": 0.3157894736842105,
    "step": 1260
  },
  {
    "loss": 0.0418,
    "grad_norm": 1.0731956958770752,
    "learning_rate": 8.939014202172098e-06,
    "epoch": 0.3182957393483709,
    "step": 1270
  },
  {
    "loss": 0.0395,
    "grad_norm": 0.17936208844184875,
    "learning_rate": 8.930659983291563e-06,
    "epoch": 0.3208020050125313,
    "step": 1280
  },
  {
    "loss": 0.0472,
    "grad_norm": 1.1354197263717651,
    "learning_rate": 8.922305764411027e-06,
    "epoch": 0.3233082706766917,
    "step": 1290
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.41540688276290894,
    "learning_rate": 8.913951545530493e-06,
    "epoch": 0.3258145363408521,
    "step": 1300
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.3715701699256897,
    "learning_rate": 8.905597326649959e-06,
    "epoch": 0.3283208020050125,
    "step": 1310
  },
  {
    "loss": 0.0496,
    "grad_norm": 0.5331628322601318,
    "learning_rate": 8.897243107769424e-06,
    "epoch": 0.3308270676691729,
    "step": 1320
  },
  {
    "loss": 0.0448,
    "grad_norm": 0.4412786662578583,
    "learning_rate": 8.888888888888888e-06,
    "epoch": 0.3333333333333333,
    "step": 1330
  },
  {
    "loss": 0.0265,
    "grad_norm": 0.7146843671798706,
    "learning_rate": 8.880534670008356e-06,
    "epoch": 0.3358395989974937,
    "step": 1340
  },
  {
    "loss": 0.0626,
    "grad_norm": 0.6066380739212036,
    "learning_rate": 8.87218045112782e-06,
    "epoch": 0.3383458646616541,
    "step": 1350
  },
  {
    "loss": 0.0289,
    "grad_norm": 0.2537241280078888,
    "learning_rate": 8.863826232247285e-06,
    "epoch": 0.3408521303258145,
    "step": 1360
  },
  {
    "loss": 0.0592,
    "grad_norm": 0.22971254587173462,
    "learning_rate": 8.855472013366751e-06,
    "epoch": 0.3433583959899749,
    "step": 1370
  },
  {
    "loss": 0.053,
    "grad_norm": 0.6456866264343262,
    "learning_rate": 8.847117794486217e-06,
    "epoch": 0.3458646616541353,
    "step": 1380
  },
  {
    "loss": 0.0498,
    "grad_norm": 1.0337469577789307,
    "learning_rate": 8.83876357560568e-06,
    "epoch": 0.3483709273182957,
    "step": 1390
  },
  {
    "loss": 0.0527,
    "grad_norm": 0.30244770646095276,
    "learning_rate": 8.830409356725146e-06,
    "epoch": 0.3508771929824561,
    "step": 1400
  },
  {
    "loss": 0.0408,
    "grad_norm": 0.21432091295719147,
    "learning_rate": 8.822055137844612e-06,
    "epoch": 0.3533834586466165,
    "step": 1410
  },
  {
    "loss": 0.0572,
    "grad_norm": 0.7862522602081299,
    "learning_rate": 8.813700918964078e-06,
    "epoch": 0.3558897243107769,
    "step": 1420
  },
  {
    "loss": 0.0484,
    "grad_norm": 0.3019372224807739,
    "learning_rate": 8.805346700083542e-06,
    "epoch": 0.3583959899749373,
    "step": 1430
  },
  {
    "loss": 0.0479,
    "grad_norm": 0.3760020434856415,
    "learning_rate": 8.796992481203007e-06,
    "epoch": 0.3609022556390977,
    "step": 1440
  },
  {
    "loss": 0.05,
    "grad_norm": 0.8285312056541443,
    "learning_rate": 8.788638262322473e-06,
    "epoch": 0.3634085213032581,
    "step": 1450
  },
  {
    "loss": 0.0463,
    "grad_norm": 0.42419400811195374,
    "learning_rate": 8.780284043441939e-06,
    "epoch": 0.3659147869674185,
    "step": 1460
  },
  {
    "loss": 0.0613,
    "grad_norm": 0.40711846947669983,
    "learning_rate": 8.771929824561405e-06,
    "epoch": 0.3684210526315789,
    "step": 1470
  },
  {
    "loss": 0.036,
    "grad_norm": 0.7847083210945129,
    "learning_rate": 8.76357560568087e-06,
    "epoch": 0.37092731829573933,
    "step": 1480
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.7806018590927124,
    "learning_rate": 8.755221386800334e-06,
    "epoch": 0.37343358395989973,
    "step": 1490
  },
  {
    "loss": 0.0517,
    "grad_norm": 0.1432655304670334,
    "learning_rate": 8.7468671679198e-06,
    "epoch": 0.37593984962406013,
    "step": 1500
  },
  {
    "eval_loss": 0.05594250187277794,
    "eval_roc_auc_macro": 0.9800836504818843,
    "eval_runtime": 40.0066,
    "eval_samples_per_second": 797.743,
    "eval_steps_per_second": 24.946,
    "epoch": 0.37593984962406013,
    "step": 1500
  },
  {
    "train_loss": 0.05425959825515747,
    "train_roc_auc_macro": 0.9792729502714753,
    "train_runtime": 159.9286,
    "train_samples_per_second": 798.206,
    "train_steps_per_second": 24.949,
    "epoch": 0.37593984962406013,
    "step": 1500
  },
  {
    "loss": 0.0629,
    "grad_norm": 0.37773212790489197,
    "learning_rate": 8.738512949039266e-06,
    "epoch": 0.37844611528822053,
    "step": 1510
  },
  {
    "loss": 0.0427,
    "grad_norm": 1.3975750207901,
    "learning_rate": 8.730158730158731e-06,
    "epoch": 0.38095238095238093,
    "step": 1520
  },
  {
    "loss": 0.0534,
    "grad_norm": 0.4397508203983307,
    "learning_rate": 8.721804511278195e-06,
    "epoch": 0.38345864661654133,
    "step": 1530
  },
  {
    "loss": 0.0478,
    "grad_norm": 0.40284186601638794,
    "learning_rate": 8.713450292397661e-06,
    "epoch": 0.38596491228070173,
    "step": 1540
  },
  {
    "loss": 0.0348,
    "grad_norm": 0.8006528615951538,
    "learning_rate": 8.705096073517127e-06,
    "epoch": 0.38847117794486213,
    "step": 1550
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.4632520079612732,
    "learning_rate": 8.696741854636592e-06,
    "epoch": 0.39097744360902253,
    "step": 1560
  },
  {
    "loss": 0.0604,
    "grad_norm": 0.8520267009735107,
    "learning_rate": 8.688387635756056e-06,
    "epoch": 0.39348370927318294,
    "step": 1570
  },
  {
    "loss": 0.0525,
    "grad_norm": 0.4650229215621948,
    "learning_rate": 8.680033416875524e-06,
    "epoch": 0.39598997493734334,
    "step": 1580
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.4938594400882721,
    "learning_rate": 8.671679197994988e-06,
    "epoch": 0.39849624060150374,
    "step": 1590
  },
  {
    "loss": 0.0298,
    "grad_norm": 0.37127014994621277,
    "learning_rate": 8.663324979114453e-06,
    "epoch": 0.40100250626566414,
    "step": 1600
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.329974889755249,
    "learning_rate": 8.654970760233919e-06,
    "epoch": 0.40350877192982454,
    "step": 1610
  },
  {
    "loss": 0.0328,
    "grad_norm": 0.30486631393432617,
    "learning_rate": 8.646616541353385e-06,
    "epoch": 0.40601503759398494,
    "step": 1620
  },
  {
    "loss": 0.0512,
    "grad_norm": 0.3915208578109741,
    "learning_rate": 8.638262322472849e-06,
    "epoch": 0.40852130325814534,
    "step": 1630
  },
  {
    "loss": 0.0416,
    "grad_norm": 0.5063753724098206,
    "learning_rate": 8.629908103592314e-06,
    "epoch": 0.41102756892230574,
    "step": 1640
  },
  {
    "loss": 0.0462,
    "grad_norm": 0.2536304295063019,
    "learning_rate": 8.62155388471178e-06,
    "epoch": 0.41353383458646614,
    "step": 1650
  },
  {
    "loss": 0.0412,
    "grad_norm": 0.5046199560165405,
    "learning_rate": 8.613199665831246e-06,
    "epoch": 0.41604010025062654,
    "step": 1660
  },
  {
    "loss": 0.0409,
    "grad_norm": 0.2604844868183136,
    "learning_rate": 8.60484544695071e-06,
    "epoch": 0.41854636591478694,
    "step": 1670
  },
  {
    "loss": 0.0471,
    "grad_norm": 0.3453022241592407,
    "learning_rate": 8.596491228070176e-06,
    "epoch": 0.42105263157894735,
    "step": 1680
  },
  {
    "loss": 0.0504,
    "grad_norm": 0.3569882810115814,
    "learning_rate": 8.588137009189641e-06,
    "epoch": 0.42355889724310775,
    "step": 1690
  },
  {
    "loss": 0.0553,
    "grad_norm": 0.6074663996696472,
    "learning_rate": 8.579782790309107e-06,
    "epoch": 0.42606516290726815,
    "step": 1700
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.5133727788925171,
    "learning_rate": 8.571428571428571e-06,
    "epoch": 0.42857142857142855,
    "step": 1710
  },
  {
    "loss": 0.0563,
    "grad_norm": 1.0203086137771606,
    "learning_rate": 8.563074352548038e-06,
    "epoch": 0.43107769423558895,
    "step": 1720
  },
  {
    "loss": 0.0459,
    "grad_norm": 0.1629783809185028,
    "learning_rate": 8.554720133667502e-06,
    "epoch": 0.43358395989974935,
    "step": 1730
  },
  {
    "loss": 0.041,
    "grad_norm": 0.2584037184715271,
    "learning_rate": 8.546365914786968e-06,
    "epoch": 0.43609022556390975,
    "step": 1740
  },
  {
    "loss": 0.0565,
    "grad_norm": 0.5671514272689819,
    "learning_rate": 8.538011695906434e-06,
    "epoch": 0.43859649122807015,
    "step": 1750
  },
  {
    "eval_loss": 0.04363619163632393,
    "eval_roc_auc_macro": 0.979847222678885,
    "eval_runtime": 39.9543,
    "eval_samples_per_second": 798.787,
    "eval_steps_per_second": 24.979,
    "epoch": 0.43859649122807015,
    "step": 1750
  },
  {
    "train_loss": 0.04159574210643768,
    "train_roc_auc_macro": 0.9792631641251811,
    "train_runtime": 159.9527,
    "train_samples_per_second": 798.086,
    "train_steps_per_second": 24.945,
    "epoch": 0.43859649122807015,
    "step": 1750
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.4980745017528534,
    "learning_rate": 8.5296574770259e-06,
    "epoch": 0.44110275689223055,
    "step": 1760
  },
  {
    "loss": 0.0558,
    "grad_norm": 0.26878151297569275,
    "learning_rate": 8.521303258145363e-06,
    "epoch": 0.44360902255639095,
    "step": 1770
  },
  {
    "loss": 0.0413,
    "grad_norm": 0.3149556815624237,
    "learning_rate": 8.512949039264829e-06,
    "epoch": 0.44611528822055135,
    "step": 1780
  },
  {
    "loss": 0.0464,
    "grad_norm": 0.32643207907676697,
    "learning_rate": 8.504594820384295e-06,
    "epoch": 0.44862155388471175,
    "step": 1790
  },
  {
    "loss": 0.0516,
    "grad_norm": 0.3945469260215759,
    "learning_rate": 8.49624060150376e-06,
    "epoch": 0.45112781954887216,
    "step": 1800
  },
  {
    "loss": 0.0613,
    "grad_norm": 0.284432053565979,
    "learning_rate": 8.487886382623224e-06,
    "epoch": 0.45363408521303256,
    "step": 1810
  },
  {
    "loss": 0.0475,
    "grad_norm": 0.3972332775592804,
    "learning_rate": 8.47953216374269e-06,
    "epoch": 0.45614035087719296,
    "step": 1820
  },
  {
    "loss": 0.0457,
    "grad_norm": 0.48286864161491394,
    "learning_rate": 8.471177944862156e-06,
    "epoch": 0.45864661654135336,
    "step": 1830
  },
  {
    "loss": 0.0478,
    "grad_norm": 1.173645257949829,
    "learning_rate": 8.462823725981621e-06,
    "epoch": 0.46115288220551376,
    "step": 1840
  },
  {
    "loss": 0.0568,
    "grad_norm": 0.3363725244998932,
    "learning_rate": 8.454469507101085e-06,
    "epoch": 0.46365914786967416,
    "step": 1850
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.24707522988319397,
    "learning_rate": 8.446115288220553e-06,
    "epoch": 0.46616541353383456,
    "step": 1860
  },
  {
    "loss": 0.0534,
    "grad_norm": 0.3460262715816498,
    "learning_rate": 8.437761069340017e-06,
    "epoch": 0.46867167919799496,
    "step": 1870
  },
  {
    "loss": 0.0505,
    "grad_norm": 0.2912001609802246,
    "learning_rate": 8.429406850459483e-06,
    "epoch": 0.47117794486215536,
    "step": 1880
  },
  {
    "loss": 0.0464,
    "grad_norm": 1.283653974533081,
    "learning_rate": 8.421052631578948e-06,
    "epoch": 0.47368421052631576,
    "step": 1890
  },
  {
    "loss": 0.0488,
    "grad_norm": 0.27329233288764954,
    "learning_rate": 8.412698412698414e-06,
    "epoch": 0.47619047619047616,
    "step": 1900
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.2733033299446106,
    "learning_rate": 8.404344193817878e-06,
    "epoch": 0.47869674185463656,
    "step": 1910
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.28308045864105225,
    "learning_rate": 8.395989974937344e-06,
    "epoch": 0.48120300751879697,
    "step": 1920
  },
  {
    "loss": 0.0435,
    "grad_norm": 0.3129265606403351,
    "learning_rate": 8.38763575605681e-06,
    "epoch": 0.48370927318295737,
    "step": 1930
  },
  {
    "loss": 0.0511,
    "grad_norm": 0.491897851228714,
    "learning_rate": 8.379281537176275e-06,
    "epoch": 0.48621553884711777,
    "step": 1940
  },
  {
    "loss": 0.0554,
    "grad_norm": 0.4812457859516144,
    "learning_rate": 8.370927318295739e-06,
    "epoch": 0.48872180451127817,
    "step": 1950
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.12272725999355316,
    "learning_rate": 8.362573099415205e-06,
    "epoch": 0.49122807017543857,
    "step": 1960
  },
  {
    "loss": 0.0366,
    "grad_norm": 0.4785144329071045,
    "learning_rate": 8.35421888053467e-06,
    "epoch": 0.49373433583959897,
    "step": 1970
  },
  {
    "loss": 0.0483,
    "grad_norm": 0.9261921644210815,
    "learning_rate": 8.345864661654136e-06,
    "epoch": 0.49624060150375937,
    "step": 1980
  },
  {
    "loss": 0.0503,
    "grad_norm": 1.13981032371521,
    "learning_rate": 8.3375104427736e-06,
    "epoch": 0.49874686716791977,
    "step": 1990
  },
  {
    "loss": 0.0338,
    "grad_norm": 0.8295858502388,
    "learning_rate": 8.329156223893067e-06,
    "epoch": 0.5012531328320802,
    "step": 2000
  },
  {
    "eval_loss": 0.04620138183236122,
    "eval_roc_auc_macro": 0.9815306567031484,
    "eval_runtime": 40.0611,
    "eval_samples_per_second": 796.657,
    "eval_steps_per_second": 24.912,
    "epoch": 0.5012531328320802,
    "step": 2000
  },
  {
    "train_loss": 0.04412546381354332,
    "train_roc_auc_macro": 0.9811969417814247,
    "train_runtime": 159.6595,
    "train_samples_per_second": 799.552,
    "train_steps_per_second": 24.991,
    "epoch": 0.5012531328320802,
    "step": 2000
  },
  {
    "loss": 0.0535,
    "grad_norm": 1.0581095218658447,
    "learning_rate": 8.320802005012531e-06,
    "epoch": 0.5037593984962406,
    "step": 2010
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.4470161497592926,
    "learning_rate": 8.312447786131997e-06,
    "epoch": 0.506265664160401,
    "step": 2020
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.20096173882484436,
    "learning_rate": 8.304093567251463e-06,
    "epoch": 0.5087719298245614,
    "step": 2030
  },
  {
    "loss": 0.0535,
    "grad_norm": 0.4444079101085663,
    "learning_rate": 8.295739348370928e-06,
    "epoch": 0.5112781954887218,
    "step": 2040
  },
  {
    "loss": 0.0259,
    "grad_norm": 0.21683727204799652,
    "learning_rate": 8.287385129490392e-06,
    "epoch": 0.5137844611528822,
    "step": 2050
  },
  {
    "loss": 0.048,
    "grad_norm": 0.6758605241775513,
    "learning_rate": 8.279030910609858e-06,
    "epoch": 0.5162907268170426,
    "step": 2060
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.8751575946807861,
    "learning_rate": 8.270676691729324e-06,
    "epoch": 0.518796992481203,
    "step": 2070
  },
  {
    "loss": 0.0445,
    "grad_norm": 0.3348569869995117,
    "learning_rate": 8.26232247284879e-06,
    "epoch": 0.5213032581453634,
    "step": 2080
  },
  {
    "loss": 0.0549,
    "grad_norm": 0.48316770792007446,
    "learning_rate": 8.253968253968254e-06,
    "epoch": 0.5238095238095238,
    "step": 2090
  },
  {
    "loss": 0.0424,
    "grad_norm": 0.3164125978946686,
    "learning_rate": 8.24561403508772e-06,
    "epoch": 0.5263157894736842,
    "step": 2100
  },
  {
    "loss": 0.046,
    "grad_norm": 0.3947729766368866,
    "learning_rate": 8.237259816207185e-06,
    "epoch": 0.5288220551378446,
    "step": 2110
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.11103789508342743,
    "learning_rate": 8.22890559732665e-06,
    "epoch": 0.531328320802005,
    "step": 2120
  },
  {
    "loss": 0.0422,
    "grad_norm": 0.2883380353450775,
    "learning_rate": 8.220551378446116e-06,
    "epoch": 0.5338345864661654,
    "step": 2130
  },
  {
    "loss": 0.0395,
    "grad_norm": 0.6344161629676819,
    "learning_rate": 8.212197159565582e-06,
    "epoch": 0.5363408521303258,
    "step": 2140
  },
  {
    "loss": 0.0397,
    "grad_norm": 0.4191558063030243,
    "learning_rate": 8.203842940685046e-06,
    "epoch": 0.5388471177944862,
    "step": 2150
  },
  {
    "loss": 0.0384,
    "grad_norm": 0.7671234011650085,
    "learning_rate": 8.195488721804512e-06,
    "epoch": 0.5413533834586466,
    "step": 2160
  },
  {
    "loss": 0.0337,
    "grad_norm": 0.6136603355407715,
    "learning_rate": 8.187134502923977e-06,
    "epoch": 0.543859649122807,
    "step": 2170
  },
  {
    "loss": 0.0412,
    "grad_norm": 0.2938693165779114,
    "learning_rate": 8.178780284043443e-06,
    "epoch": 0.5463659147869674,
    "step": 2180
  },
  {
    "loss": 0.0327,
    "grad_norm": 0.18009896576404572,
    "learning_rate": 8.170426065162907e-06,
    "epoch": 0.5488721804511278,
    "step": 2190
  },
  {
    "loss": 0.0486,
    "grad_norm": 0.7230425477027893,
    "learning_rate": 8.162071846282373e-06,
    "epoch": 0.5513784461152882,
    "step": 2200
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.20029640197753906,
    "learning_rate": 8.153717627401838e-06,
    "epoch": 0.5538847117794486,
    "step": 2210
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.447550892829895,
    "learning_rate": 8.145363408521304e-06,
    "epoch": 0.556390977443609,
    "step": 2220
  },
  {
    "loss": 0.0393,
    "grad_norm": 0.1603633016347885,
    "learning_rate": 8.137009189640768e-06,
    "epoch": 0.5588972431077694,
    "step": 2230
  },
  {
    "loss": 0.043,
    "grad_norm": 0.42581963539123535,
    "learning_rate": 8.128654970760235e-06,
    "epoch": 0.5614035087719298,
    "step": 2240
  },
  {
    "loss": 0.04,
    "grad_norm": 0.30639150738716125,
    "learning_rate": 8.1203007518797e-06,
    "epoch": 0.5639097744360902,
    "step": 2250
  },
  {
    "eval_loss": 0.043148089200258255,
    "eval_roc_auc_macro": 0.9818879656637103,
    "eval_runtime": 39.9961,
    "eval_samples_per_second": 797.952,
    "eval_steps_per_second": 24.952,
    "epoch": 0.5639097744360902,
    "step": 2250
  },
  {
    "train_loss": 0.04091856628656387,
    "train_roc_auc_macro": 0.981242407568821,
    "train_runtime": 159.5895,
    "train_samples_per_second": 799.902,
    "train_steps_per_second": 25.002,
    "epoch": 0.5639097744360902,
    "step": 2250
  },
  {
    "loss": 0.0532,
    "grad_norm": 0.7473667860031128,
    "learning_rate": 8.111946532999165e-06,
    "epoch": 0.5664160401002506,
    "step": 2260
  },
  {
    "loss": 0.053,
    "grad_norm": 2.1699576377868652,
    "learning_rate": 8.103592314118631e-06,
    "epoch": 0.568922305764411,
    "step": 2270
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.2898707687854767,
    "learning_rate": 8.095238095238097e-06,
    "epoch": 0.5714285714285714,
    "step": 2280
  },
  {
    "loss": 0.0415,
    "grad_norm": 0.5446420311927795,
    "learning_rate": 8.08688387635756e-06,
    "epoch": 0.5739348370927319,
    "step": 2290
  },
  {
    "loss": 0.0488,
    "grad_norm": 0.3688560426235199,
    "learning_rate": 8.078529657477026e-06,
    "epoch": 0.5764411027568922,
    "step": 2300
  },
  {
    "loss": 0.0274,
    "grad_norm": 0.4338096082210541,
    "learning_rate": 8.070175438596492e-06,
    "epoch": 0.5789473684210527,
    "step": 2310
  },
  {
    "loss": 0.0385,
    "grad_norm": 0.4875083863735199,
    "learning_rate": 8.061821219715958e-06,
    "epoch": 0.581453634085213,
    "step": 2320
  },
  {
    "loss": 0.045,
    "grad_norm": 0.5762667059898376,
    "learning_rate": 8.053467000835422e-06,
    "epoch": 0.5839598997493735,
    "step": 2330
  },
  {
    "loss": 0.059,
    "grad_norm": 0.20597687363624573,
    "learning_rate": 8.045112781954887e-06,
    "epoch": 0.5864661654135338,
    "step": 2340
  },
  {
    "loss": 0.0435,
    "grad_norm": 0.6094363331794739,
    "learning_rate": 8.036758563074353e-06,
    "epoch": 0.5889724310776943,
    "step": 2350
  },
  {
    "loss": 0.0442,
    "grad_norm": 0.39583835005760193,
    "learning_rate": 8.028404344193819e-06,
    "epoch": 0.5914786967418546,
    "step": 2360
  },
  {
    "loss": 0.0471,
    "grad_norm": 0.2542031407356262,
    "learning_rate": 8.020050125313283e-06,
    "epoch": 0.5939849624060151,
    "step": 2370
  },
  {
    "loss": 0.0469,
    "grad_norm": 0.3785684108734131,
    "learning_rate": 8.01169590643275e-06,
    "epoch": 0.5964912280701754,
    "step": 2380
  },
  {
    "loss": 0.0509,
    "grad_norm": 0.4210227429866791,
    "learning_rate": 8.003341687552214e-06,
    "epoch": 0.5989974937343359,
    "step": 2390
  },
  {
    "loss": 0.035,
    "grad_norm": 0.27242276072502136,
    "learning_rate": 7.99498746867168e-06,
    "epoch": 0.6015037593984962,
    "step": 2400
  },
  {
    "loss": 0.046,
    "grad_norm": 0.5476567149162292,
    "learning_rate": 7.986633249791145e-06,
    "epoch": 0.6040100250626567,
    "step": 2410
  },
  {
    "loss": 0.0363,
    "grad_norm": 0.10697009414434433,
    "learning_rate": 7.978279030910611e-06,
    "epoch": 0.606516290726817,
    "step": 2420
  },
  {
    "loss": 0.0399,
    "grad_norm": 0.5364345908164978,
    "learning_rate": 7.969924812030075e-06,
    "epoch": 0.6090225563909775,
    "step": 2430
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.361415296792984,
    "learning_rate": 7.96157059314954e-06,
    "epoch": 0.6115288220551378,
    "step": 2440
  },
  {
    "loss": 0.0428,
    "grad_norm": 0.5530555844306946,
    "learning_rate": 7.953216374269006e-06,
    "epoch": 0.6140350877192983,
    "step": 2450
  },
  {
    "loss": 0.0603,
    "grad_norm": 0.64068603515625,
    "learning_rate": 7.944862155388472e-06,
    "epoch": 0.6165413533834586,
    "step": 2460
  },
  {
    "loss": 0.0544,
    "grad_norm": 0.9593676924705505,
    "learning_rate": 7.936507936507936e-06,
    "epoch": 0.6190476190476191,
    "step": 2470
  },
  {
    "loss": 0.0397,
    "grad_norm": 0.3475091755390167,
    "learning_rate": 7.928153717627402e-06,
    "epoch": 0.6215538847117794,
    "step": 2480
  },
  {
    "loss": 0.0397,
    "grad_norm": 0.5190036296844482,
    "learning_rate": 7.919799498746868e-06,
    "epoch": 0.6240601503759399,
    "step": 2490
  },
  {
    "loss": 0.0402,
    "grad_norm": 0.7189645767211914,
    "learning_rate": 7.911445279866333e-06,
    "epoch": 0.6265664160401002,
    "step": 2500
  },
  {
    "eval_loss": 0.043154384940862656,
    "eval_roc_auc_macro": 0.9820017329739162,
    "eval_runtime": 39.9748,
    "eval_samples_per_second": 798.378,
    "eval_steps_per_second": 24.966,
    "epoch": 0.6265664160401002,
    "step": 2500
  },
  {
    "train_loss": 0.040564484894275665,
    "train_roc_auc_macro": 0.9822354692395661,
    "train_runtime": 159.9164,
    "train_samples_per_second": 798.267,
    "train_steps_per_second": 24.951,
    "epoch": 0.6265664160401002,
    "step": 2500
  },
  {
    "loss": 0.0466,
    "grad_norm": 0.4714122414588928,
    "learning_rate": 7.903091060985797e-06,
    "epoch": 0.6290726817042607,
    "step": 2510
  },
  {
    "loss": 0.0369,
    "grad_norm": 0.5302111506462097,
    "learning_rate": 7.894736842105265e-06,
    "epoch": 0.631578947368421,
    "step": 2520
  },
  {
    "loss": 0.0384,
    "grad_norm": 0.16994652152061462,
    "learning_rate": 7.886382623224729e-06,
    "epoch": 0.6340852130325815,
    "step": 2530
  },
  {
    "loss": 0.0479,
    "grad_norm": 0.8874771595001221,
    "learning_rate": 7.878028404344194e-06,
    "epoch": 0.6365914786967418,
    "step": 2540
  },
  {
    "loss": 0.0326,
    "grad_norm": 0.6028802990913391,
    "learning_rate": 7.86967418546366e-06,
    "epoch": 0.6390977443609023,
    "step": 2550
  },
  {
    "loss": 0.0459,
    "grad_norm": 1.3760420083999634,
    "learning_rate": 7.861319966583126e-06,
    "epoch": 0.6416040100250626,
    "step": 2560
  },
  {
    "loss": 0.0273,
    "grad_norm": 0.625218391418457,
    "learning_rate": 7.85296574770259e-06,
    "epoch": 0.6441102756892231,
    "step": 2570
  },
  {
    "loss": 0.0386,
    "grad_norm": 0.7921721339225769,
    "learning_rate": 7.844611528822055e-06,
    "epoch": 0.6466165413533834,
    "step": 2580
  },
  {
    "loss": 0.0369,
    "grad_norm": 0.34249579906463623,
    "learning_rate": 7.836257309941521e-06,
    "epoch": 0.6491228070175439,
    "step": 2590
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.4457331895828247,
    "learning_rate": 7.827903091060987e-06,
    "epoch": 0.6516290726817042,
    "step": 2600
  },
  {
    "loss": 0.0407,
    "grad_norm": 0.6575812697410583,
    "learning_rate": 7.81954887218045e-06,
    "epoch": 0.6541353383458647,
    "step": 2610
  },
  {
    "loss": 0.0454,
    "grad_norm": 0.6236728429794312,
    "learning_rate": 7.811194653299916e-06,
    "epoch": 0.656641604010025,
    "step": 2620
  },
  {
    "loss": 0.0465,
    "grad_norm": 0.25589150190353394,
    "learning_rate": 7.802840434419382e-06,
    "epoch": 0.6591478696741855,
    "step": 2630
  },
  {
    "loss": 0.038,
    "grad_norm": 0.2006371021270752,
    "learning_rate": 7.794486215538848e-06,
    "epoch": 0.6616541353383458,
    "step": 2640
  },
  {
    "loss": 0.049,
    "grad_norm": 0.33041155338287354,
    "learning_rate": 7.786131996658313e-06,
    "epoch": 0.6641604010025063,
    "step": 2650
  },
  {
    "loss": 0.029,
    "grad_norm": 0.5766146779060364,
    "learning_rate": 7.77777777777778e-06,
    "epoch": 0.6666666666666666,
    "step": 2660
  },
  {
    "loss": 0.0364,
    "grad_norm": 1.3570525646209717,
    "learning_rate": 7.769423558897243e-06,
    "epoch": 0.6691729323308271,
    "step": 2670
  },
  {
    "loss": 0.055,
    "grad_norm": 0.40262341499328613,
    "learning_rate": 7.761069340016709e-06,
    "epoch": 0.6716791979949874,
    "step": 2680
  },
  {
    "loss": 0.0402,
    "grad_norm": 0.8870128989219666,
    "learning_rate": 7.752715121136175e-06,
    "epoch": 0.6741854636591479,
    "step": 2690
  },
  {
    "loss": 0.0312,
    "grad_norm": 0.25049474835395813,
    "learning_rate": 7.74436090225564e-06,
    "epoch": 0.6766917293233082,
    "step": 2700
  },
  {
    "loss": 0.0586,
    "grad_norm": 0.41615256667137146,
    "learning_rate": 7.736006683375104e-06,
    "epoch": 0.6791979949874687,
    "step": 2710
  },
  {
    "loss": 0.0396,
    "grad_norm": 0.9339696764945984,
    "learning_rate": 7.72765246449457e-06,
    "epoch": 0.681704260651629,
    "step": 2720
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.45392829179763794,
    "learning_rate": 7.719298245614036e-06,
    "epoch": 0.6842105263157895,
    "step": 2730
  },
  {
    "loss": 0.0479,
    "grad_norm": 0.19683879613876343,
    "learning_rate": 7.710944026733501e-06,
    "epoch": 0.6867167919799498,
    "step": 2740
  },
  {
    "loss": 0.029,
    "grad_norm": 0.5547283291816711,
    "learning_rate": 7.702589807852965e-06,
    "epoch": 0.6892230576441103,
    "step": 2750
  },
  {
    "eval_loss": 0.04372181370854378,
    "eval_roc_auc_macro": 0.9800372526478807,
    "eval_runtime": 40.0398,
    "eval_samples_per_second": 797.082,
    "eval_steps_per_second": 24.925,
    "epoch": 0.6892230576441103,
    "step": 2750
  },
  {
    "train_loss": 0.04050041362643242,
    "train_roc_auc_macro": 0.9812285498650749,
    "train_runtime": 159.854,
    "train_samples_per_second": 798.579,
    "train_steps_per_second": 24.96,
    "epoch": 0.6892230576441103,
    "step": 2750
  },
  {
    "loss": 0.04,
    "grad_norm": 0.07716935873031616,
    "learning_rate": 7.694235588972433e-06,
    "epoch": 0.6917293233082706,
    "step": 2760
  },
  {
    "loss": 0.0366,
    "grad_norm": 0.6665096282958984,
    "learning_rate": 7.685881370091897e-06,
    "epoch": 0.6942355889724311,
    "step": 2770
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.4488235414028168,
    "learning_rate": 7.677527151211362e-06,
    "epoch": 0.6967418546365914,
    "step": 2780
  },
  {
    "loss": 0.0276,
    "grad_norm": 0.1044580489397049,
    "learning_rate": 7.669172932330828e-06,
    "epoch": 0.6992481203007519,
    "step": 2790
  },
  {
    "loss": 0.0586,
    "grad_norm": 0.49194520711898804,
    "learning_rate": 7.660818713450294e-06,
    "epoch": 0.7017543859649122,
    "step": 2800
  },
  {
    "loss": 0.0388,
    "grad_norm": 0.28963154554367065,
    "learning_rate": 7.652464494569758e-06,
    "epoch": 0.7042606516290727,
    "step": 2810
  },
  {
    "loss": 0.0401,
    "grad_norm": 1.0472050905227661,
    "learning_rate": 7.644110275689223e-06,
    "epoch": 0.706766917293233,
    "step": 2820
  },
  {
    "loss": 0.0513,
    "grad_norm": 0.8354638814926147,
    "learning_rate": 7.635756056808689e-06,
    "epoch": 0.7092731829573935,
    "step": 2830
  },
  {
    "loss": 0.0346,
    "grad_norm": 0.4001978039741516,
    "learning_rate": 7.627401837928155e-06,
    "epoch": 0.7117794486215538,
    "step": 2840
  },
  {
    "loss": 0.042,
    "grad_norm": 0.45572203397750854,
    "learning_rate": 7.61904761904762e-06,
    "epoch": 0.7142857142857143,
    "step": 2850
  },
  {
    "loss": 0.0311,
    "grad_norm": 0.27843087911605835,
    "learning_rate": 7.610693400167085e-06,
    "epoch": 0.7167919799498746,
    "step": 2860
  },
  {
    "loss": 0.0575,
    "grad_norm": 0.6297701001167297,
    "learning_rate": 7.60233918128655e-06,
    "epoch": 0.7192982456140351,
    "step": 2870
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.4769802987575531,
    "learning_rate": 7.593984962406016e-06,
    "epoch": 0.7218045112781954,
    "step": 2880
  },
  {
    "loss": 0.0318,
    "grad_norm": 0.11791422218084335,
    "learning_rate": 7.585630743525481e-06,
    "epoch": 0.7243107769423559,
    "step": 2890
  },
  {
    "loss": 0.0431,
    "grad_norm": 0.1971701681613922,
    "learning_rate": 7.577276524644946e-06,
    "epoch": 0.7268170426065163,
    "step": 2900
  },
  {
    "loss": 0.0405,
    "grad_norm": 0.40948787331581116,
    "learning_rate": 7.568922305764411e-06,
    "epoch": 0.7293233082706767,
    "step": 2910
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.26004138588905334,
    "learning_rate": 7.560568086883877e-06,
    "epoch": 0.731829573934837,
    "step": 2920
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.48156124353408813,
    "learning_rate": 7.552213868003342e-06,
    "epoch": 0.7343358395989975,
    "step": 2930
  },
  {
    "loss": 0.0412,
    "grad_norm": 0.8116852641105652,
    "learning_rate": 7.5438596491228074e-06,
    "epoch": 0.7368421052631579,
    "step": 2940
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.6610565185546875,
    "learning_rate": 7.535505430242272e-06,
    "epoch": 0.7393483709273183,
    "step": 2950
  },
  {
    "loss": 0.0448,
    "grad_norm": 0.21718695759773254,
    "learning_rate": 7.527151211361739e-06,
    "epoch": 0.7418546365914787,
    "step": 2960
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.30952295660972595,
    "learning_rate": 7.518796992481203e-06,
    "epoch": 0.7443609022556391,
    "step": 2970
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.8603510856628418,
    "learning_rate": 7.510442773600669e-06,
    "epoch": 0.7468671679197995,
    "step": 2980
  },
  {
    "loss": 0.0423,
    "grad_norm": 0.5937120318412781,
    "learning_rate": 7.502088554720134e-06,
    "epoch": 0.7493734335839599,
    "step": 2990
  },
  {
    "loss": 0.0373,
    "grad_norm": 0.7531766295433044,
    "learning_rate": 7.4937343358396e-06,
    "epoch": 0.7518796992481203,
    "step": 3000
  },
  {
    "eval_loss": 0.04252554103732109,
    "eval_roc_auc_macro": 0.9837781150893341,
    "eval_runtime": 39.9254,
    "eval_samples_per_second": 799.366,
    "eval_steps_per_second": 24.997,
    "epoch": 0.7518796992481203,
    "step": 3000
  },
  {
    "train_loss": 0.04008088633418083,
    "train_roc_auc_macro": 0.9838003610251063,
    "train_runtime": 159.9778,
    "train_samples_per_second": 797.961,
    "train_steps_per_second": 24.941,
    "epoch": 0.7518796992481203,
    "step": 3000
  },
  {
    "loss": 0.0379,
    "grad_norm": 0.4417380690574646,
    "learning_rate": 7.485380116959065e-06,
    "epoch": 0.7543859649122807,
    "step": 3010
  },
  {
    "loss": 0.0533,
    "grad_norm": 1.6320383548736572,
    "learning_rate": 7.47702589807853e-06,
    "epoch": 0.7568922305764411,
    "step": 3020
  },
  {
    "loss": 0.0425,
    "grad_norm": 0.4227752089500427,
    "learning_rate": 7.468671679197995e-06,
    "epoch": 0.7593984962406015,
    "step": 3030
  },
  {
    "loss": 0.0365,
    "grad_norm": 0.2663240432739258,
    "learning_rate": 7.460317460317461e-06,
    "epoch": 0.7619047619047619,
    "step": 3040
  },
  {
    "loss": 0.0385,
    "grad_norm": 0.927093505859375,
    "learning_rate": 7.451963241436926e-06,
    "epoch": 0.7644110275689223,
    "step": 3050
  },
  {
    "loss": 0.0388,
    "grad_norm": 0.30234476923942566,
    "learning_rate": 7.4436090225563915e-06,
    "epoch": 0.7669172932330827,
    "step": 3060
  },
  {
    "loss": 0.0462,
    "grad_norm": 0.5553832054138184,
    "learning_rate": 7.435254803675856e-06,
    "epoch": 0.7694235588972431,
    "step": 3070
  },
  {
    "loss": 0.0352,
    "grad_norm": 0.38860011100769043,
    "learning_rate": 7.426900584795322e-06,
    "epoch": 0.7719298245614035,
    "step": 3080
  },
  {
    "loss": 0.0468,
    "grad_norm": 0.3037770688533783,
    "learning_rate": 7.418546365914787e-06,
    "epoch": 0.7744360902255639,
    "step": 3090
  },
  {
    "loss": 0.0426,
    "grad_norm": 0.315827339887619,
    "learning_rate": 7.410192147034253e-06,
    "epoch": 0.7769423558897243,
    "step": 3100
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.39250993728637695,
    "learning_rate": 7.401837928153718e-06,
    "epoch": 0.7794486215538847,
    "step": 3110
  },
  {
    "loss": 0.0198,
    "grad_norm": 0.41638699173927307,
    "learning_rate": 7.393483709273184e-06,
    "epoch": 0.7819548872180451,
    "step": 3120
  },
  {
    "loss": 0.0518,
    "grad_norm": 0.5663459300994873,
    "learning_rate": 7.385129490392649e-06,
    "epoch": 0.7844611528822055,
    "step": 3130
  },
  {
    "loss": 0.0461,
    "grad_norm": 0.3771314322948456,
    "learning_rate": 7.3767752715121144e-06,
    "epoch": 0.7869674185463659,
    "step": 3140
  },
  {
    "loss": 0.0332,
    "grad_norm": 0.37607091665267944,
    "learning_rate": 7.368421052631579e-06,
    "epoch": 0.7894736842105263,
    "step": 3150
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.4392107129096985,
    "learning_rate": 7.360066833751045e-06,
    "epoch": 0.7919799498746867,
    "step": 3160
  },
  {
    "loss": 0.0461,
    "grad_norm": 0.37261509895324707,
    "learning_rate": 7.35171261487051e-06,
    "epoch": 0.7944862155388471,
    "step": 3170
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.5101303458213806,
    "learning_rate": 7.3433583959899755e-06,
    "epoch": 0.7969924812030075,
    "step": 3180
  },
  {
    "loss": 0.0334,
    "grad_norm": 0.5522726774215698,
    "learning_rate": 7.33500417710944e-06,
    "epoch": 0.7994987468671679,
    "step": 3190
  },
  {
    "loss": 0.0503,
    "grad_norm": 0.4138524532318115,
    "learning_rate": 7.326649958228906e-06,
    "epoch": 0.8020050125313283,
    "step": 3200
  },
  {
    "loss": 0.0408,
    "grad_norm": 0.47271859645843506,
    "learning_rate": 7.318295739348371e-06,
    "epoch": 0.8045112781954887,
    "step": 3210
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.1948351114988327,
    "learning_rate": 7.309941520467837e-06,
    "epoch": 0.8070175438596491,
    "step": 3220
  },
  {
    "loss": 0.041,
    "grad_norm": 0.8697149753570557,
    "learning_rate": 7.301587301587301e-06,
    "epoch": 0.8095238095238095,
    "step": 3230
  },
  {
    "loss": 0.0392,
    "grad_norm": 0.43387141823768616,
    "learning_rate": 7.293233082706768e-06,
    "epoch": 0.8120300751879699,
    "step": 3240
  },
  {
    "loss": 0.0386,
    "grad_norm": 0.4322119951248169,
    "learning_rate": 7.284878863826233e-06,
    "epoch": 0.8145363408521303,
    "step": 3250
  },
  {
    "eval_loss": 0.043000612407922745,
    "eval_roc_auc_macro": 0.9840406463147827,
    "eval_runtime": 40.0017,
    "eval_samples_per_second": 797.842,
    "eval_steps_per_second": 24.949,
    "epoch": 0.8145363408521303,
    "step": 3250
  },
  {
    "train_loss": 0.04040689393877983,
    "train_roc_auc_macro": 0.9841042400320476,
    "train_runtime": 159.7152,
    "train_samples_per_second": 799.273,
    "train_steps_per_second": 24.982,
    "epoch": 0.8145363408521303,
    "step": 3250
  },
  {
    "loss": 0.0378,
    "grad_norm": 0.6570333242416382,
    "learning_rate": 7.2765246449456985e-06,
    "epoch": 0.8170426065162907,
    "step": 3260
  },
  {
    "loss": 0.0431,
    "grad_norm": 0.9000953435897827,
    "learning_rate": 7.268170426065163e-06,
    "epoch": 0.8195488721804511,
    "step": 3270
  },
  {
    "loss": 0.0449,
    "grad_norm": 0.4357687830924988,
    "learning_rate": 7.259816207184629e-06,
    "epoch": 0.8220551378446115,
    "step": 3280
  },
  {
    "loss": 0.0454,
    "grad_norm": 0.6125727891921997,
    "learning_rate": 7.251461988304094e-06,
    "epoch": 0.8245614035087719,
    "step": 3290
  },
  {
    "loss": 0.0464,
    "grad_norm": 0.5513541102409363,
    "learning_rate": 7.2431077694235595e-06,
    "epoch": 0.8270676691729323,
    "step": 3300
  },
  {
    "loss": 0.0471,
    "grad_norm": 0.49994340538978577,
    "learning_rate": 7.234753550543024e-06,
    "epoch": 0.8295739348370927,
    "step": 3310
  },
  {
    "loss": 0.0429,
    "grad_norm": 0.21551001071929932,
    "learning_rate": 7.22639933166249e-06,
    "epoch": 0.8320802005012531,
    "step": 3320
  },
  {
    "loss": 0.0373,
    "grad_norm": 0.5507022738456726,
    "learning_rate": 7.218045112781955e-06,
    "epoch": 0.8345864661654135,
    "step": 3330
  },
  {
    "loss": 0.0335,
    "grad_norm": 0.4908674955368042,
    "learning_rate": 7.209690893901421e-06,
    "epoch": 0.8370927318295739,
    "step": 3340
  },
  {
    "loss": 0.0567,
    "grad_norm": 1.210649013519287,
    "learning_rate": 7.2013366750208854e-06,
    "epoch": 0.8395989974937343,
    "step": 3350
  },
  {
    "loss": 0.038,
    "grad_norm": 0.4529270827770233,
    "learning_rate": 7.192982456140352e-06,
    "epoch": 0.8421052631578947,
    "step": 3360
  },
  {
    "loss": 0.0448,
    "grad_norm": 0.7142676711082458,
    "learning_rate": 7.184628237259817e-06,
    "epoch": 0.8446115288220551,
    "step": 3370
  },
  {
    "loss": 0.0486,
    "grad_norm": 0.6757846474647522,
    "learning_rate": 7.1762740183792825e-06,
    "epoch": 0.8471177944862155,
    "step": 3380
  },
  {
    "loss": 0.038,
    "grad_norm": 0.1744994968175888,
    "learning_rate": 7.167919799498747e-06,
    "epoch": 0.849624060150376,
    "step": 3390
  },
  {
    "loss": 0.0293,
    "grad_norm": 0.3458723723888397,
    "learning_rate": 7.159565580618213e-06,
    "epoch": 0.8521303258145363,
    "step": 3400
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.4857826828956604,
    "learning_rate": 7.151211361737678e-06,
    "epoch": 0.8546365914786967,
    "step": 3410
  },
  {
    "loss": 0.0372,
    "grad_norm": 0.6297512650489807,
    "learning_rate": 7.1428571428571436e-06,
    "epoch": 0.8571428571428571,
    "step": 3420
  },
  {
    "loss": 0.0391,
    "grad_norm": 0.3482569754123688,
    "learning_rate": 7.134502923976608e-06,
    "epoch": 0.8596491228070176,
    "step": 3430
  },
  {
    "loss": 0.0429,
    "grad_norm": 0.5002357363700867,
    "learning_rate": 7.126148705096074e-06,
    "epoch": 0.8621553884711779,
    "step": 3440
  },
  {
    "loss": 0.0382,
    "grad_norm": 0.22519804537296295,
    "learning_rate": 7.117794486215539e-06,
    "epoch": 0.8646616541353384,
    "step": 3450
  },
  {
    "loss": 0.0373,
    "grad_norm": 0.35717326402664185,
    "learning_rate": 7.109440267335005e-06,
    "epoch": 0.8671679197994987,
    "step": 3460
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.6146859526634216,
    "learning_rate": 7.1010860484544695e-06,
    "epoch": 0.8696741854636592,
    "step": 3470
  },
  {
    "loss": 0.0494,
    "grad_norm": 0.5803267359733582,
    "learning_rate": 7.092731829573936e-06,
    "epoch": 0.8721804511278195,
    "step": 3480
  },
  {
    "loss": 0.0511,
    "grad_norm": 0.6827003359794617,
    "learning_rate": 7.0843776106934e-06,
    "epoch": 0.87468671679198,
    "step": 3490
  },
  {
    "loss": 0.0466,
    "grad_norm": 0.5820181965827942,
    "learning_rate": 7.0760233918128665e-06,
    "epoch": 0.8771929824561403,
    "step": 3500
  },
  {
    "eval_loss": 0.04126529023051262,
    "eval_roc_auc_macro": 0.9848156341257193,
    "eval_runtime": 39.9802,
    "eval_samples_per_second": 798.27,
    "eval_steps_per_second": 24.962,
    "epoch": 0.8771929824561403,
    "step": 3500
  },
  {
    "train_loss": 0.038471419364213943,
    "train_roc_auc_macro": 0.9853322318421965,
    "train_runtime": 159.9722,
    "train_samples_per_second": 797.989,
    "train_steps_per_second": 24.942,
    "epoch": 0.8771929824561403,
    "step": 3500
  },
  {
    "loss": 0.042,
    "grad_norm": 0.884475827217102,
    "learning_rate": 7.067669172932331e-06,
    "epoch": 0.8796992481203008,
    "step": 3510
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.13940437138080597,
    "learning_rate": 7.059314954051797e-06,
    "epoch": 0.8822055137844611,
    "step": 3520
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.5322759747505188,
    "learning_rate": 7.050960735171262e-06,
    "epoch": 0.8847117794486216,
    "step": 3530
  },
  {
    "loss": 0.0323,
    "grad_norm": 0.39134982228279114,
    "learning_rate": 7.042606516290728e-06,
    "epoch": 0.8872180451127819,
    "step": 3540
  },
  {
    "loss": 0.0523,
    "grad_norm": 0.2262226939201355,
    "learning_rate": 7.0342522974101924e-06,
    "epoch": 0.8897243107769424,
    "step": 3550
  },
  {
    "loss": 0.0441,
    "grad_norm": 0.34654951095581055,
    "learning_rate": 7.025898078529658e-06,
    "epoch": 0.8922305764411027,
    "step": 3560
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.5086077451705933,
    "learning_rate": 7.017543859649123e-06,
    "epoch": 0.8947368421052632,
    "step": 3570
  },
  {
    "loss": 0.053,
    "grad_norm": 0.5159306526184082,
    "learning_rate": 7.009189640768589e-06,
    "epoch": 0.8972431077694235,
    "step": 3580
  },
  {
    "loss": 0.051,
    "grad_norm": 0.5172264575958252,
    "learning_rate": 7.0008354218880535e-06,
    "epoch": 0.899749373433584,
    "step": 3590
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.35645532608032227,
    "learning_rate": 6.992481203007519e-06,
    "epoch": 0.9022556390977443,
    "step": 3600
  },
  {
    "loss": 0.0475,
    "grad_norm": 0.38721978664398193,
    "learning_rate": 6.984126984126984e-06,
    "epoch": 0.9047619047619048,
    "step": 3610
  },
  {
    "loss": 0.0507,
    "grad_norm": 0.383597731590271,
    "learning_rate": 6.9757727652464506e-06,
    "epoch": 0.9072681704260651,
    "step": 3620
  },
  {
    "loss": 0.0385,
    "grad_norm": 0.5144876837730408,
    "learning_rate": 6.9674185463659146e-06,
    "epoch": 0.9097744360902256,
    "step": 3630
  },
  {
    "loss": 0.041,
    "grad_norm": 0.5713372826576233,
    "learning_rate": 6.959064327485381e-06,
    "epoch": 0.9122807017543859,
    "step": 3640
  },
  {
    "loss": 0.0479,
    "grad_norm": 0.2728078365325928,
    "learning_rate": 6.950710108604846e-06,
    "epoch": 0.9147869674185464,
    "step": 3650
  },
  {
    "loss": 0.0493,
    "grad_norm": 0.29699087142944336,
    "learning_rate": 6.942355889724312e-06,
    "epoch": 0.9172932330827067,
    "step": 3660
  },
  {
    "loss": 0.0409,
    "grad_norm": 0.4677264392375946,
    "learning_rate": 6.9340016708437765e-06,
    "epoch": 0.9197994987468672,
    "step": 3670
  },
  {
    "loss": 0.0355,
    "grad_norm": 0.22407130897045135,
    "learning_rate": 6.925647451963242e-06,
    "epoch": 0.9223057644110275,
    "step": 3680
  },
  {
    "loss": 0.0435,
    "grad_norm": 0.4848649203777313,
    "learning_rate": 6.917293233082707e-06,
    "epoch": 0.924812030075188,
    "step": 3690
  },
  {
    "loss": 0.0381,
    "grad_norm": 0.36884716153144836,
    "learning_rate": 6.908939014202173e-06,
    "epoch": 0.9273182957393483,
    "step": 3700
  },
  {
    "loss": 0.046,
    "grad_norm": 0.26424163579940796,
    "learning_rate": 6.9005847953216375e-06,
    "epoch": 0.9298245614035088,
    "step": 3710
  },
  {
    "loss": 0.0462,
    "grad_norm": 0.39572256803512573,
    "learning_rate": 6.892230576441103e-06,
    "epoch": 0.9323308270676691,
    "step": 3720
  },
  {
    "loss": 0.0451,
    "grad_norm": 0.166570782661438,
    "learning_rate": 6.883876357560568e-06,
    "epoch": 0.9348370927318296,
    "step": 3730
  },
  {
    "loss": 0.0396,
    "grad_norm": 0.24598756432533264,
    "learning_rate": 6.875522138680034e-06,
    "epoch": 0.9373433583959899,
    "step": 3740
  },
  {
    "loss": 0.0384,
    "grad_norm": 0.6550189852714539,
    "learning_rate": 6.867167919799499e-06,
    "epoch": 0.9398496240601504,
    "step": 3750
  },
  {
    "eval_loss": 0.040798213332891464,
    "eval_roc_auc_macro": 0.9856548368007784,
    "eval_runtime": 40.029,
    "eval_samples_per_second": 797.298,
    "eval_steps_per_second": 24.932,
    "epoch": 0.9398496240601504,
    "step": 3750
  },
  {
    "train_loss": 0.03799084201455116,
    "train_roc_auc_macro": 0.9865394314268757,
    "train_runtime": 159.91,
    "train_samples_per_second": 798.299,
    "train_steps_per_second": 24.952,
    "epoch": 0.9398496240601504,
    "step": 3750
  },
  {
    "loss": 0.0438,
    "grad_norm": 0.4990778863430023,
    "learning_rate": 6.858813700918965e-06,
    "epoch": 0.9423558897243107,
    "step": 3760
  },
  {
    "loss": 0.0505,
    "grad_norm": 0.7663307785987854,
    "learning_rate": 6.85045948203843e-06,
    "epoch": 0.9448621553884712,
    "step": 3770
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.7710272669792175,
    "learning_rate": 6.842105263157896e-06,
    "epoch": 0.9473684210526315,
    "step": 3780
  },
  {
    "loss": 0.0375,
    "grad_norm": 0.6020576357841492,
    "learning_rate": 6.8337510442773605e-06,
    "epoch": 0.949874686716792,
    "step": 3790
  },
  {
    "loss": 0.051,
    "grad_norm": 0.6733189821243286,
    "learning_rate": 6.825396825396826e-06,
    "epoch": 0.9523809523809523,
    "step": 3800
  },
  {
    "loss": 0.0382,
    "grad_norm": 0.3342191278934479,
    "learning_rate": 6.817042606516291e-06,
    "epoch": 0.9548872180451128,
    "step": 3810
  },
  {
    "loss": 0.0221,
    "grad_norm": 0.22665376961231232,
    "learning_rate": 6.808688387635757e-06,
    "epoch": 0.9573934837092731,
    "step": 3820
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.23741039633750916,
    "learning_rate": 6.8003341687552216e-06,
    "epoch": 0.9598997493734336,
    "step": 3830
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.4437296688556671,
    "learning_rate": 6.791979949874687e-06,
    "epoch": 0.9624060150375939,
    "step": 3840
  },
  {
    "loss": 0.0305,
    "grad_norm": 0.47698095440864563,
    "learning_rate": 6.783625730994152e-06,
    "epoch": 0.9649122807017544,
    "step": 3850
  },
  {
    "loss": 0.0436,
    "grad_norm": 0.39895930886268616,
    "learning_rate": 6.775271512113618e-06,
    "epoch": 0.9674185463659147,
    "step": 3860
  },
  {
    "loss": 0.0364,
    "grad_norm": 0.33953607082366943,
    "learning_rate": 6.766917293233083e-06,
    "epoch": 0.9699248120300752,
    "step": 3870
  },
  {
    "loss": 0.044,
    "grad_norm": 0.3816664218902588,
    "learning_rate": 6.758563074352549e-06,
    "epoch": 0.9724310776942355,
    "step": 3880
  },
  {
    "loss": 0.0474,
    "grad_norm": 0.4799041748046875,
    "learning_rate": 6.750208855472013e-06,
    "epoch": 0.974937343358396,
    "step": 3890
  },
  {
    "loss": 0.0295,
    "grad_norm": 0.693881094455719,
    "learning_rate": 6.74185463659148e-06,
    "epoch": 0.9774436090225563,
    "step": 3900
  },
  {
    "loss": 0.0387,
    "grad_norm": 0.3236173093318939,
    "learning_rate": 6.7335004177109445e-06,
    "epoch": 0.9799498746867168,
    "step": 3910
  },
  {
    "loss": 0.0271,
    "grad_norm": 0.8515500426292419,
    "learning_rate": 6.72514619883041e-06,
    "epoch": 0.9824561403508771,
    "step": 3920
  },
  {
    "loss": 0.0556,
    "grad_norm": 0.22671905159950256,
    "learning_rate": 6.716791979949875e-06,
    "epoch": 0.9849624060150376,
    "step": 3930
  },
  {
    "loss": 0.0455,
    "grad_norm": 0.26819464564323425,
    "learning_rate": 6.708437761069341e-06,
    "epoch": 0.9874686716791979,
    "step": 3940
  },
  {
    "loss": 0.0412,
    "grad_norm": 0.15322867035865784,
    "learning_rate": 6.700083542188806e-06,
    "epoch": 0.9899749373433584,
    "step": 3950
  },
  {
    "loss": 0.0563,
    "grad_norm": 0.42693641781806946,
    "learning_rate": 6.691729323308271e-06,
    "epoch": 0.9924812030075187,
    "step": 3960
  },
  {
    "loss": 0.0326,
    "grad_norm": 0.683583676815033,
    "learning_rate": 6.683375104427736e-06,
    "epoch": 0.9949874686716792,
    "step": 3970
  },
  {
    "loss": 0.048,
    "grad_norm": 1.0723397731781006,
    "learning_rate": 6.675020885547202e-06,
    "epoch": 0.9974937343358395,
    "step": 3980
  },
  {
    "loss": 0.0395,
    "grad_norm": 0.8446420431137085,
    "learning_rate": 6.666666666666667e-06,
    "epoch": 1.0,
    "step": 3990
  },
  {
    "loss": 0.0359,
    "grad_norm": 0.56746506690979,
    "learning_rate": 6.658312447786132e-06,
    "epoch": 1.0025062656641603,
    "step": 4000
  },
  {
    "eval_loss": 0.04107813164591789,
    "eval_roc_auc_macro": 0.9856512644034767,
    "eval_runtime": 40.1521,
    "eval_samples_per_second": 794.853,
    "eval_steps_per_second": 24.855,
    "epoch": 1.0025062656641603,
    "step": 4000
  },
  {
    "train_loss": 0.03825928270816803,
    "train_roc_auc_macro": 0.9864159898255195,
    "train_runtime": 160.3906,
    "train_samples_per_second": 795.907,
    "train_steps_per_second": 24.877,
    "epoch": 1.0025062656641603,
    "step": 4000
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.4490790367126465,
    "learning_rate": 6.649958228905597e-06,
    "epoch": 1.0050125313283207,
    "step": 4010
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.5686764717102051,
    "learning_rate": 6.641604010025064e-06,
    "epoch": 1.0075187969924813,
    "step": 4020
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.25419995188713074,
    "learning_rate": 6.6332497911445286e-06,
    "epoch": 1.0100250626566416,
    "step": 4030
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.20768781006336212,
    "learning_rate": 6.624895572263994e-06,
    "epoch": 1.012531328320802,
    "step": 4040
  },
  {
    "loss": 0.0327,
    "grad_norm": 0.28116071224212646,
    "learning_rate": 6.616541353383459e-06,
    "epoch": 1.0150375939849625,
    "step": 4050
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.47317302227020264,
    "learning_rate": 6.608187134502925e-06,
    "epoch": 1.0175438596491229,
    "step": 4060
  },
  {
    "loss": 0.0439,
    "grad_norm": 0.3177763521671295,
    "learning_rate": 6.59983291562239e-06,
    "epoch": 1.0200501253132832,
    "step": 4070
  },
  {
    "loss": 0.0384,
    "grad_norm": 0.48610419034957886,
    "learning_rate": 6.591478696741855e-06,
    "epoch": 1.0225563909774436,
    "step": 4080
  },
  {
    "loss": 0.0505,
    "grad_norm": 0.5731077790260315,
    "learning_rate": 6.58312447786132e-06,
    "epoch": 1.025062656641604,
    "step": 4090
  },
  {
    "loss": 0.0464,
    "grad_norm": 0.9228944778442383,
    "learning_rate": 6.574770258980786e-06,
    "epoch": 1.0275689223057645,
    "step": 4100
  },
  {
    "loss": 0.0354,
    "grad_norm": 0.3367563486099243,
    "learning_rate": 6.566416040100251e-06,
    "epoch": 1.0300751879699248,
    "step": 4110
  },
  {
    "loss": 0.0306,
    "grad_norm": 0.09074387699365616,
    "learning_rate": 6.558061821219716e-06,
    "epoch": 1.0325814536340852,
    "step": 4120
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.46940624713897705,
    "learning_rate": 6.549707602339181e-06,
    "epoch": 1.0350877192982457,
    "step": 4130
  },
  {
    "loss": 0.0335,
    "grad_norm": 0.45923927426338196,
    "learning_rate": 6.541353383458648e-06,
    "epoch": 1.037593984962406,
    "step": 4140
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.6605537533760071,
    "learning_rate": 6.532999164578112e-06,
    "epoch": 1.0401002506265664,
    "step": 4150
  },
  {
    "loss": 0.0352,
    "grad_norm": 0.20958872139453888,
    "learning_rate": 6.524644945697578e-06,
    "epoch": 1.0426065162907268,
    "step": 4160
  },
  {
    "loss": 0.039,
    "grad_norm": 0.3715447187423706,
    "learning_rate": 6.516290726817043e-06,
    "epoch": 1.045112781954887,
    "step": 4170
  },
  {
    "loss": 0.0448,
    "grad_norm": 0.4865051209926605,
    "learning_rate": 6.507936507936509e-06,
    "epoch": 1.0476190476190477,
    "step": 4180
  },
  {
    "loss": 0.0267,
    "grad_norm": 0.2841433882713318,
    "learning_rate": 6.499582289055974e-06,
    "epoch": 1.050125313283208,
    "step": 4190
  },
  {
    "loss": 0.035,
    "grad_norm": 0.3013745844364166,
    "learning_rate": 6.491228070175439e-06,
    "epoch": 1.0526315789473684,
    "step": 4200
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.5134321451187134,
    "learning_rate": 6.482873851294904e-06,
    "epoch": 1.055137844611529,
    "step": 4210
  },
  {
    "loss": 0.0354,
    "grad_norm": 0.29570770263671875,
    "learning_rate": 6.47451963241437e-06,
    "epoch": 1.0576441102756893,
    "step": 4220
  },
  {
    "loss": 0.0413,
    "grad_norm": 0.5304464101791382,
    "learning_rate": 6.466165413533835e-06,
    "epoch": 1.0601503759398496,
    "step": 4230
  },
  {
    "loss": 0.0471,
    "grad_norm": 1.0245513916015625,
    "learning_rate": 6.4578111946533e-06,
    "epoch": 1.06265664160401,
    "step": 4240
  },
  {
    "loss": 0.0269,
    "grad_norm": 0.25895580649375916,
    "learning_rate": 6.449456975772765e-06,
    "epoch": 1.0651629072681703,
    "step": 4250
  },
  {
    "eval_loss": 0.03968244418501854,
    "eval_roc_auc_macro": 0.9863468042864518,
    "eval_runtime": 40.1832,
    "eval_samples_per_second": 794.236,
    "eval_steps_per_second": 24.836,
    "epoch": 1.0651629072681703,
    "step": 4250
  },
  {
    "train_loss": 0.03607602417469025,
    "train_roc_auc_macro": 0.9864622436753384,
    "train_runtime": 160.2976,
    "train_samples_per_second": 796.369,
    "train_steps_per_second": 24.891,
    "epoch": 1.0651629072681703,
    "step": 4250
  },
  {
    "loss": 0.049,
    "grad_norm": 0.45188266038894653,
    "learning_rate": 6.441102756892231e-06,
    "epoch": 1.0676691729323309,
    "step": 4260
  },
  {
    "loss": 0.0488,
    "grad_norm": 0.5007519125938416,
    "learning_rate": 6.432748538011696e-06,
    "epoch": 1.0701754385964912,
    "step": 4270
  },
  {
    "loss": 0.031,
    "grad_norm": 0.3903917372226715,
    "learning_rate": 6.424394319131162e-06,
    "epoch": 1.0726817042606516,
    "step": 4280
  },
  {
    "loss": 0.0417,
    "grad_norm": 0.8093329668045044,
    "learning_rate": 6.416040100250627e-06,
    "epoch": 1.0751879699248121,
    "step": 4290
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.3681328296661377,
    "learning_rate": 6.407685881370093e-06,
    "epoch": 1.0776942355889725,
    "step": 4300
  },
  {
    "loss": 0.043,
    "grad_norm": 0.3247831463813782,
    "learning_rate": 6.399331662489558e-06,
    "epoch": 1.0802005012531328,
    "step": 4310
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.5984863638877869,
    "learning_rate": 6.390977443609023e-06,
    "epoch": 1.0827067669172932,
    "step": 4320
  },
  {
    "loss": 0.0414,
    "grad_norm": 0.3739526867866516,
    "learning_rate": 6.382623224728488e-06,
    "epoch": 1.0852130325814535,
    "step": 4330
  },
  {
    "loss": 0.0273,
    "grad_norm": 0.18421514332294464,
    "learning_rate": 6.374269005847954e-06,
    "epoch": 1.087719298245614,
    "step": 4340
  },
  {
    "loss": 0.0402,
    "grad_norm": 0.49487224221229553,
    "learning_rate": 6.365914786967419e-06,
    "epoch": 1.0902255639097744,
    "step": 4350
  },
  {
    "loss": 0.0468,
    "grad_norm": 0.3242258131504059,
    "learning_rate": 6.3575605680868844e-06,
    "epoch": 1.0927318295739348,
    "step": 4360
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.5889577865600586,
    "learning_rate": 6.349206349206349e-06,
    "epoch": 1.0952380952380953,
    "step": 4370
  },
  {
    "loss": 0.0437,
    "grad_norm": 0.8117478489875793,
    "learning_rate": 6.340852130325815e-06,
    "epoch": 1.0977443609022557,
    "step": 4380
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.5593594908714294,
    "learning_rate": 6.33249791144528e-06,
    "epoch": 1.100250626566416,
    "step": 4390
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.5625436305999756,
    "learning_rate": 6.324143692564746e-06,
    "epoch": 1.1027568922305764,
    "step": 4400
  },
  {
    "loss": 0.0522,
    "grad_norm": 0.4477474093437195,
    "learning_rate": 6.31578947368421e-06,
    "epoch": 1.1052631578947367,
    "step": 4410
  },
  {
    "loss": 0.0438,
    "grad_norm": 0.521310567855835,
    "learning_rate": 6.307435254803677e-06,
    "epoch": 1.1077694235588973,
    "step": 4420
  },
  {
    "loss": 0.0489,
    "grad_norm": 0.39288392663002014,
    "learning_rate": 6.299081035923142e-06,
    "epoch": 1.1102756892230576,
    "step": 4430
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.6047528982162476,
    "learning_rate": 6.290726817042607e-06,
    "epoch": 1.112781954887218,
    "step": 4440
  },
  {
    "loss": 0.05,
    "grad_norm": 0.6544190049171448,
    "learning_rate": 6.282372598162072e-06,
    "epoch": 1.1152882205513786,
    "step": 4450
  },
  {
    "loss": 0.0404,
    "grad_norm": 0.28339627385139465,
    "learning_rate": 6.274018379281538e-06,
    "epoch": 1.117794486215539,
    "step": 4460
  },
  {
    "loss": 0.0277,
    "grad_norm": 0.4010413885116577,
    "learning_rate": 6.265664160401003e-06,
    "epoch": 1.1203007518796992,
    "step": 4470
  },
  {
    "loss": 0.0338,
    "grad_norm": 0.4535258710384369,
    "learning_rate": 6.2573099415204685e-06,
    "epoch": 1.1228070175438596,
    "step": 4480
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.8146612048149109,
    "learning_rate": 6.248955722639933e-06,
    "epoch": 1.12531328320802,
    "step": 4490
  },
  {
    "loss": 0.042,
    "grad_norm": 0.3181295394897461,
    "learning_rate": 6.240601503759399e-06,
    "epoch": 1.1278195488721805,
    "step": 4500
  },
  {
    "eval_loss": 0.038804128766059875,
    "eval_roc_auc_macro": 0.9870618476526435,
    "eval_runtime": 40.1559,
    "eval_samples_per_second": 794.777,
    "eval_steps_per_second": 24.853,
    "epoch": 1.1278195488721805,
    "step": 4500
  },
  {
    "train_loss": 0.03527136147022247,
    "train_roc_auc_macro": 0.9882140026961465,
    "train_runtime": 160.3511,
    "train_samples_per_second": 796.103,
    "train_steps_per_second": 24.883,
    "epoch": 1.1278195488721805,
    "step": 4500
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.42919066548347473,
    "learning_rate": 6.232247284878864e-06,
    "epoch": 1.1303258145363408,
    "step": 4510
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.7700753211975098,
    "learning_rate": 6.2238930659983295e-06,
    "epoch": 1.1328320802005012,
    "step": 4520
  },
  {
    "loss": 0.0448,
    "grad_norm": 0.38973817229270935,
    "learning_rate": 6.215538847117794e-06,
    "epoch": 1.1353383458646618,
    "step": 4530
  },
  {
    "loss": 0.0346,
    "grad_norm": 0.24248597025871277,
    "learning_rate": 6.207184628237261e-06,
    "epoch": 1.137844611528822,
    "step": 4540
  },
  {
    "loss": 0.0378,
    "grad_norm": 0.3626902997493744,
    "learning_rate": 6.198830409356725e-06,
    "epoch": 1.1403508771929824,
    "step": 4550
  },
  {
    "loss": 0.0456,
    "grad_norm": 1.2020888328552246,
    "learning_rate": 6.1904761904761914e-06,
    "epoch": 1.1428571428571428,
    "step": 4560
  },
  {
    "loss": 0.0518,
    "grad_norm": 0.486674427986145,
    "learning_rate": 6.182121971595656e-06,
    "epoch": 1.1453634085213031,
    "step": 4570
  },
  {
    "loss": 0.0385,
    "grad_norm": 0.6039485335350037,
    "learning_rate": 6.173767752715122e-06,
    "epoch": 1.1478696741854637,
    "step": 4580
  },
  {
    "loss": 0.0433,
    "grad_norm": 0.5025339722633362,
    "learning_rate": 6.165413533834587e-06,
    "epoch": 1.150375939849624,
    "step": 4590
  },
  {
    "loss": 0.0288,
    "grad_norm": 0.12310392409563065,
    "learning_rate": 6.1570593149540525e-06,
    "epoch": 1.1528822055137844,
    "step": 4600
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.5916838049888611,
    "learning_rate": 6.148705096073517e-06,
    "epoch": 1.155388471177945,
    "step": 4610
  },
  {
    "loss": 0.0425,
    "grad_norm": 0.49967721104621887,
    "learning_rate": 6.140350877192983e-06,
    "epoch": 1.1578947368421053,
    "step": 4620
  },
  {
    "loss": 0.0366,
    "grad_norm": 0.09912128746509552,
    "learning_rate": 6.131996658312448e-06,
    "epoch": 1.1604010025062657,
    "step": 4630
  },
  {
    "loss": 0.0354,
    "grad_norm": 0.25486478209495544,
    "learning_rate": 6.1236424394319135e-06,
    "epoch": 1.162907268170426,
    "step": 4640
  },
  {
    "loss": 0.0391,
    "grad_norm": 0.5077267289161682,
    "learning_rate": 6.115288220551378e-06,
    "epoch": 1.1654135338345863,
    "step": 4650
  },
  {
    "loss": 0.0441,
    "grad_norm": 0.4830837547779083,
    "learning_rate": 6.106934001670844e-06,
    "epoch": 1.167919799498747,
    "step": 4660
  },
  {
    "loss": 0.0375,
    "grad_norm": 0.03583129122853279,
    "learning_rate": 6.098579782790309e-06,
    "epoch": 1.1704260651629073,
    "step": 4670
  },
  {
    "loss": 0.0386,
    "grad_norm": 0.7586148977279663,
    "learning_rate": 6.0902255639097755e-06,
    "epoch": 1.1729323308270676,
    "step": 4680
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.7471466660499573,
    "learning_rate": 6.08187134502924e-06,
    "epoch": 1.1754385964912282,
    "step": 4690
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.30257806181907654,
    "learning_rate": 6.073517126148706e-06,
    "epoch": 1.1779448621553885,
    "step": 4700
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.5836167931556702,
    "learning_rate": 6.065162907268171e-06,
    "epoch": 1.1804511278195489,
    "step": 4710
  },
  {
    "loss": 0.0386,
    "grad_norm": 0.4118351638317108,
    "learning_rate": 6.0568086883876365e-06,
    "epoch": 1.1829573934837092,
    "step": 4720
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.8901023268699646,
    "learning_rate": 6.048454469507101e-06,
    "epoch": 1.1854636591478696,
    "step": 4730
  },
  {
    "loss": 0.0447,
    "grad_norm": 0.7330406904220581,
    "learning_rate": 6.040100250626567e-06,
    "epoch": 1.1879699248120301,
    "step": 4740
  },
  {
    "loss": 0.0332,
    "grad_norm": 0.21519796550273895,
    "learning_rate": 6.031746031746032e-06,
    "epoch": 1.1904761904761905,
    "step": 4750
  },
  {
    "eval_loss": 0.03865841031074524,
    "eval_roc_auc_macro": 0.9867034779856806,
    "eval_runtime": 40.1329,
    "eval_samples_per_second": 795.233,
    "eval_steps_per_second": 24.867,
    "epoch": 1.1904761904761905,
    "step": 4750
  },
  {
    "train_loss": 0.03540739789605141,
    "train_roc_auc_macro": 0.9883849951077051,
    "train_runtime": 160.1816,
    "train_samples_per_second": 796.946,
    "train_steps_per_second": 24.909,
    "epoch": 1.1904761904761905,
    "step": 4750
  },
  {
    "loss": 0.0391,
    "grad_norm": 0.33336976170539856,
    "learning_rate": 6.023391812865498e-06,
    "epoch": 1.1929824561403508,
    "step": 4760
  },
  {
    "loss": 0.0397,
    "grad_norm": 0.9290540218353271,
    "learning_rate": 6.015037593984962e-06,
    "epoch": 1.1954887218045114,
    "step": 4770
  },
  {
    "loss": 0.0379,
    "grad_norm": 0.4012543857097626,
    "learning_rate": 6.006683375104428e-06,
    "epoch": 1.1979949874686717,
    "step": 4780
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.6571126580238342,
    "learning_rate": 5.998329156223893e-06,
    "epoch": 1.200501253132832,
    "step": 4790
  },
  {
    "loss": 0.0333,
    "grad_norm": 0.3622584640979767,
    "learning_rate": 5.9899749373433595e-06,
    "epoch": 1.2030075187969924,
    "step": 4800
  },
  {
    "loss": 0.0475,
    "grad_norm": 0.4045959413051605,
    "learning_rate": 5.9816207184628235e-06,
    "epoch": 1.2055137844611528,
    "step": 4810
  },
  {
    "loss": 0.0457,
    "grad_norm": 0.7909560799598694,
    "learning_rate": 5.97326649958229e-06,
    "epoch": 1.2080200501253133,
    "step": 4820
  },
  {
    "loss": 0.0416,
    "grad_norm": 0.6823650598526001,
    "learning_rate": 5.964912280701755e-06,
    "epoch": 1.2105263157894737,
    "step": 4830
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.22924251854419708,
    "learning_rate": 5.9565580618212205e-06,
    "epoch": 1.213032581453634,
    "step": 4840
  },
  {
    "loss": 0.034,
    "grad_norm": 0.6178516149520874,
    "learning_rate": 5.948203842940685e-06,
    "epoch": 1.2155388471177946,
    "step": 4850
  },
  {
    "loss": 0.0442,
    "grad_norm": 0.336503267288208,
    "learning_rate": 5.939849624060151e-06,
    "epoch": 1.218045112781955,
    "step": 4860
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.3077813982963562,
    "learning_rate": 5.931495405179616e-06,
    "epoch": 1.2205513784461153,
    "step": 4870
  },
  {
    "loss": 0.0256,
    "grad_norm": 0.7995824813842773,
    "learning_rate": 5.923141186299082e-06,
    "epoch": 1.2230576441102756,
    "step": 4880
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.20423871278762817,
    "learning_rate": 5.9147869674185465e-06,
    "epoch": 1.225563909774436,
    "step": 4890
  },
  {
    "loss": 0.0496,
    "grad_norm": 0.48927754163742065,
    "learning_rate": 5.906432748538012e-06,
    "epoch": 1.2280701754385965,
    "step": 4900
  },
  {
    "loss": 0.0346,
    "grad_norm": 0.37747976183891296,
    "learning_rate": 5.898078529657477e-06,
    "epoch": 1.2305764411027569,
    "step": 4910
  },
  {
    "loss": 0.0239,
    "grad_norm": 0.14514940977096558,
    "learning_rate": 5.889724310776943e-06,
    "epoch": 1.2330827067669172,
    "step": 4920
  },
  {
    "loss": 0.0332,
    "grad_norm": 0.6295230984687805,
    "learning_rate": 5.8813700918964075e-06,
    "epoch": 1.2355889724310778,
    "step": 4930
  },
  {
    "loss": 0.0491,
    "grad_norm": 0.6186471581459045,
    "learning_rate": 5.873015873015874e-06,
    "epoch": 1.2380952380952381,
    "step": 4940
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.4041522145271301,
    "learning_rate": 5.864661654135339e-06,
    "epoch": 1.2406015037593985,
    "step": 4950
  },
  {
    "loss": 0.0268,
    "grad_norm": 0.34863024950027466,
    "learning_rate": 5.856307435254805e-06,
    "epoch": 1.2431077694235588,
    "step": 4960
  },
  {
    "loss": 0.0265,
    "grad_norm": 0.5035917162895203,
    "learning_rate": 5.847953216374269e-06,
    "epoch": 1.2456140350877192,
    "step": 4970
  },
  {
    "loss": 0.0348,
    "grad_norm": 0.2816225588321686,
    "learning_rate": 5.839598997493735e-06,
    "epoch": 1.2481203007518797,
    "step": 4980
  },
  {
    "loss": 0.0368,
    "grad_norm": 0.3919313848018646,
    "learning_rate": 5.8312447786132e-06,
    "epoch": 1.25062656641604,
    "step": 4990
  },
  {
    "loss": 0.0271,
    "grad_norm": 0.3926771879196167,
    "learning_rate": 5.822890559732666e-06,
    "epoch": 1.2531328320802004,
    "step": 5000
  },
  {
    "eval_loss": 0.03987927734851837,
    "eval_roc_auc_macro": 0.9856245560051101,
    "eval_runtime": 40.1359,
    "eval_samples_per_second": 795.173,
    "eval_steps_per_second": 24.865,
    "epoch": 1.2531328320802004,
    "step": 5000
  },
  {
    "train_loss": 0.03538193181157112,
    "train_roc_auc_macro": 0.9878372602096204,
    "train_runtime": 160.1431,
    "train_samples_per_second": 797.137,
    "train_steps_per_second": 24.915,
    "epoch": 1.2531328320802004,
    "step": 5000
  },
  {
    "loss": 0.0417,
    "grad_norm": 0.569895327091217,
    "learning_rate": 5.8145363408521305e-06,
    "epoch": 1.255639097744361,
    "step": 5010
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.3076859414577484,
    "learning_rate": 5.806182121971596e-06,
    "epoch": 1.2581453634085213,
    "step": 5020
  },
  {
    "loss": 0.0399,
    "grad_norm": 0.5576054453849792,
    "learning_rate": 5.797827903091061e-06,
    "epoch": 1.2606516290726817,
    "step": 5030
  },
  {
    "loss": 0.0276,
    "grad_norm": 0.3751646876335144,
    "learning_rate": 5.789473684210527e-06,
    "epoch": 1.263157894736842,
    "step": 5040
  },
  {
    "loss": 0.031,
    "grad_norm": 0.36881664395332336,
    "learning_rate": 5.7811194653299915e-06,
    "epoch": 1.2656641604010024,
    "step": 5050
  },
  {
    "loss": 0.0387,
    "grad_norm": 0.5908041000366211,
    "learning_rate": 5.772765246449458e-06,
    "epoch": 1.268170426065163,
    "step": 5060
  },
  {
    "loss": 0.0442,
    "grad_norm": 0.7585870027542114,
    "learning_rate": 5.764411027568922e-06,
    "epoch": 1.2706766917293233,
    "step": 5070
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.32745662331581116,
    "learning_rate": 5.756056808688389e-06,
    "epoch": 1.2731829573934836,
    "step": 5080
  },
  {
    "loss": 0.0355,
    "grad_norm": 0.21066634356975555,
    "learning_rate": 5.7477025898078535e-06,
    "epoch": 1.2756892230576442,
    "step": 5090
  },
  {
    "loss": 0.0305,
    "grad_norm": 0.44828659296035767,
    "learning_rate": 5.739348370927319e-06,
    "epoch": 1.2781954887218046,
    "step": 5100
  },
  {
    "loss": 0.032,
    "grad_norm": 0.3683274984359741,
    "learning_rate": 5.730994152046784e-06,
    "epoch": 1.280701754385965,
    "step": 5110
  },
  {
    "loss": 0.0392,
    "grad_norm": 0.35214224457740784,
    "learning_rate": 5.72263993316625e-06,
    "epoch": 1.2832080200501252,
    "step": 5120
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.4425436854362488,
    "learning_rate": 5.7142857142857145e-06,
    "epoch": 1.2857142857142856,
    "step": 5130
  },
  {
    "loss": 0.04,
    "grad_norm": 0.24328498542308807,
    "learning_rate": 5.70593149540518e-06,
    "epoch": 1.2882205513784462,
    "step": 5140
  },
  {
    "loss": 0.0279,
    "grad_norm": 0.6190058588981628,
    "learning_rate": 5.697577276524645e-06,
    "epoch": 1.2907268170426065,
    "step": 5150
  },
  {
    "loss": 0.0488,
    "grad_norm": 0.5420510172843933,
    "learning_rate": 5.689223057644111e-06,
    "epoch": 1.2932330827067668,
    "step": 5160
  },
  {
    "loss": 0.0464,
    "grad_norm": 0.18656444549560547,
    "learning_rate": 5.6808688387635756e-06,
    "epoch": 1.2957393483709274,
    "step": 5170
  },
  {
    "loss": 0.0447,
    "grad_norm": 0.3813302218914032,
    "learning_rate": 5.672514619883041e-06,
    "epoch": 1.2982456140350878,
    "step": 5180
  },
  {
    "loss": 0.0499,
    "grad_norm": 0.39146777987480164,
    "learning_rate": 5.664160401002506e-06,
    "epoch": 1.300751879699248,
    "step": 5190
  },
  {
    "loss": 0.0253,
    "grad_norm": 0.1451311856508255,
    "learning_rate": 5.655806182121973e-06,
    "epoch": 1.3032581453634084,
    "step": 5200
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.176656112074852,
    "learning_rate": 5.6474519632414375e-06,
    "epoch": 1.3057644110275688,
    "step": 5210
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.19058957695960999,
    "learning_rate": 5.639097744360903e-06,
    "epoch": 1.3082706766917294,
    "step": 5220
  },
  {
    "loss": 0.0363,
    "grad_norm": 0.5392745733261108,
    "learning_rate": 5.630743525480368e-06,
    "epoch": 1.3107769423558897,
    "step": 5230
  },
  {
    "loss": 0.0366,
    "grad_norm": 0.44648632407188416,
    "learning_rate": 5.622389306599834e-06,
    "epoch": 1.31328320802005,
    "step": 5240
  },
  {
    "loss": 0.037,
    "grad_norm": 0.4151048958301544,
    "learning_rate": 5.6140350877192985e-06,
    "epoch": 1.3157894736842106,
    "step": 5250
  },
  {
    "eval_loss": 0.03975771740078926,
    "eval_roc_auc_macro": 0.9873562597959507,
    "eval_runtime": 40.0731,
    "eval_samples_per_second": 796.42,
    "eval_steps_per_second": 24.904,
    "epoch": 1.3157894736842106,
    "step": 5250
  },
  {
    "train_loss": 0.035763952881097794,
    "train_roc_auc_macro": 0.988943990881234,
    "train_runtime": 160.2194,
    "train_samples_per_second": 796.758,
    "train_steps_per_second": 24.903,
    "epoch": 1.3157894736842106,
    "step": 5250
  },
  {
    "loss": 0.035,
    "grad_norm": 0.2327147275209427,
    "learning_rate": 5.605680868838764e-06,
    "epoch": 1.318295739348371,
    "step": 5260
  },
  {
    "loss": 0.0378,
    "grad_norm": 0.21059326827526093,
    "learning_rate": 5.597326649958229e-06,
    "epoch": 1.3208020050125313,
    "step": 5270
  },
  {
    "loss": 0.0396,
    "grad_norm": 0.41347235441207886,
    "learning_rate": 5.588972431077695e-06,
    "epoch": 1.3233082706766917,
    "step": 5280
  },
  {
    "loss": 0.0438,
    "grad_norm": 0.4944988191127777,
    "learning_rate": 5.58061821219716e-06,
    "epoch": 1.325814536340852,
    "step": 5290
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.9380417466163635,
    "learning_rate": 5.572263993316625e-06,
    "epoch": 1.3283208020050126,
    "step": 5300
  },
  {
    "loss": 0.0302,
    "grad_norm": 0.4762740731239319,
    "learning_rate": 5.56390977443609e-06,
    "epoch": 1.330827067669173,
    "step": 5310
  },
  {
    "loss": 0.0472,
    "grad_norm": 1.0100547075271606,
    "learning_rate": 5.555555555555557e-06,
    "epoch": 1.3333333333333333,
    "step": 5320
  },
  {
    "loss": 0.0509,
    "grad_norm": 0.422952264547348,
    "learning_rate": 5.547201336675021e-06,
    "epoch": 1.3358395989974938,
    "step": 5330
  },
  {
    "loss": 0.047,
    "grad_norm": 0.6649206280708313,
    "learning_rate": 5.538847117794487e-06,
    "epoch": 1.3383458646616542,
    "step": 5340
  },
  {
    "loss": 0.0386,
    "grad_norm": 0.5361868739128113,
    "learning_rate": 5.530492898913952e-06,
    "epoch": 1.3408521303258145,
    "step": 5350
  },
  {
    "loss": 0.04,
    "grad_norm": 0.8672096133232117,
    "learning_rate": 5.522138680033418e-06,
    "epoch": 1.3433583959899749,
    "step": 5360
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.6411358714103699,
    "learning_rate": 5.5137844611528826e-06,
    "epoch": 1.3458646616541352,
    "step": 5370
  },
  {
    "loss": 0.0355,
    "grad_norm": 0.4857752025127411,
    "learning_rate": 5.505430242272348e-06,
    "epoch": 1.3483709273182958,
    "step": 5380
  },
  {
    "loss": 0.0359,
    "grad_norm": 1.4068504571914673,
    "learning_rate": 5.497076023391813e-06,
    "epoch": 1.3508771929824561,
    "step": 5390
  },
  {
    "loss": 0.0393,
    "grad_norm": 0.4862160086631775,
    "learning_rate": 5.488721804511279e-06,
    "epoch": 1.3533834586466165,
    "step": 5400
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.6303238868713379,
    "learning_rate": 5.480367585630744e-06,
    "epoch": 1.355889724310777,
    "step": 5410
  },
  {
    "loss": 0.0544,
    "grad_norm": 2.267392158508301,
    "learning_rate": 5.472013366750209e-06,
    "epoch": 1.3583959899749374,
    "step": 5420
  },
  {
    "loss": 0.0287,
    "grad_norm": 0.6025378108024597,
    "learning_rate": 5.463659147869674e-06,
    "epoch": 1.3609022556390977,
    "step": 5430
  },
  {
    "loss": 0.0574,
    "grad_norm": 0.06938894838094711,
    "learning_rate": 5.45530492898914e-06,
    "epoch": 1.363408521303258,
    "step": 5440
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.3703475594520569,
    "learning_rate": 5.446950710108605e-06,
    "epoch": 1.3659147869674184,
    "step": 5450
  },
  {
    "loss": 0.0355,
    "grad_norm": 0.5253967046737671,
    "learning_rate": 5.438596491228071e-06,
    "epoch": 1.368421052631579,
    "step": 5460
  },
  {
    "loss": 0.0402,
    "grad_norm": 0.30603307485580444,
    "learning_rate": 5.430242272347536e-06,
    "epoch": 1.3709273182957393,
    "step": 5470
  },
  {
    "loss": 0.0289,
    "grad_norm": 0.25492197275161743,
    "learning_rate": 5.421888053467002e-06,
    "epoch": 1.3734335839598997,
    "step": 5480
  },
  {
    "loss": 0.0392,
    "grad_norm": 0.42451104521751404,
    "learning_rate": 5.413533834586467e-06,
    "epoch": 1.3759398496240602,
    "step": 5490
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.45251336693763733,
    "learning_rate": 5.405179615705932e-06,
    "epoch": 1.3784461152882206,
    "step": 5500
  },
  {
    "eval_loss": 0.03877926617860794,
    "eval_roc_auc_macro": 0.9874419813330763,
    "eval_runtime": 40.0847,
    "eval_samples_per_second": 796.188,
    "eval_steps_per_second": 24.897,
    "epoch": 1.3784461152882206,
    "step": 5500
  },
  {
    "train_loss": 0.034182801842689514,
    "train_roc_auc_macro": 0.9897927824329006,
    "train_runtime": 160.4358,
    "train_samples_per_second": 795.683,
    "train_steps_per_second": 24.87,
    "epoch": 1.3784461152882206,
    "step": 5500
  },
  {
    "loss": 0.045,
    "grad_norm": 0.7251145243644714,
    "learning_rate": 5.396825396825397e-06,
    "epoch": 1.380952380952381,
    "step": 5510
  },
  {
    "loss": 0.043,
    "grad_norm": 0.333209753036499,
    "learning_rate": 5.388471177944863e-06,
    "epoch": 1.3834586466165413,
    "step": 5520
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.4179993271827698,
    "learning_rate": 5.380116959064328e-06,
    "epoch": 1.3859649122807016,
    "step": 5530
  },
  {
    "loss": 0.0275,
    "grad_norm": 0.30948808789253235,
    "learning_rate": 5.371762740183793e-06,
    "epoch": 1.3884711779448622,
    "step": 5540
  },
  {
    "loss": 0.0326,
    "grad_norm": 0.23940737545490265,
    "learning_rate": 5.363408521303258e-06,
    "epoch": 1.3909774436090225,
    "step": 5550
  },
  {
    "loss": 0.0433,
    "grad_norm": 1.4864839315414429,
    "learning_rate": 5.355054302422724e-06,
    "epoch": 1.3934837092731829,
    "step": 5560
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.20456184446811676,
    "learning_rate": 5.346700083542189e-06,
    "epoch": 1.3959899749373434,
    "step": 5570
  },
  {
    "loss": 0.0308,
    "grad_norm": 0.13698016107082367,
    "learning_rate": 5.338345864661654e-06,
    "epoch": 1.3984962406015038,
    "step": 5580
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.37930336594581604,
    "learning_rate": 5.329991645781119e-06,
    "epoch": 1.4010025062656641,
    "step": 5590
  },
  {
    "loss": 0.0355,
    "grad_norm": 0.5197480916976929,
    "learning_rate": 5.321637426900586e-06,
    "epoch": 1.4035087719298245,
    "step": 5600
  },
  {
    "loss": 0.0457,
    "grad_norm": 0.47805091738700867,
    "learning_rate": 5.313283208020051e-06,
    "epoch": 1.4060150375939848,
    "step": 5610
  },
  {
    "loss": 0.037,
    "grad_norm": 0.4807877838611603,
    "learning_rate": 5.304928989139516e-06,
    "epoch": 1.4085213032581454,
    "step": 5620
  },
  {
    "loss": 0.0466,
    "grad_norm": 0.3841250240802765,
    "learning_rate": 5.296574770258981e-06,
    "epoch": 1.4110275689223057,
    "step": 5630
  },
  {
    "loss": 0.0397,
    "grad_norm": 0.46650242805480957,
    "learning_rate": 5.288220551378447e-06,
    "epoch": 1.413533834586466,
    "step": 5640
  },
  {
    "loss": 0.0263,
    "grad_norm": 0.3898387551307678,
    "learning_rate": 5.279866332497912e-06,
    "epoch": 1.4160401002506267,
    "step": 5650
  },
  {
    "loss": 0.0308,
    "grad_norm": 0.19671271741390228,
    "learning_rate": 5.271512113617377e-06,
    "epoch": 1.418546365914787,
    "step": 5660
  },
  {
    "loss": 0.0333,
    "grad_norm": 0.10433398187160492,
    "learning_rate": 5.263157894736842e-06,
    "epoch": 1.4210526315789473,
    "step": 5670
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.5335329174995422,
    "learning_rate": 5.254803675856308e-06,
    "epoch": 1.4235588972431077,
    "step": 5680
  },
  {
    "loss": 0.0369,
    "grad_norm": 0.2794191837310791,
    "learning_rate": 5.246449456975773e-06,
    "epoch": 1.426065162907268,
    "step": 5690
  },
  {
    "loss": 0.0358,
    "grad_norm": 0.5044180750846863,
    "learning_rate": 5.2380952380952384e-06,
    "epoch": 1.4285714285714286,
    "step": 5700
  },
  {
    "loss": 0.0365,
    "grad_norm": 0.13315927982330322,
    "learning_rate": 5.229741019214703e-06,
    "epoch": 1.431077694235589,
    "step": 5710
  },
  {
    "loss": 0.0326,
    "grad_norm": 0.18683932721614838,
    "learning_rate": 5.22138680033417e-06,
    "epoch": 1.4335839598997493,
    "step": 5720
  },
  {
    "loss": 0.0367,
    "grad_norm": 0.03219602257013321,
    "learning_rate": 5.213032581453634e-06,
    "epoch": 1.4360902255639099,
    "step": 5730
  },
  {
    "loss": 0.0343,
    "grad_norm": 0.35762476921081543,
    "learning_rate": 5.2046783625731e-06,
    "epoch": 1.4385964912280702,
    "step": 5740
  },
  {
    "loss": 0.0298,
    "grad_norm": 0.8271435499191284,
    "learning_rate": 5.196324143692565e-06,
    "epoch": 1.4411027568922306,
    "step": 5750
  },
  {
    "eval_loss": 0.03925896808505058,
    "eval_roc_auc_macro": 0.9883941314996182,
    "eval_runtime": 40.2191,
    "eval_samples_per_second": 793.529,
    "eval_steps_per_second": 24.814,
    "epoch": 1.4411027568922306,
    "step": 5750
  },
  {
    "train_loss": 0.03484383597970009,
    "train_roc_auc_macro": 0.9906352252919532,
    "train_runtime": 160.2189,
    "train_samples_per_second": 796.76,
    "train_steps_per_second": 24.903,
    "epoch": 1.4411027568922306,
    "step": 5750
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.30872437357902527,
    "learning_rate": 5.187969924812031e-06,
    "epoch": 1.443609022556391,
    "step": 5760
  },
  {
    "loss": 0.0463,
    "grad_norm": 0.47017040848731995,
    "learning_rate": 5.179615705931496e-06,
    "epoch": 1.4461152882205512,
    "step": 5770
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.48826080560684204,
    "learning_rate": 5.171261487050961e-06,
    "epoch": 1.4486215538847118,
    "step": 5780
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.40343424677848816,
    "learning_rate": 5.162907268170426e-06,
    "epoch": 1.4511278195488722,
    "step": 5790
  },
  {
    "loss": 0.0547,
    "grad_norm": 1.6747814416885376,
    "learning_rate": 5.154553049289892e-06,
    "epoch": 1.4536340852130325,
    "step": 5800
  },
  {
    "loss": 0.0431,
    "grad_norm": 0.43743616342544556,
    "learning_rate": 5.146198830409357e-06,
    "epoch": 1.456140350877193,
    "step": 5810
  },
  {
    "loss": 0.0392,
    "grad_norm": 0.3128988444805145,
    "learning_rate": 5.1378446115288225e-06,
    "epoch": 1.4586466165413534,
    "step": 5820
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.5532389879226685,
    "learning_rate": 5.129490392648287e-06,
    "epoch": 1.4611528822055138,
    "step": 5830
  },
  {
    "loss": 0.0327,
    "grad_norm": 0.34920910000801086,
    "learning_rate": 5.121136173767753e-06,
    "epoch": 1.463659147869674,
    "step": 5840
  },
  {
    "loss": 0.0449,
    "grad_norm": 0.7981542944908142,
    "learning_rate": 5.112781954887218e-06,
    "epoch": 1.4661654135338344,
    "step": 5850
  },
  {
    "loss": 0.0304,
    "grad_norm": 0.25205978751182556,
    "learning_rate": 5.104427736006684e-06,
    "epoch": 1.468671679197995,
    "step": 5860
  },
  {
    "loss": 0.0355,
    "grad_norm": 0.23134474456310272,
    "learning_rate": 5.096073517126149e-06,
    "epoch": 1.4711779448621554,
    "step": 5870
  },
  {
    "loss": 0.0327,
    "grad_norm": 0.14752329885959625,
    "learning_rate": 5.087719298245615e-06,
    "epoch": 1.4736842105263157,
    "step": 5880
  },
  {
    "loss": 0.0296,
    "grad_norm": 0.2140509933233261,
    "learning_rate": 5.07936507936508e-06,
    "epoch": 1.4761904761904763,
    "step": 5890
  },
  {
    "loss": 0.0211,
    "grad_norm": 0.037240851670503616,
    "learning_rate": 5.0710108604845454e-06,
    "epoch": 1.4786967418546366,
    "step": 5900
  },
  {
    "loss": 0.0297,
    "grad_norm": 0.2697282135486603,
    "learning_rate": 5.06265664160401e-06,
    "epoch": 1.481203007518797,
    "step": 5910
  },
  {
    "loss": 0.0368,
    "grad_norm": 0.6301437020301819,
    "learning_rate": 5.054302422723476e-06,
    "epoch": 1.4837092731829573,
    "step": 5920
  },
  {
    "loss": 0.0254,
    "grad_norm": 0.25060486793518066,
    "learning_rate": 5.045948203842941e-06,
    "epoch": 1.4862155388471177,
    "step": 5930
  },
  {
    "loss": 0.032,
    "grad_norm": 0.32484981417655945,
    "learning_rate": 5.0375939849624065e-06,
    "epoch": 1.4887218045112782,
    "step": 5940
  },
  {
    "loss": 0.033,
    "grad_norm": 0.2244085967540741,
    "learning_rate": 5.029239766081871e-06,
    "epoch": 1.4912280701754386,
    "step": 5950
  },
  {
    "loss": 0.0372,
    "grad_norm": 0.3474343717098236,
    "learning_rate": 5.020885547201337e-06,
    "epoch": 1.493734335839599,
    "step": 5960
  },
  {
    "loss": 0.0486,
    "grad_norm": 0.6566636562347412,
    "learning_rate": 5.012531328320802e-06,
    "epoch": 1.4962406015037595,
    "step": 5970
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.46943211555480957,
    "learning_rate": 5.004177109440268e-06,
    "epoch": 1.4987468671679198,
    "step": 5980
  },
  {
    "loss": 0.0254,
    "grad_norm": 0.14655721187591553,
    "learning_rate": 4.995822890559732e-06,
    "epoch": 1.5012531328320802,
    "step": 5990
  },
  {
    "loss": 0.0413,
    "grad_norm": 0.29620450735092163,
    "learning_rate": 4.987468671679198e-06,
    "epoch": 1.5037593984962405,
    "step": 6000
  },
  {
    "eval_loss": 0.0384826585650444,
    "eval_roc_auc_macro": 0.988579470321803,
    "eval_runtime": 40.1841,
    "eval_samples_per_second": 794.22,
    "eval_steps_per_second": 24.836,
    "epoch": 1.5037593984962405,
    "step": 6000
  },
  {
    "train_loss": 0.03347308561205864,
    "train_roc_auc_macro": 0.9906529729974252,
    "train_runtime": 160.3109,
    "train_samples_per_second": 796.302,
    "train_steps_per_second": 24.889,
    "epoch": 1.5037593984962405,
    "step": 6000
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.47935184836387634,
    "learning_rate": 4.979114452798664e-06,
    "epoch": 1.5062656641604009,
    "step": 6010
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.462347149848938,
    "learning_rate": 4.970760233918129e-06,
    "epoch": 1.5087719298245614,
    "step": 6020
  },
  {
    "loss": 0.042,
    "grad_norm": 0.26419633626937866,
    "learning_rate": 4.962406015037594e-06,
    "epoch": 1.5112781954887218,
    "step": 6030
  },
  {
    "loss": 0.0426,
    "grad_norm": 0.6112730503082275,
    "learning_rate": 4.954051796157059e-06,
    "epoch": 1.5137844611528823,
    "step": 6040
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.13231723010540009,
    "learning_rate": 4.945697577276525e-06,
    "epoch": 1.5162907268170427,
    "step": 6050
  },
  {
    "loss": 0.0225,
    "grad_norm": 0.5067945718765259,
    "learning_rate": 4.93734335839599e-06,
    "epoch": 1.518796992481203,
    "step": 6060
  },
  {
    "loss": 0.0403,
    "grad_norm": 0.6140537858009338,
    "learning_rate": 4.928989139515455e-06,
    "epoch": 1.5213032581453634,
    "step": 6070
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.5405690670013428,
    "learning_rate": 4.920634920634921e-06,
    "epoch": 1.5238095238095237,
    "step": 6080
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.5821142196655273,
    "learning_rate": 4.912280701754386e-06,
    "epoch": 1.526315789473684,
    "step": 6090
  },
  {
    "loss": 0.0269,
    "grad_norm": 0.48169612884521484,
    "learning_rate": 4.903926482873852e-06,
    "epoch": 1.5288220551378446,
    "step": 6100
  },
  {
    "loss": 0.0489,
    "grad_norm": 1.2432036399841309,
    "learning_rate": 4.8955722639933164e-06,
    "epoch": 1.531328320802005,
    "step": 6110
  },
  {
    "loss": 0.0346,
    "grad_norm": 0.6115509271621704,
    "learning_rate": 4.887218045112782e-06,
    "epoch": 1.5338345864661656,
    "step": 6120
  },
  {
    "loss": 0.0307,
    "grad_norm": 1.2950376272201538,
    "learning_rate": 4.878863826232248e-06,
    "epoch": 1.536340852130326,
    "step": 6130
  },
  {
    "loss": 0.03,
    "grad_norm": 0.47187232971191406,
    "learning_rate": 4.870509607351713e-06,
    "epoch": 1.5388471177944862,
    "step": 6140
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.38102132081985474,
    "learning_rate": 4.862155388471178e-06,
    "epoch": 1.5413533834586466,
    "step": 6150
  },
  {
    "loss": 0.0358,
    "grad_norm": 0.5412380695343018,
    "learning_rate": 4.853801169590643e-06,
    "epoch": 1.543859649122807,
    "step": 6160
  },
  {
    "loss": 0.0451,
    "grad_norm": 0.3622116148471832,
    "learning_rate": 4.845446950710109e-06,
    "epoch": 1.5463659147869673,
    "step": 6170
  },
  {
    "loss": 0.0265,
    "grad_norm": 0.6763761639595032,
    "learning_rate": 4.837092731829574e-06,
    "epoch": 1.5488721804511278,
    "step": 6180
  },
  {
    "loss": 0.0524,
    "grad_norm": 0.456847608089447,
    "learning_rate": 4.828738512949039e-06,
    "epoch": 1.5513784461152882,
    "step": 6190
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.278265118598938,
    "learning_rate": 4.820384294068505e-06,
    "epoch": 1.5538847117794488,
    "step": 6200
  },
  {
    "loss": 0.0407,
    "grad_norm": 0.19228331744670868,
    "learning_rate": 4.81203007518797e-06,
    "epoch": 1.556390977443609,
    "step": 6210
  },
  {
    "loss": 0.0164,
    "grad_norm": 0.14219887554645538,
    "learning_rate": 4.803675856307436e-06,
    "epoch": 1.5588972431077694,
    "step": 6220
  },
  {
    "loss": 0.031,
    "grad_norm": 0.5861409902572632,
    "learning_rate": 4.7953216374269005e-06,
    "epoch": 1.5614035087719298,
    "step": 6230
  },
  {
    "loss": 0.044,
    "grad_norm": 0.532403826713562,
    "learning_rate": 4.786967418546366e-06,
    "epoch": 1.5639097744360901,
    "step": 6240
  },
  {
    "loss": 0.0368,
    "grad_norm": 0.3262796103954315,
    "learning_rate": 4.778613199665831e-06,
    "epoch": 1.5664160401002505,
    "step": 6250
  },
  {
    "eval_loss": 0.042698998004198074,
    "eval_roc_auc_macro": 0.9881792205099263,
    "eval_runtime": 40.2247,
    "eval_samples_per_second": 793.417,
    "eval_steps_per_second": 24.811,
    "epoch": 1.5664160401002505,
    "step": 6250
  },
  {
    "train_loss": 0.037882424890995026,
    "train_roc_auc_macro": 0.9905791887399987,
    "train_runtime": 160.1804,
    "train_samples_per_second": 796.951,
    "train_steps_per_second": 24.909,
    "epoch": 1.5664160401002505,
    "step": 6250
  },
  {
    "loss": 0.0279,
    "grad_norm": 0.2865510582923889,
    "learning_rate": 4.770258980785297e-06,
    "epoch": 1.568922305764411,
    "step": 6260
  },
  {
    "loss": 0.0325,
    "grad_norm": 1.0358771085739136,
    "learning_rate": 4.761904761904762e-06,
    "epoch": 1.5714285714285714,
    "step": 6270
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.374049574136734,
    "learning_rate": 4.753550543024227e-06,
    "epoch": 1.573934837092732,
    "step": 6280
  },
  {
    "loss": 0.0373,
    "grad_norm": 0.4443087577819824,
    "learning_rate": 4.745196324143693e-06,
    "epoch": 1.5764411027568923,
    "step": 6290
  },
  {
    "loss": 0.0274,
    "grad_norm": 0.23229709267616272,
    "learning_rate": 4.736842105263158e-06,
    "epoch": 1.5789473684210527,
    "step": 6300
  },
  {
    "loss": 0.041,
    "grad_norm": 0.39066413044929504,
    "learning_rate": 4.7284878863826234e-06,
    "epoch": 1.581453634085213,
    "step": 6310
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.5147201418876648,
    "learning_rate": 4.720133667502088e-06,
    "epoch": 1.5839598997493733,
    "step": 6320
  },
  {
    "loss": 0.037,
    "grad_norm": 0.42348286509513855,
    "learning_rate": 4.711779448621554e-06,
    "epoch": 1.5864661654135337,
    "step": 6330
  },
  {
    "loss": 0.0463,
    "grad_norm": 0.7036197781562805,
    "learning_rate": 4.70342522974102e-06,
    "epoch": 1.5889724310776943,
    "step": 6340
  },
  {
    "loss": 0.0405,
    "grad_norm": 0.40728044509887695,
    "learning_rate": 4.6950710108604845e-06,
    "epoch": 1.5914786967418546,
    "step": 6350
  },
  {
    "loss": 0.0369,
    "grad_norm": 0.8336752653121948,
    "learning_rate": 4.68671679197995e-06,
    "epoch": 1.5939849624060152,
    "step": 6360
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.7724816799163818,
    "learning_rate": 4.678362573099415e-06,
    "epoch": 1.5964912280701755,
    "step": 6370
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.5369353294372559,
    "learning_rate": 4.670008354218881e-06,
    "epoch": 1.5989974937343359,
    "step": 6380
  },
  {
    "loss": 0.0409,
    "grad_norm": 0.4246133267879486,
    "learning_rate": 4.661654135338346e-06,
    "epoch": 1.6015037593984962,
    "step": 6390
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.1907884031534195,
    "learning_rate": 4.653299916457811e-06,
    "epoch": 1.6040100250626566,
    "step": 6400
  },
  {
    "loss": 0.0389,
    "grad_norm": 0.5920154452323914,
    "learning_rate": 4.644945697577277e-06,
    "epoch": 1.606516290726817,
    "step": 6410
  },
  {
    "loss": 0.0365,
    "grad_norm": 0.7768440842628479,
    "learning_rate": 4.636591478696742e-06,
    "epoch": 1.6090225563909775,
    "step": 6420
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.17722788453102112,
    "learning_rate": 4.6282372598162075e-06,
    "epoch": 1.6115288220551378,
    "step": 6430
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.39486202597618103,
    "learning_rate": 4.619883040935672e-06,
    "epoch": 1.6140350877192984,
    "step": 6440
  },
  {
    "loss": 0.0375,
    "grad_norm": 0.27531248331069946,
    "learning_rate": 4.611528822055138e-06,
    "epoch": 1.6165413533834587,
    "step": 6450
  },
  {
    "loss": 0.0306,
    "grad_norm": 0.30375316739082336,
    "learning_rate": 4.603174603174604e-06,
    "epoch": 1.619047619047619,
    "step": 6460
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.49740925431251526,
    "learning_rate": 4.5948203842940685e-06,
    "epoch": 1.6215538847117794,
    "step": 6470
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.31718507409095764,
    "learning_rate": 4.586466165413534e-06,
    "epoch": 1.6240601503759398,
    "step": 6480
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.30037420988082886,
    "learning_rate": 4.578111946532999e-06,
    "epoch": 1.6265664160401,
    "step": 6490
  },
  {
    "loss": 0.0368,
    "grad_norm": 0.7564720511436462,
    "learning_rate": 4.569757727652465e-06,
    "epoch": 1.6290726817042607,
    "step": 6500
  },
  {
    "eval_loss": 0.03897801786661148,
    "eval_roc_auc_macro": 0.9885332639646643,
    "eval_runtime": 40.2319,
    "eval_samples_per_second": 793.275,
    "eval_steps_per_second": 24.806,
    "epoch": 1.6290726817042607,
    "step": 6500
  },
  {
    "train_loss": 0.03407907113432884,
    "train_roc_auc_macro": 0.9905164945797854,
    "train_runtime": 160.2499,
    "train_samples_per_second": 796.606,
    "train_steps_per_second": 24.899,
    "epoch": 1.6290726817042607,
    "step": 6500
  },
  {
    "loss": 0.0406,
    "grad_norm": 0.3914260268211365,
    "learning_rate": 4.56140350877193e-06,
    "epoch": 1.631578947368421,
    "step": 6510
  },
  {
    "loss": 0.0469,
    "grad_norm": 0.4539794623851776,
    "learning_rate": 4.553049289891395e-06,
    "epoch": 1.6340852130325816,
    "step": 6520
  },
  {
    "loss": 0.0353,
    "grad_norm": 0.3290850818157196,
    "learning_rate": 4.544695071010861e-06,
    "epoch": 1.636591478696742,
    "step": 6530
  },
  {
    "loss": 0.0422,
    "grad_norm": 0.8348318934440613,
    "learning_rate": 4.536340852130326e-06,
    "epoch": 1.6390977443609023,
    "step": 6540
  },
  {
    "loss": 0.0477,
    "grad_norm": 0.5299882292747498,
    "learning_rate": 4.5279866332497915e-06,
    "epoch": 1.6416040100250626,
    "step": 6550
  },
  {
    "loss": 0.044,
    "grad_norm": 0.5528404712677002,
    "learning_rate": 4.519632414369256e-06,
    "epoch": 1.644110275689223,
    "step": 6560
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.6879475712776184,
    "learning_rate": 4.511278195488722e-06,
    "epoch": 1.6466165413533833,
    "step": 6570
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.2697215974330902,
    "learning_rate": 4.502923976608187e-06,
    "epoch": 1.6491228070175439,
    "step": 6580
  },
  {
    "loss": 0.038,
    "grad_norm": 0.3554835319519043,
    "learning_rate": 4.4945697577276526e-06,
    "epoch": 1.6516290726817042,
    "step": 6590
  },
  {
    "loss": 0.0299,
    "grad_norm": 0.36161190271377563,
    "learning_rate": 4.486215538847118e-06,
    "epoch": 1.6541353383458648,
    "step": 6600
  },
  {
    "loss": 0.0312,
    "grad_norm": 0.3065144121646881,
    "learning_rate": 4.477861319966583e-06,
    "epoch": 1.6566416040100251,
    "step": 6610
  },
  {
    "loss": 0.0272,
    "grad_norm": 0.18513089418411255,
    "learning_rate": 4.469507101086049e-06,
    "epoch": 1.6591478696741855,
    "step": 6620
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.9645050168037415,
    "learning_rate": 4.461152882205514e-06,
    "epoch": 1.6616541353383458,
    "step": 6630
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.4364362061023712,
    "learning_rate": 4.452798663324979e-06,
    "epoch": 1.6641604010025062,
    "step": 6640
  },
  {
    "loss": 0.0375,
    "grad_norm": 0.36325153708457947,
    "learning_rate": 4.444444444444444e-06,
    "epoch": 1.6666666666666665,
    "step": 6650
  },
  {
    "loss": 0.0257,
    "grad_norm": 0.21609127521514893,
    "learning_rate": 4.43609022556391e-06,
    "epoch": 1.669172932330827,
    "step": 6660
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.30066463351249695,
    "learning_rate": 4.4277360066833755e-06,
    "epoch": 1.6716791979949874,
    "step": 6670
  },
  {
    "loss": 0.046,
    "grad_norm": 0.5700749158859253,
    "learning_rate": 4.41938178780284e-06,
    "epoch": 1.674185463659148,
    "step": 6680
  },
  {
    "loss": 0.0299,
    "grad_norm": 0.2828253209590912,
    "learning_rate": 4.411027568922306e-06,
    "epoch": 1.6766917293233083,
    "step": 6690
  },
  {
    "loss": 0.0295,
    "grad_norm": 0.6511417627334595,
    "learning_rate": 4.402673350041771e-06,
    "epoch": 1.6791979949874687,
    "step": 6700
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.5618978142738342,
    "learning_rate": 4.394319131161237e-06,
    "epoch": 1.681704260651629,
    "step": 6710
  },
  {
    "loss": 0.0454,
    "grad_norm": 1.0374475717544556,
    "learning_rate": 4.385964912280702e-06,
    "epoch": 1.6842105263157894,
    "step": 6720
  },
  {
    "loss": 0.0408,
    "grad_norm": 0.4040642976760864,
    "learning_rate": 4.377610693400167e-06,
    "epoch": 1.6867167919799497,
    "step": 6730
  },
  {
    "loss": 0.0338,
    "grad_norm": 0.5079851746559143,
    "learning_rate": 4.369256474519633e-06,
    "epoch": 1.6892230576441103,
    "step": 6740
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.1870417296886444,
    "learning_rate": 4.360902255639098e-06,
    "epoch": 1.6917293233082706,
    "step": 6750
  },
  {
    "eval_loss": 0.038130708038806915,
    "eval_roc_auc_macro": 0.9883998580912271,
    "eval_runtime": 40.1153,
    "eval_samples_per_second": 795.581,
    "eval_steps_per_second": 24.878,
    "epoch": 1.6917293233082706,
    "step": 6750
  },
  {
    "train_loss": 0.03313805162906647,
    "train_roc_auc_macro": 0.9908965815529811,
    "train_runtime": 160.4441,
    "train_samples_per_second": 795.642,
    "train_steps_per_second": 24.868,
    "epoch": 1.6917293233082706,
    "step": 6750
  },
  {
    "loss": 0.0414,
    "grad_norm": 1.166347622871399,
    "learning_rate": 4.352548036758563e-06,
    "epoch": 1.6942355889724312,
    "step": 6760
  },
  {
    "loss": 0.0321,
    "grad_norm": 0.3180655241012573,
    "learning_rate": 4.344193817878028e-06,
    "epoch": 1.6967418546365916,
    "step": 6770
  },
  {
    "loss": 0.034,
    "grad_norm": 0.2590533494949341,
    "learning_rate": 4.335839598997494e-06,
    "epoch": 1.699248120300752,
    "step": 6780
  },
  {
    "loss": 0.0291,
    "grad_norm": 0.345777690410614,
    "learning_rate": 4.3274853801169596e-06,
    "epoch": 1.7017543859649122,
    "step": 6790
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.26762187480926514,
    "learning_rate": 4.319131161236424e-06,
    "epoch": 1.7042606516290726,
    "step": 6800
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.21750013530254364,
    "learning_rate": 4.31077694235589e-06,
    "epoch": 1.706766917293233,
    "step": 6810
  },
  {
    "loss": 0.0301,
    "grad_norm": 0.5032734870910645,
    "learning_rate": 4.302422723475355e-06,
    "epoch": 1.7092731829573935,
    "step": 6820
  },
  {
    "loss": 0.047,
    "grad_norm": 0.37139183282852173,
    "learning_rate": 4.294068504594821e-06,
    "epoch": 1.7117794486215538,
    "step": 6830
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.38153791427612305,
    "learning_rate": 4.2857142857142855e-06,
    "epoch": 1.7142857142857144,
    "step": 6840
  },
  {
    "loss": 0.0264,
    "grad_norm": 0.46991464495658875,
    "learning_rate": 4.277360066833751e-06,
    "epoch": 1.7167919799498748,
    "step": 6850
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.3012995719909668,
    "learning_rate": 4.269005847953217e-06,
    "epoch": 1.719298245614035,
    "step": 6860
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.7237914204597473,
    "learning_rate": 4.260651629072682e-06,
    "epoch": 1.7218045112781954,
    "step": 6870
  },
  {
    "loss": 0.0357,
    "grad_norm": 1.225058674812317,
    "learning_rate": 4.252297410192147e-06,
    "epoch": 1.7243107769423558,
    "step": 6880
  },
  {
    "loss": 0.035,
    "grad_norm": 0.2958050072193146,
    "learning_rate": 4.243943191311612e-06,
    "epoch": 1.7268170426065161,
    "step": 6890
  },
  {
    "loss": 0.0367,
    "grad_norm": 0.9274229407310486,
    "learning_rate": 4.235588972431078e-06,
    "epoch": 1.7293233082706767,
    "step": 6900
  },
  {
    "loss": 0.0335,
    "grad_norm": 0.4981282949447632,
    "learning_rate": 4.227234753550543e-06,
    "epoch": 1.731829573934837,
    "step": 6910
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.45594826340675354,
    "learning_rate": 4.2188805346700084e-06,
    "epoch": 1.7343358395989976,
    "step": 6920
  },
  {
    "loss": 0.0453,
    "grad_norm": 0.34195324778556824,
    "learning_rate": 4.210526315789474e-06,
    "epoch": 1.736842105263158,
    "step": 6930
  },
  {
    "loss": 0.0213,
    "grad_norm": 0.22172489762306213,
    "learning_rate": 4.202172096908939e-06,
    "epoch": 1.7393483709273183,
    "step": 6940
  },
  {
    "loss": 0.0332,
    "grad_norm": 0.5762429237365723,
    "learning_rate": 4.193817878028405e-06,
    "epoch": 1.7418546365914787,
    "step": 6950
  },
  {
    "loss": 0.0283,
    "grad_norm": 0.42780598998069763,
    "learning_rate": 4.1854636591478695e-06,
    "epoch": 1.744360902255639,
    "step": 6960
  },
  {
    "loss": 0.0366,
    "grad_norm": 1.0394062995910645,
    "learning_rate": 4.177109440267335e-06,
    "epoch": 1.7468671679197993,
    "step": 6970
  },
  {
    "loss": 0.0382,
    "grad_norm": 0.2570040822029114,
    "learning_rate": 4.1687552213868e-06,
    "epoch": 1.74937343358396,
    "step": 6980
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.38926562666893005,
    "learning_rate": 4.160401002506266e-06,
    "epoch": 1.7518796992481203,
    "step": 6990
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.5107365846633911,
    "learning_rate": 4.152046783625731e-06,
    "epoch": 1.7543859649122808,
    "step": 7000
  },
  {
    "eval_loss": 0.03921804949641228,
    "eval_roc_auc_macro": 0.9886071910406149,
    "eval_runtime": 40.231,
    "eval_samples_per_second": 793.295,
    "eval_steps_per_second": 24.807,
    "epoch": 1.7543859649122808,
    "step": 7000
  },
  {
    "train_loss": 0.034473445266485214,
    "train_roc_auc_macro": 0.9910533949031888,
    "train_runtime": 160.1548,
    "train_samples_per_second": 797.079,
    "train_steps_per_second": 24.913,
    "epoch": 1.7543859649122808,
    "step": 7000
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.39264121651649475,
    "learning_rate": 4.143692564745196e-06,
    "epoch": 1.7568922305764412,
    "step": 7010
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.13127446174621582,
    "learning_rate": 4.135338345864662e-06,
    "epoch": 1.7593984962406015,
    "step": 7020
  },
  {
    "loss": 0.0287,
    "grad_norm": 0.25849297642707825,
    "learning_rate": 4.126984126984127e-06,
    "epoch": 1.7619047619047619,
    "step": 7030
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.47663789987564087,
    "learning_rate": 4.1186299081035925e-06,
    "epoch": 1.7644110275689222,
    "step": 7040
  },
  {
    "loss": 0.0212,
    "grad_norm": 0.492125004529953,
    "learning_rate": 4.110275689223058e-06,
    "epoch": 1.7669172932330826,
    "step": 7050
  },
  {
    "loss": 0.0363,
    "grad_norm": 0.2809793949127197,
    "learning_rate": 4.101921470342523e-06,
    "epoch": 1.7694235588972431,
    "step": 7060
  },
  {
    "loss": 0.037,
    "grad_norm": 0.4937621057033539,
    "learning_rate": 4.093567251461989e-06,
    "epoch": 1.7719298245614035,
    "step": 7070
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.3257518708705902,
    "learning_rate": 4.0852130325814535e-06,
    "epoch": 1.774436090225564,
    "step": 7080
  },
  {
    "loss": 0.0396,
    "grad_norm": 0.15151818096637726,
    "learning_rate": 4.076858813700919e-06,
    "epoch": 1.7769423558897244,
    "step": 7090
  },
  {
    "loss": 0.0355,
    "grad_norm": 0.45731353759765625,
    "learning_rate": 4.068504594820384e-06,
    "epoch": 1.7794486215538847,
    "step": 7100
  },
  {
    "loss": 0.036,
    "grad_norm": 0.4783431589603424,
    "learning_rate": 4.06015037593985e-06,
    "epoch": 1.781954887218045,
    "step": 7110
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.5901915431022644,
    "learning_rate": 4.0517961570593154e-06,
    "epoch": 1.7844611528822054,
    "step": 7120
  },
  {
    "loss": 0.0299,
    "grad_norm": 0.05929736793041229,
    "learning_rate": 4.04344193817878e-06,
    "epoch": 1.7869674185463658,
    "step": 7130
  },
  {
    "loss": 0.038,
    "grad_norm": 0.8109357953071594,
    "learning_rate": 4.035087719298246e-06,
    "epoch": 1.7894736842105263,
    "step": 7140
  },
  {
    "loss": 0.0337,
    "grad_norm": 0.27965864539146423,
    "learning_rate": 4.026733500417711e-06,
    "epoch": 1.7919799498746867,
    "step": 7150
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.32133665680885315,
    "learning_rate": 4.0183792815371765e-06,
    "epoch": 1.7944862155388472,
    "step": 7160
  },
  {
    "loss": 0.0299,
    "grad_norm": 0.35918623208999634,
    "learning_rate": 4.010025062656641e-06,
    "epoch": 1.7969924812030076,
    "step": 7170
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.3712831139564514,
    "learning_rate": 4.001670843776107e-06,
    "epoch": 1.799498746867168,
    "step": 7180
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.6037456393241882,
    "learning_rate": 3.993316624895573e-06,
    "epoch": 1.8020050125313283,
    "step": 7190
  },
  {
    "loss": 0.0342,
    "grad_norm": 0.28691527247428894,
    "learning_rate": 3.9849624060150376e-06,
    "epoch": 1.8045112781954886,
    "step": 7200
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.36017388105392456,
    "learning_rate": 3.976608187134503e-06,
    "epoch": 1.807017543859649,
    "step": 7210
  },
  {
    "loss": 0.0323,
    "grad_norm": 0.3031873404979706,
    "learning_rate": 3.968253968253968e-06,
    "epoch": 1.8095238095238095,
    "step": 7220
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.49417680501937866,
    "learning_rate": 3.959899749373434e-06,
    "epoch": 1.8120300751879699,
    "step": 7230
  },
  {
    "loss": 0.036,
    "grad_norm": 0.4090258479118347,
    "learning_rate": 3.951545530492899e-06,
    "epoch": 1.8145363408521304,
    "step": 7240
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.8248823285102844,
    "learning_rate": 3.943191311612364e-06,
    "epoch": 1.8170426065162908,
    "step": 7250
  },
  {
    "eval_loss": 0.03735857829451561,
    "eval_roc_auc_macro": 0.988559077290327,
    "eval_runtime": 40.1564,
    "eval_samples_per_second": 794.768,
    "eval_steps_per_second": 24.853,
    "epoch": 1.8170426065162908,
    "step": 7250
  },
  {
    "train_loss": 0.03198063746094704,
    "train_roc_auc_macro": 0.9911186264161173,
    "train_runtime": 160.3601,
    "train_samples_per_second": 796.058,
    "train_steps_per_second": 24.881,
    "epoch": 1.8170426065162908,
    "step": 7250
  },
  {
    "loss": 0.0226,
    "grad_norm": 0.43425676226615906,
    "learning_rate": 3.93483709273183e-06,
    "epoch": 1.8195488721804511,
    "step": 7260
  },
  {
    "loss": 0.0297,
    "grad_norm": 0.5811648964881897,
    "learning_rate": 3.926482873851295e-06,
    "epoch": 1.8220551378446115,
    "step": 7270
  },
  {
    "loss": 0.0435,
    "grad_norm": 0.6138055324554443,
    "learning_rate": 3.9181286549707605e-06,
    "epoch": 1.8245614035087718,
    "step": 7280
  },
  {
    "loss": 0.0318,
    "grad_norm": 0.34623953700065613,
    "learning_rate": 3.909774436090225e-06,
    "epoch": 1.8270676691729322,
    "step": 7290
  },
  {
    "loss": 0.0252,
    "grad_norm": 0.249867245554924,
    "learning_rate": 3.901420217209691e-06,
    "epoch": 1.8295739348370927,
    "step": 7300
  },
  {
    "loss": 0.0262,
    "grad_norm": 0.12009426951408386,
    "learning_rate": 3.893065998329157e-06,
    "epoch": 1.832080200501253,
    "step": 7310
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.4162887930870056,
    "learning_rate": 3.884711779448622e-06,
    "epoch": 1.8345864661654137,
    "step": 7320
  },
  {
    "loss": 0.0401,
    "grad_norm": 0.32483750581741333,
    "learning_rate": 3.876357560568087e-06,
    "epoch": 1.837092731829574,
    "step": 7330
  },
  {
    "loss": 0.0278,
    "grad_norm": 0.1722583919763565,
    "learning_rate": 3.868003341687552e-06,
    "epoch": 1.8395989974937343,
    "step": 7340
  },
  {
    "loss": 0.0309,
    "grad_norm": 0.23417459428310394,
    "learning_rate": 3.859649122807018e-06,
    "epoch": 1.8421052631578947,
    "step": 7350
  },
  {
    "loss": 0.0476,
    "grad_norm": 0.2893977761268616,
    "learning_rate": 3.851294903926483e-06,
    "epoch": 1.844611528822055,
    "step": 7360
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.43957263231277466,
    "learning_rate": 3.842940685045948e-06,
    "epoch": 1.8471177944862154,
    "step": 7370
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.2662787139415741,
    "learning_rate": 3.834586466165414e-06,
    "epoch": 1.849624060150376,
    "step": 7380
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.4934370219707489,
    "learning_rate": 3.826232247284879e-06,
    "epoch": 1.8521303258145363,
    "step": 7390
  },
  {
    "loss": 0.0354,
    "grad_norm": 1.0772550106048584,
    "learning_rate": 3.8178780284043446e-06,
    "epoch": 1.8546365914786969,
    "step": 7400
  },
  {
    "loss": 0.0365,
    "grad_norm": 0.2438797503709793,
    "learning_rate": 3.80952380952381e-06,
    "epoch": 1.8571428571428572,
    "step": 7410
  },
  {
    "loss": 0.0473,
    "grad_norm": 0.44931113719940186,
    "learning_rate": 3.801169590643275e-06,
    "epoch": 1.8596491228070176,
    "step": 7420
  },
  {
    "loss": 0.0304,
    "grad_norm": 0.289625883102417,
    "learning_rate": 3.7928153717627403e-06,
    "epoch": 1.862155388471178,
    "step": 7430
  },
  {
    "loss": 0.0315,
    "grad_norm": 1.4206132888793945,
    "learning_rate": 3.7844611528822056e-06,
    "epoch": 1.8646616541353382,
    "step": 7440
  },
  {
    "loss": 0.0289,
    "grad_norm": 0.3273957073688507,
    "learning_rate": 3.776106934001671e-06,
    "epoch": 1.8671679197994986,
    "step": 7450
  },
  {
    "loss": 0.047,
    "grad_norm": 0.2988186776638031,
    "learning_rate": 3.767752715121136e-06,
    "epoch": 1.8696741854636592,
    "step": 7460
  },
  {
    "loss": 0.0309,
    "grad_norm": 0.45083892345428467,
    "learning_rate": 3.7593984962406014e-06,
    "epoch": 1.8721804511278195,
    "step": 7470
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.8300185203552246,
    "learning_rate": 3.751044277360067e-06,
    "epoch": 1.87468671679198,
    "step": 7480
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.49420392513275146,
    "learning_rate": 3.7426900584795324e-06,
    "epoch": 1.8771929824561404,
    "step": 7490
  },
  {
    "loss": 0.0442,
    "grad_norm": 0.40119048953056335,
    "learning_rate": 3.7343358395989976e-06,
    "epoch": 1.8796992481203008,
    "step": 7500
  },
  {
    "eval_loss": 0.04247744381427765,
    "eval_roc_auc_macro": 0.9889826033270488,
    "eval_runtime": 40.1728,
    "eval_samples_per_second": 794.442,
    "eval_steps_per_second": 24.843,
    "epoch": 1.8796992481203008,
    "step": 7500
  },
  {
    "train_loss": 0.03732307255268097,
    "train_roc_auc_macro": 0.9913220045972749,
    "train_runtime": 160.4364,
    "train_samples_per_second": 795.68,
    "train_steps_per_second": 24.87,
    "epoch": 1.8796992481203008,
    "step": 7500
  },
  {
    "loss": 0.04,
    "grad_norm": 0.4288129508495331,
    "learning_rate": 3.725981620718463e-06,
    "epoch": 1.882205513784461,
    "step": 7510
  },
  {
    "loss": 0.0304,
    "grad_norm": 0.3268962800502777,
    "learning_rate": 3.717627401837928e-06,
    "epoch": 1.8847117794486214,
    "step": 7520
  },
  {
    "loss": 0.0404,
    "grad_norm": 0.2637803256511688,
    "learning_rate": 3.7092731829573934e-06,
    "epoch": 1.8872180451127818,
    "step": 7530
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.5671846270561218,
    "learning_rate": 3.700918964076859e-06,
    "epoch": 1.8897243107769424,
    "step": 7540
  },
  {
    "loss": 0.0252,
    "grad_norm": 0.24238108098506927,
    "learning_rate": 3.6925647451963244e-06,
    "epoch": 1.8922305764411027,
    "step": 7550
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.4114384651184082,
    "learning_rate": 3.6842105263157896e-06,
    "epoch": 1.8947368421052633,
    "step": 7560
  },
  {
    "loss": 0.0477,
    "grad_norm": 1.12344491481781,
    "learning_rate": 3.675856307435255e-06,
    "epoch": 1.8972431077694236,
    "step": 7570
  },
  {
    "loss": 0.0434,
    "grad_norm": 0.6346834897994995,
    "learning_rate": 3.66750208855472e-06,
    "epoch": 1.899749373433584,
    "step": 7580
  },
  {
    "loss": 0.0227,
    "grad_norm": 0.1277092546224594,
    "learning_rate": 3.6591478696741854e-06,
    "epoch": 1.9022556390977443,
    "step": 7590
  },
  {
    "loss": 0.0414,
    "grad_norm": 0.48746660351753235,
    "learning_rate": 3.6507936507936507e-06,
    "epoch": 1.9047619047619047,
    "step": 7600
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.6817461848258972,
    "learning_rate": 3.6424394319131164e-06,
    "epoch": 1.907268170426065,
    "step": 7610
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.28163254261016846,
    "learning_rate": 3.6340852130325817e-06,
    "epoch": 1.9097744360902256,
    "step": 7620
  },
  {
    "loss": 0.0328,
    "grad_norm": 0.45417195558547974,
    "learning_rate": 3.625730994152047e-06,
    "epoch": 1.912280701754386,
    "step": 7630
  },
  {
    "loss": 0.0298,
    "grad_norm": 0.29949191212654114,
    "learning_rate": 3.617376775271512e-06,
    "epoch": 1.9147869674185465,
    "step": 7640
  },
  {
    "loss": 0.0373,
    "grad_norm": 0.5818338990211487,
    "learning_rate": 3.6090225563909775e-06,
    "epoch": 1.9172932330827068,
    "step": 7650
  },
  {
    "loss": 0.0326,
    "grad_norm": 0.34909093379974365,
    "learning_rate": 3.6006683375104427e-06,
    "epoch": 1.9197994987468672,
    "step": 7660
  },
  {
    "loss": 0.0289,
    "grad_norm": 0.8597334027290344,
    "learning_rate": 3.5923141186299084e-06,
    "epoch": 1.9223057644110275,
    "step": 7670
  },
  {
    "loss": 0.043,
    "grad_norm": 0.41301271319389343,
    "learning_rate": 3.5839598997493737e-06,
    "epoch": 1.9248120300751879,
    "step": 7680
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.3597121834754944,
    "learning_rate": 3.575605680868839e-06,
    "epoch": 1.9273182957393482,
    "step": 7690
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.41870442032814026,
    "learning_rate": 3.567251461988304e-06,
    "epoch": 1.9298245614035088,
    "step": 7700
  },
  {
    "loss": 0.0341,
    "grad_norm": 1.4924222230911255,
    "learning_rate": 3.5588972431077695e-06,
    "epoch": 1.9323308270676691,
    "step": 7710
  },
  {
    "loss": 0.0272,
    "grad_norm": 0.46535730361938477,
    "learning_rate": 3.5505430242272347e-06,
    "epoch": 1.9348370927318297,
    "step": 7720
  },
  {
    "loss": 0.0365,
    "grad_norm": 0.4439443349838257,
    "learning_rate": 3.5421888053467e-06,
    "epoch": 1.93734335839599,
    "step": 7730
  },
  {
    "loss": 0.027,
    "grad_norm": 0.5598247647285461,
    "learning_rate": 3.5338345864661657e-06,
    "epoch": 1.9398496240601504,
    "step": 7740
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.27585962414741516,
    "learning_rate": 3.525480367585631e-06,
    "epoch": 1.9423558897243107,
    "step": 7750
  },
  {
    "eval_loss": 0.037491440773010254,
    "eval_roc_auc_macro": 0.9890112789069304,
    "eval_runtime": 40.1558,
    "eval_samples_per_second": 794.779,
    "eval_steps_per_second": 24.853,
    "epoch": 1.9423558897243107,
    "step": 7750
  },
  {
    "train_loss": 0.03229883313179016,
    "train_roc_auc_macro": 0.9915686759341331,
    "train_runtime": 160.4962,
    "train_samples_per_second": 795.383,
    "train_steps_per_second": 24.86,
    "epoch": 1.9423558897243107,
    "step": 7750
  },
  {
    "loss": 0.0471,
    "grad_norm": 0.5349372029304504,
    "learning_rate": 3.5171261487050962e-06,
    "epoch": 1.944862155388471,
    "step": 7760
  },
  {
    "loss": 0.045,
    "grad_norm": 1.1086889505386353,
    "learning_rate": 3.5087719298245615e-06,
    "epoch": 1.9473684210526314,
    "step": 7770
  },
  {
    "loss": 0.0284,
    "grad_norm": 0.19626860320568085,
    "learning_rate": 3.5004177109440267e-06,
    "epoch": 1.949874686716792,
    "step": 7780
  },
  {
    "loss": 0.0504,
    "grad_norm": 1.2568784952163696,
    "learning_rate": 3.492063492063492e-06,
    "epoch": 1.9523809523809523,
    "step": 7790
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.41435176134109497,
    "learning_rate": 3.4837092731829573e-06,
    "epoch": 1.954887218045113,
    "step": 7800
  },
  {
    "loss": 0.0276,
    "grad_norm": 0.28462526202201843,
    "learning_rate": 3.475355054302423e-06,
    "epoch": 1.9573934837092732,
    "step": 7810
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.39263054728507996,
    "learning_rate": 3.4670008354218882e-06,
    "epoch": 1.9598997493734336,
    "step": 7820
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.4322160482406616,
    "learning_rate": 3.4586466165413535e-06,
    "epoch": 1.962406015037594,
    "step": 7830
  },
  {
    "loss": 0.0217,
    "grad_norm": 0.25806766748428345,
    "learning_rate": 3.4502923976608188e-06,
    "epoch": 1.9649122807017543,
    "step": 7840
  },
  {
    "loss": 0.0318,
    "grad_norm": 0.4660921096801758,
    "learning_rate": 3.441938178780284e-06,
    "epoch": 1.9674185463659146,
    "step": 7850
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.5237217545509338,
    "learning_rate": 3.4335839598997493e-06,
    "epoch": 1.9699248120300752,
    "step": 7860
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.5760914087295532,
    "learning_rate": 3.425229741019215e-06,
    "epoch": 1.9724310776942355,
    "step": 7870
  },
  {
    "loss": 0.0456,
    "grad_norm": 0.7013567090034485,
    "learning_rate": 3.4168755221386802e-06,
    "epoch": 1.974937343358396,
    "step": 7880
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.29380878806114197,
    "learning_rate": 3.4085213032581455e-06,
    "epoch": 1.9774436090225564,
    "step": 7890
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.5036566257476807,
    "learning_rate": 3.4001670843776108e-06,
    "epoch": 1.9799498746867168,
    "step": 7900
  },
  {
    "loss": 0.0287,
    "grad_norm": 0.6823908686637878,
    "learning_rate": 3.391812865497076e-06,
    "epoch": 1.9824561403508771,
    "step": 7910
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.2022906243801117,
    "learning_rate": 3.3834586466165413e-06,
    "epoch": 1.9849624060150375,
    "step": 7920
  },
  {
    "loss": 0.0316,
    "grad_norm": 0.208568274974823,
    "learning_rate": 3.3751044277360066e-06,
    "epoch": 1.9874686716791978,
    "step": 7930
  },
  {
    "loss": 0.0288,
    "grad_norm": 0.6147617101669312,
    "learning_rate": 3.3667502088554723e-06,
    "epoch": 1.9899749373433584,
    "step": 7940
  },
  {
    "loss": 0.031,
    "grad_norm": 0.2919102907180786,
    "learning_rate": 3.3583959899749375e-06,
    "epoch": 1.9924812030075187,
    "step": 7950
  },
  {
    "loss": 0.0439,
    "grad_norm": 0.7428850531578064,
    "learning_rate": 3.350041771094403e-06,
    "epoch": 1.9949874686716793,
    "step": 7960
  },
  {
    "loss": 0.0382,
    "grad_norm": 0.560778021812439,
    "learning_rate": 3.341687552213868e-06,
    "epoch": 1.9974937343358397,
    "step": 7970
  },
  {
    "loss": 0.0269,
    "grad_norm": 0.4724017083644867,
    "learning_rate": 3.3333333333333333e-06,
    "epoch": 2.0,
    "step": 7980
  },
  {
    "loss": 0.0237,
    "grad_norm": 0.6051903963088989,
    "learning_rate": 3.3249791144527986e-06,
    "epoch": 2.0025062656641603,
    "step": 7990
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.6716068387031555,
    "learning_rate": 3.3166248955722643e-06,
    "epoch": 2.0050125313283207,
    "step": 8000
  },
  {
    "eval_loss": 0.037851497530937195,
    "eval_roc_auc_macro": 0.9890665334310783,
    "eval_runtime": 40.1455,
    "eval_samples_per_second": 794.983,
    "eval_steps_per_second": 24.86,
    "epoch": 2.0050125313283207,
    "step": 8000
  },
  {
    "train_loss": 0.03195488825440407,
    "train_roc_auc_macro": 0.9917366750924947,
    "train_runtime": 160.3994,
    "train_samples_per_second": 795.864,
    "train_steps_per_second": 24.875,
    "epoch": 2.0050125313283207,
    "step": 8000
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.4250907599925995,
    "learning_rate": 3.3082706766917295e-06,
    "epoch": 2.007518796992481,
    "step": 8010
  },
  {
    "loss": 0.0404,
    "grad_norm": 0.37800517678260803,
    "learning_rate": 3.299916457811195e-06,
    "epoch": 2.0100250626566414,
    "step": 8020
  },
  {
    "loss": 0.0447,
    "grad_norm": 0.5983891487121582,
    "learning_rate": 3.29156223893066e-06,
    "epoch": 2.012531328320802,
    "step": 8030
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.4334666132926941,
    "learning_rate": 3.2832080200501253e-06,
    "epoch": 2.0150375939849625,
    "step": 8040
  },
  {
    "loss": 0.038,
    "grad_norm": 0.7858575582504272,
    "learning_rate": 3.2748538011695906e-06,
    "epoch": 2.017543859649123,
    "step": 8050
  },
  {
    "loss": 0.0316,
    "grad_norm": 0.4926290810108185,
    "learning_rate": 3.266499582289056e-06,
    "epoch": 2.020050125313283,
    "step": 8060
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.5520452260971069,
    "learning_rate": 3.2581453634085216e-06,
    "epoch": 2.0225563909774436,
    "step": 8070
  },
  {
    "loss": 0.03,
    "grad_norm": 0.39525288343429565,
    "learning_rate": 3.249791144527987e-06,
    "epoch": 2.025062656641604,
    "step": 8080
  },
  {
    "loss": 0.0342,
    "grad_norm": 0.3984285593032837,
    "learning_rate": 3.241436925647452e-06,
    "epoch": 2.0275689223057642,
    "step": 8090
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.3659377992153168,
    "learning_rate": 3.2330827067669174e-06,
    "epoch": 2.030075187969925,
    "step": 8100
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.7988353967666626,
    "learning_rate": 3.2247284878863826e-06,
    "epoch": 2.0325814536340854,
    "step": 8110
  },
  {
    "loss": 0.0333,
    "grad_norm": 0.470375657081604,
    "learning_rate": 3.216374269005848e-06,
    "epoch": 2.0350877192982457,
    "step": 8120
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.3552785813808441,
    "learning_rate": 3.2080200501253136e-06,
    "epoch": 2.037593984962406,
    "step": 8130
  },
  {
    "loss": 0.0337,
    "grad_norm": 0.5135576725006104,
    "learning_rate": 3.199665831244779e-06,
    "epoch": 2.0401002506265664,
    "step": 8140
  },
  {
    "loss": 0.0405,
    "grad_norm": 0.6615871787071228,
    "learning_rate": 3.191311612364244e-06,
    "epoch": 2.0426065162907268,
    "step": 8150
  },
  {
    "loss": 0.0293,
    "grad_norm": 0.634057879447937,
    "learning_rate": 3.1829573934837094e-06,
    "epoch": 2.045112781954887,
    "step": 8160
  },
  {
    "loss": 0.0407,
    "grad_norm": 0.6583999395370483,
    "learning_rate": 3.1746031746031746e-06,
    "epoch": 2.0476190476190474,
    "step": 8170
  },
  {
    "loss": 0.0381,
    "grad_norm": 0.5081652402877808,
    "learning_rate": 3.16624895572264e-06,
    "epoch": 2.050125313283208,
    "step": 8180
  },
  {
    "loss": 0.031,
    "grad_norm": 0.4040578603744507,
    "learning_rate": 3.157894736842105e-06,
    "epoch": 2.0526315789473686,
    "step": 8190
  },
  {
    "loss": 0.0301,
    "grad_norm": 0.41628292202949524,
    "learning_rate": 3.149540517961571e-06,
    "epoch": 2.055137844611529,
    "step": 8200
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.6057664752006531,
    "learning_rate": 3.141186299081036e-06,
    "epoch": 2.0576441102756893,
    "step": 8210
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.6142004728317261,
    "learning_rate": 3.1328320802005014e-06,
    "epoch": 2.0601503759398496,
    "step": 8220
  },
  {
    "loss": 0.0317,
    "grad_norm": 0.358460009098053,
    "learning_rate": 3.1244778613199666e-06,
    "epoch": 2.06265664160401,
    "step": 8230
  },
  {
    "loss": 0.0266,
    "grad_norm": 0.7221225500106812,
    "learning_rate": 3.116123642439432e-06,
    "epoch": 2.0651629072681703,
    "step": 8240
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.20620450377464294,
    "learning_rate": 3.107769423558897e-06,
    "epoch": 2.0676691729323307,
    "step": 8250
  },
  {
    "eval_loss": 0.04119621962308884,
    "eval_roc_auc_macro": 0.9894822952311655,
    "eval_runtime": 40.1776,
    "eval_samples_per_second": 794.348,
    "eval_steps_per_second": 24.84,
    "epoch": 2.0676691729323307,
    "step": 8250
  },
  {
    "train_loss": 0.034983448684215546,
    "train_roc_auc_macro": 0.9918051598074719,
    "train_runtime": 160.2709,
    "train_samples_per_second": 796.502,
    "train_steps_per_second": 24.895,
    "epoch": 2.0676691729323307,
    "step": 8250
  },
  {
    "loss": 0.0305,
    "grad_norm": 0.4706519842147827,
    "learning_rate": 3.0994152046783624e-06,
    "epoch": 2.0701754385964914,
    "step": 8260
  },
  {
    "loss": 0.0251,
    "grad_norm": 0.3886294960975647,
    "learning_rate": 3.091060985797828e-06,
    "epoch": 2.072681704260652,
    "step": 8270
  },
  {
    "loss": 0.028,
    "grad_norm": 0.39404046535491943,
    "learning_rate": 3.0827067669172934e-06,
    "epoch": 2.075187969924812,
    "step": 8280
  },
  {
    "loss": 0.0312,
    "grad_norm": 0.29973793029785156,
    "learning_rate": 3.0743525480367587e-06,
    "epoch": 2.0776942355889725,
    "step": 8290
  },
  {
    "loss": 0.0385,
    "grad_norm": 0.6396194696426392,
    "learning_rate": 3.065998329156224e-06,
    "epoch": 2.080200501253133,
    "step": 8300
  },
  {
    "loss": 0.0259,
    "grad_norm": 0.6016060709953308,
    "learning_rate": 3.057644110275689e-06,
    "epoch": 2.082706766917293,
    "step": 8310
  },
  {
    "loss": 0.0311,
    "grad_norm": 0.3687347173690796,
    "learning_rate": 3.0492898913951545e-06,
    "epoch": 2.0852130325814535,
    "step": 8320
  },
  {
    "loss": 0.0396,
    "grad_norm": 0.7722859382629395,
    "learning_rate": 3.04093567251462e-06,
    "epoch": 2.087719298245614,
    "step": 8330
  },
  {
    "loss": 0.0385,
    "grad_norm": 0.7558945417404175,
    "learning_rate": 3.0325814536340854e-06,
    "epoch": 2.090225563909774,
    "step": 8340
  },
  {
    "loss": 0.024,
    "grad_norm": 0.4597901999950409,
    "learning_rate": 3.0242272347535507e-06,
    "epoch": 2.092731829573935,
    "step": 8350
  },
  {
    "loss": 0.0296,
    "grad_norm": 0.5387485027313232,
    "learning_rate": 3.015873015873016e-06,
    "epoch": 2.0952380952380953,
    "step": 8360
  },
  {
    "loss": 0.0252,
    "grad_norm": 0.2270049899816513,
    "learning_rate": 3.007518796992481e-06,
    "epoch": 2.0977443609022557,
    "step": 8370
  },
  {
    "loss": 0.0353,
    "grad_norm": 0.5090845227241516,
    "learning_rate": 2.9991645781119465e-06,
    "epoch": 2.100250626566416,
    "step": 8380
  },
  {
    "loss": 0.0417,
    "grad_norm": 0.6418401002883911,
    "learning_rate": 2.9908103592314117e-06,
    "epoch": 2.1027568922305764,
    "step": 8390
  },
  {
    "loss": 0.0199,
    "grad_norm": 0.3824600875377655,
    "learning_rate": 2.9824561403508774e-06,
    "epoch": 2.1052631578947367,
    "step": 8400
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.6324685215950012,
    "learning_rate": 2.9741019214703427e-06,
    "epoch": 2.107769423558897,
    "step": 8410
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.7381376624107361,
    "learning_rate": 2.965747702589808e-06,
    "epoch": 2.110275689223058,
    "step": 8420
  },
  {
    "loss": 0.0366,
    "grad_norm": 0.33432537317276,
    "learning_rate": 2.9573934837092732e-06,
    "epoch": 2.112781954887218,
    "step": 8430
  },
  {
    "loss": 0.0388,
    "grad_norm": 0.1368161141872406,
    "learning_rate": 2.9490392648287385e-06,
    "epoch": 2.1152882205513786,
    "step": 8440
  },
  {
    "loss": 0.0342,
    "grad_norm": 0.39892736077308655,
    "learning_rate": 2.9406850459482038e-06,
    "epoch": 2.117794486215539,
    "step": 8450
  },
  {
    "loss": 0.0257,
    "grad_norm": 0.31906598806381226,
    "learning_rate": 2.9323308270676694e-06,
    "epoch": 2.1203007518796992,
    "step": 8460
  },
  {
    "loss": 0.0215,
    "grad_norm": 0.3860047161579132,
    "learning_rate": 2.9239766081871347e-06,
    "epoch": 2.1228070175438596,
    "step": 8470
  },
  {
    "loss": 0.0295,
    "grad_norm": 0.3738449811935425,
    "learning_rate": 2.9156223893066e-06,
    "epoch": 2.12531328320802,
    "step": 8480
  },
  {
    "loss": 0.0397,
    "grad_norm": 0.4190889596939087,
    "learning_rate": 2.9072681704260652e-06,
    "epoch": 2.1278195488721803,
    "step": 8490
  },
  {
    "loss": 0.0332,
    "grad_norm": 0.5412874817848206,
    "learning_rate": 2.8989139515455305e-06,
    "epoch": 2.1303258145363406,
    "step": 8500
  },
  {
    "eval_loss": 0.03812973201274872,
    "eval_roc_auc_macro": 0.9893205218275828,
    "eval_runtime": 40.1704,
    "eval_samples_per_second": 794.49,
    "eval_steps_per_second": 24.844,
    "epoch": 2.1303258145363406,
    "step": 8500
  },
  {
    "train_loss": 0.031960733234882355,
    "train_roc_auc_macro": 0.992148176499759,
    "train_runtime": 160.2501,
    "train_samples_per_second": 796.605,
    "train_steps_per_second": 24.899,
    "epoch": 2.1303258145363406,
    "step": 8500
  },
  {
    "loss": 0.0343,
    "grad_norm": 0.4699406623840332,
    "learning_rate": 2.8905597326649958e-06,
    "epoch": 2.1328320802005014,
    "step": 8510
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.5968918204307556,
    "learning_rate": 2.882205513784461e-06,
    "epoch": 2.1353383458646618,
    "step": 8520
  },
  {
    "loss": 0.0416,
    "grad_norm": 0.46759289503097534,
    "learning_rate": 2.8738512949039267e-06,
    "epoch": 2.137844611528822,
    "step": 8530
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.5251409411430359,
    "learning_rate": 2.865497076023392e-06,
    "epoch": 2.1403508771929824,
    "step": 8540
  },
  {
    "loss": 0.033,
    "grad_norm": 0.46505385637283325,
    "learning_rate": 2.8571428571428573e-06,
    "epoch": 2.142857142857143,
    "step": 8550
  },
  {
    "loss": 0.0375,
    "grad_norm": 0.20694980025291443,
    "learning_rate": 2.8487886382623225e-06,
    "epoch": 2.145363408521303,
    "step": 8560
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.4345301389694214,
    "learning_rate": 2.8404344193817878e-06,
    "epoch": 2.1478696741854635,
    "step": 8570
  },
  {
    "loss": 0.0323,
    "grad_norm": 0.35910409688949585,
    "learning_rate": 2.832080200501253e-06,
    "epoch": 2.1503759398496243,
    "step": 8580
  },
  {
    "loss": 0.0343,
    "grad_norm": 0.43267446756362915,
    "learning_rate": 2.8237259816207187e-06,
    "epoch": 2.1528822055137846,
    "step": 8590
  },
  {
    "loss": 0.0328,
    "grad_norm": 0.9277001023292542,
    "learning_rate": 2.815371762740184e-06,
    "epoch": 2.155388471177945,
    "step": 8600
  },
  {
    "loss": 0.0337,
    "grad_norm": 0.6066271066665649,
    "learning_rate": 2.8070175438596493e-06,
    "epoch": 2.1578947368421053,
    "step": 8610
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.30008581280708313,
    "learning_rate": 2.7986633249791145e-06,
    "epoch": 2.1604010025062657,
    "step": 8620
  },
  {
    "loss": 0.0226,
    "grad_norm": 0.4776837229728699,
    "learning_rate": 2.79030910609858e-06,
    "epoch": 2.162907268170426,
    "step": 8630
  },
  {
    "loss": 0.0316,
    "grad_norm": 0.11243031919002533,
    "learning_rate": 2.781954887218045e-06,
    "epoch": 2.1654135338345863,
    "step": 8640
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.3182024359703064,
    "learning_rate": 2.7736006683375103e-06,
    "epoch": 2.1679197994987467,
    "step": 8650
  },
  {
    "loss": 0.0195,
    "grad_norm": 0.32362833619117737,
    "learning_rate": 2.765246449456976e-06,
    "epoch": 2.170426065162907,
    "step": 8660
  },
  {
    "loss": 0.0261,
    "grad_norm": 0.48274049162864685,
    "learning_rate": 2.7568922305764413e-06,
    "epoch": 2.172932330827068,
    "step": 8670
  },
  {
    "loss": 0.0305,
    "grad_norm": 0.16247808933258057,
    "learning_rate": 2.7485380116959066e-06,
    "epoch": 2.175438596491228,
    "step": 8680
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.37492528557777405,
    "learning_rate": 2.740183792815372e-06,
    "epoch": 2.1779448621553885,
    "step": 8690
  },
  {
    "loss": 0.0275,
    "grad_norm": 0.5730411410331726,
    "learning_rate": 2.731829573934837e-06,
    "epoch": 2.180451127819549,
    "step": 8700
  },
  {
    "loss": 0.0285,
    "grad_norm": 0.2900587022304535,
    "learning_rate": 2.7234753550543023e-06,
    "epoch": 2.182957393483709,
    "step": 8710
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.6858728528022766,
    "learning_rate": 2.715121136173768e-06,
    "epoch": 2.1854636591478696,
    "step": 8720
  },
  {
    "loss": 0.0315,
    "grad_norm": 0.4275687336921692,
    "learning_rate": 2.7067669172932333e-06,
    "epoch": 2.18796992481203,
    "step": 8730
  },
  {
    "loss": 0.0296,
    "grad_norm": 0.8286060094833374,
    "learning_rate": 2.6984126984126986e-06,
    "epoch": 2.1904761904761907,
    "step": 8740
  },
  {
    "loss": 0.0268,
    "grad_norm": 0.9576122760772705,
    "learning_rate": 2.690058479532164e-06,
    "epoch": 2.192982456140351,
    "step": 8750
  },
  {
    "eval_loss": 0.03872070088982582,
    "eval_roc_auc_macro": 0.9893879962334792,
    "eval_runtime": 40.1786,
    "eval_samples_per_second": 794.329,
    "eval_steps_per_second": 24.839,
    "epoch": 2.192982456140351,
    "step": 8750
  },
  {
    "train_loss": 0.03159031644463539,
    "train_roc_auc_macro": 0.9921182439881938,
    "train_runtime": 160.3185,
    "train_samples_per_second": 796.265,
    "train_steps_per_second": 24.888,
    "epoch": 2.192982456140351,
    "step": 8750
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.7400760650634766,
    "learning_rate": 2.681704260651629e-06,
    "epoch": 2.1954887218045114,
    "step": 8760
  },
  {
    "loss": 0.0315,
    "grad_norm": 0.6584673523902893,
    "learning_rate": 2.6733500417710944e-06,
    "epoch": 2.1979949874686717,
    "step": 8770
  },
  {
    "loss": 0.025,
    "grad_norm": 0.32211732864379883,
    "learning_rate": 2.6649958228905596e-06,
    "epoch": 2.200501253132832,
    "step": 8780
  },
  {
    "loss": 0.0291,
    "grad_norm": 0.8958010077476501,
    "learning_rate": 2.6566416040100253e-06,
    "epoch": 2.2030075187969924,
    "step": 8790
  },
  {
    "loss": 0.0265,
    "grad_norm": 0.4386231303215027,
    "learning_rate": 2.6482873851294906e-06,
    "epoch": 2.2055137844611528,
    "step": 8800
  },
  {
    "loss": 0.0338,
    "grad_norm": 0.608497679233551,
    "learning_rate": 2.639933166248956e-06,
    "epoch": 2.208020050125313,
    "step": 8810
  },
  {
    "loss": 0.0396,
    "grad_norm": 0.4793076515197754,
    "learning_rate": 2.631578947368421e-06,
    "epoch": 2.2105263157894735,
    "step": 8820
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.4965512752532959,
    "learning_rate": 2.6232247284878864e-06,
    "epoch": 2.2130325814536342,
    "step": 8830
  },
  {
    "loss": 0.0323,
    "grad_norm": 0.2295820564031601,
    "learning_rate": 2.6148705096073516e-06,
    "epoch": 2.2155388471177946,
    "step": 8840
  },
  {
    "loss": 0.0316,
    "grad_norm": 0.49066779017448425,
    "learning_rate": 2.606516290726817e-06,
    "epoch": 2.218045112781955,
    "step": 8850
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.400291383266449,
    "learning_rate": 2.5981620718462826e-06,
    "epoch": 2.2205513784461153,
    "step": 8860
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.3510347306728363,
    "learning_rate": 2.589807852965748e-06,
    "epoch": 2.2230576441102756,
    "step": 8870
  },
  {
    "loss": 0.0316,
    "grad_norm": 0.5166151523590088,
    "learning_rate": 2.581453634085213e-06,
    "epoch": 2.225563909774436,
    "step": 8880
  },
  {
    "loss": 0.0213,
    "grad_norm": 0.7844095230102539,
    "learning_rate": 2.5730994152046784e-06,
    "epoch": 2.2280701754385963,
    "step": 8890
  },
  {
    "loss": 0.022,
    "grad_norm": 0.932604193687439,
    "learning_rate": 2.5647451963241437e-06,
    "epoch": 2.230576441102757,
    "step": 8900
  },
  {
    "loss": 0.0448,
    "grad_norm": 0.7663534283638,
    "learning_rate": 2.556390977443609e-06,
    "epoch": 2.2330827067669174,
    "step": 8910
  },
  {
    "loss": 0.0392,
    "grad_norm": 0.7097216248512268,
    "learning_rate": 2.5480367585630746e-06,
    "epoch": 2.235588972431078,
    "step": 8920
  },
  {
    "loss": 0.0364,
    "grad_norm": 0.5332860350608826,
    "learning_rate": 2.53968253968254e-06,
    "epoch": 2.238095238095238,
    "step": 8930
  },
  {
    "loss": 0.0236,
    "grad_norm": 0.6847936511039734,
    "learning_rate": 2.531328320802005e-06,
    "epoch": 2.2406015037593985,
    "step": 8940
  },
  {
    "loss": 0.0276,
    "grad_norm": 0.21647970378398895,
    "learning_rate": 2.5229741019214704e-06,
    "epoch": 2.243107769423559,
    "step": 8950
  },
  {
    "loss": 0.0217,
    "grad_norm": 0.42910224199295044,
    "learning_rate": 2.5146198830409357e-06,
    "epoch": 2.245614035087719,
    "step": 8960
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.40141761302948,
    "learning_rate": 2.506265664160401e-06,
    "epoch": 2.2481203007518795,
    "step": 8970
  },
  {
    "loss": 0.0227,
    "grad_norm": 0.3883153796195984,
    "learning_rate": 2.497911445279866e-06,
    "epoch": 2.25062656641604,
    "step": 8980
  },
  {
    "loss": 0.0356,
    "grad_norm": 0.4505418837070465,
    "learning_rate": 2.489557226399332e-06,
    "epoch": 2.2531328320802007,
    "step": 8990
  },
  {
    "loss": 0.0316,
    "grad_norm": 0.3795033097267151,
    "learning_rate": 2.481203007518797e-06,
    "epoch": 2.255639097744361,
    "step": 9000
  },
  {
    "eval_loss": 0.04116559028625488,
    "eval_roc_auc_macro": 0.9895844922125431,
    "eval_runtime": 40.1793,
    "eval_samples_per_second": 794.314,
    "eval_steps_per_second": 24.839,
    "epoch": 2.255639097744361,
    "step": 9000
  },
  {
    "train_loss": 0.03489913046360016,
    "train_roc_auc_macro": 0.9923888140264333,
    "train_runtime": 160.1125,
    "train_samples_per_second": 797.289,
    "train_steps_per_second": 24.92,
    "epoch": 2.255639097744361,
    "step": 9000
  },
  {
    "loss": 0.0388,
    "grad_norm": 0.7791702151298523,
    "learning_rate": 2.4728487886382624e-06,
    "epoch": 2.2581453634085213,
    "step": 9010
  },
  {
    "loss": 0.0241,
    "grad_norm": 0.22860603034496307,
    "learning_rate": 2.4644945697577277e-06,
    "epoch": 2.2606516290726817,
    "step": 9020
  },
  {
    "loss": 0.0301,
    "grad_norm": 0.3740417957305908,
    "learning_rate": 2.456140350877193e-06,
    "epoch": 2.263157894736842,
    "step": 9030
  },
  {
    "loss": 0.028,
    "grad_norm": 0.5037354826927185,
    "learning_rate": 2.4477861319966582e-06,
    "epoch": 2.2656641604010024,
    "step": 9040
  },
  {
    "loss": 0.0255,
    "grad_norm": 0.20667482912540436,
    "learning_rate": 2.439431913116124e-06,
    "epoch": 2.2681704260651627,
    "step": 9050
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.2553001344203949,
    "learning_rate": 2.431077694235589e-06,
    "epoch": 2.2706766917293235,
    "step": 9060
  },
  {
    "loss": 0.0273,
    "grad_norm": 0.3216310441493988,
    "learning_rate": 2.4227234753550544e-06,
    "epoch": 2.273182957393484,
    "step": 9070
  },
  {
    "loss": 0.0258,
    "grad_norm": 0.3977910876274109,
    "learning_rate": 2.4143692564745197e-06,
    "epoch": 2.275689223057644,
    "step": 9080
  },
  {
    "loss": 0.0344,
    "grad_norm": 1.013540267944336,
    "learning_rate": 2.406015037593985e-06,
    "epoch": 2.2781954887218046,
    "step": 9090
  },
  {
    "loss": 0.0378,
    "grad_norm": 0.527931809425354,
    "learning_rate": 2.3976608187134502e-06,
    "epoch": 2.280701754385965,
    "step": 9100
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.1752491593360901,
    "learning_rate": 2.3893065998329155e-06,
    "epoch": 2.2832080200501252,
    "step": 9110
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.30006182193756104,
    "learning_rate": 2.380952380952381e-06,
    "epoch": 2.2857142857142856,
    "step": 9120
  },
  {
    "loss": 0.0406,
    "grad_norm": 0.5055258870124817,
    "learning_rate": 2.3725981620718465e-06,
    "epoch": 2.288220551378446,
    "step": 9130
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.4751211404800415,
    "learning_rate": 2.3642439431913117e-06,
    "epoch": 2.2907268170426063,
    "step": 9140
  },
  {
    "loss": 0.0323,
    "grad_norm": 0.4754549562931061,
    "learning_rate": 2.355889724310777e-06,
    "epoch": 2.293233082706767,
    "step": 9150
  },
  {
    "loss": 0.0277,
    "grad_norm": 0.22283560037612915,
    "learning_rate": 2.3475355054302422e-06,
    "epoch": 2.2957393483709274,
    "step": 9160
  },
  {
    "loss": 0.0245,
    "grad_norm": 0.29289576411247253,
    "learning_rate": 2.3391812865497075e-06,
    "epoch": 2.2982456140350878,
    "step": 9170
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.5119770169258118,
    "learning_rate": 2.330827067669173e-06,
    "epoch": 2.300751879699248,
    "step": 9180
  },
  {
    "loss": 0.0254,
    "grad_norm": 0.527421772480011,
    "learning_rate": 2.3224728487886385e-06,
    "epoch": 2.3032581453634084,
    "step": 9190
  },
  {
    "loss": 0.0279,
    "grad_norm": 0.3452565670013428,
    "learning_rate": 2.3141186299081037e-06,
    "epoch": 2.305764411027569,
    "step": 9200
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.49796780943870544,
    "learning_rate": 2.305764411027569e-06,
    "epoch": 2.308270676691729,
    "step": 9210
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.6033300161361694,
    "learning_rate": 2.2974101921470343e-06,
    "epoch": 2.31077694235589,
    "step": 9220
  },
  {
    "loss": 0.0433,
    "grad_norm": 0.7369683384895325,
    "learning_rate": 2.2890559732664995e-06,
    "epoch": 2.3132832080200503,
    "step": 9230
  },
  {
    "loss": 0.0252,
    "grad_norm": 0.4394701421260834,
    "learning_rate": 2.280701754385965e-06,
    "epoch": 2.3157894736842106,
    "step": 9240
  },
  {
    "loss": 0.0297,
    "grad_norm": 0.23841089010238647,
    "learning_rate": 2.2723475355054305e-06,
    "epoch": 2.318295739348371,
    "step": 9250
  },
  {
    "eval_loss": 0.03720748797059059,
    "eval_roc_auc_macro": 0.9896314395909788,
    "eval_runtime": 40.139,
    "eval_samples_per_second": 795.112,
    "eval_steps_per_second": 24.864,
    "epoch": 2.318295739348371,
    "step": 9250
  },
  {
    "train_loss": 0.030713651329278946,
    "train_roc_auc_macro": 0.9925662776974497,
    "train_runtime": 160.3607,
    "train_samples_per_second": 796.055,
    "train_steps_per_second": 24.881,
    "epoch": 2.318295739348371,
    "step": 9250
  },
  {
    "loss": 0.0224,
    "grad_norm": 0.5612936615943909,
    "learning_rate": 2.2639933166248957e-06,
    "epoch": 2.3208020050125313,
    "step": 9260
  },
  {
    "loss": 0.0257,
    "grad_norm": 0.21829824149608612,
    "learning_rate": 2.255639097744361e-06,
    "epoch": 2.3233082706766917,
    "step": 9270
  },
  {
    "loss": 0.0272,
    "grad_norm": 0.32419392466545105,
    "learning_rate": 2.2472848788638263e-06,
    "epoch": 2.325814536340852,
    "step": 9280
  },
  {
    "loss": 0.036,
    "grad_norm": 1.32931649684906,
    "learning_rate": 2.2389306599832915e-06,
    "epoch": 2.3283208020050123,
    "step": 9290
  },
  {
    "loss": 0.0338,
    "grad_norm": 0.46463826298713684,
    "learning_rate": 2.230576441102757e-06,
    "epoch": 2.3308270676691727,
    "step": 9300
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.37495437264442444,
    "learning_rate": 2.222222222222222e-06,
    "epoch": 2.3333333333333335,
    "step": 9310
  },
  {
    "loss": 0.0268,
    "grad_norm": 0.6723706722259521,
    "learning_rate": 2.2138680033416878e-06,
    "epoch": 2.335839598997494,
    "step": 9320
  },
  {
    "loss": 0.0319,
    "grad_norm": 0.41065117716789246,
    "learning_rate": 2.205513784461153e-06,
    "epoch": 2.338345864661654,
    "step": 9330
  },
  {
    "loss": 0.0409,
    "grad_norm": 0.7621975541114807,
    "learning_rate": 2.1971595655806183e-06,
    "epoch": 2.3408521303258145,
    "step": 9340
  },
  {
    "loss": 0.0365,
    "grad_norm": 0.6356766819953918,
    "learning_rate": 2.1888053467000836e-06,
    "epoch": 2.343358395989975,
    "step": 9350
  },
  {
    "loss": 0.0332,
    "grad_norm": 0.21441632509231567,
    "learning_rate": 2.180451127819549e-06,
    "epoch": 2.345864661654135,
    "step": 9360
  },
  {
    "loss": 0.0288,
    "grad_norm": 0.5601972937583923,
    "learning_rate": 2.172096908939014e-06,
    "epoch": 2.3483709273182956,
    "step": 9370
  },
  {
    "loss": 0.0287,
    "grad_norm": 0.47340354323387146,
    "learning_rate": 2.1637426900584798e-06,
    "epoch": 2.3508771929824563,
    "step": 9380
  },
  {
    "loss": 0.033,
    "grad_norm": 0.886106014251709,
    "learning_rate": 2.155388471177945e-06,
    "epoch": 2.3533834586466167,
    "step": 9390
  },
  {
    "loss": 0.0403,
    "grad_norm": 0.5736281871795654,
    "learning_rate": 2.1470342522974103e-06,
    "epoch": 2.355889724310777,
    "step": 9400
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.44963470101356506,
    "learning_rate": 2.1386800334168756e-06,
    "epoch": 2.3583959899749374,
    "step": 9410
  },
  {
    "loss": 0.0465,
    "grad_norm": 0.6762669682502747,
    "learning_rate": 2.130325814536341e-06,
    "epoch": 2.3609022556390977,
    "step": 9420
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.7836991548538208,
    "learning_rate": 2.121971595655806e-06,
    "epoch": 2.363408521303258,
    "step": 9430
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.3869975507259369,
    "learning_rate": 2.1136173767752714e-06,
    "epoch": 2.3659147869674184,
    "step": 9440
  },
  {
    "loss": 0.0309,
    "grad_norm": 0.4768364131450653,
    "learning_rate": 2.105263157894737e-06,
    "epoch": 2.3684210526315788,
    "step": 9450
  },
  {
    "loss": 0.0249,
    "grad_norm": 0.5048282742500305,
    "learning_rate": 2.0969089390142023e-06,
    "epoch": 2.370927318295739,
    "step": 9460
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.6852734684944153,
    "learning_rate": 2.0885547201336676e-06,
    "epoch": 2.3734335839599,
    "step": 9470
  },
  {
    "loss": 0.0318,
    "grad_norm": 0.055903926491737366,
    "learning_rate": 2.080200501253133e-06,
    "epoch": 2.3759398496240602,
    "step": 9480
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.3187089264392853,
    "learning_rate": 2.071846282372598e-06,
    "epoch": 2.3784461152882206,
    "step": 9490
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.6091695427894592,
    "learning_rate": 2.0634920634920634e-06,
    "epoch": 2.380952380952381,
    "step": 9500
  },
  {
    "eval_loss": 0.03867233544588089,
    "eval_roc_auc_macro": 0.9898050614302653,
    "eval_runtime": 40.0986,
    "eval_samples_per_second": 795.914,
    "eval_steps_per_second": 24.889,
    "epoch": 2.380952380952381,
    "step": 9500
  },
  {
    "train_loss": 0.03186836466193199,
    "train_roc_auc_macro": 0.9928179621497363,
    "train_runtime": 160.3633,
    "train_samples_per_second": 796.043,
    "train_steps_per_second": 24.881,
    "epoch": 2.380952380952381,
    "step": 9500
  },
  {
    "loss": 0.03,
    "grad_norm": 0.46882951259613037,
    "learning_rate": 2.055137844611529e-06,
    "epoch": 2.3834586466165413,
    "step": 9510
  },
  {
    "loss": 0.0524,
    "grad_norm": 0.5473319888114929,
    "learning_rate": 2.0467836257309943e-06,
    "epoch": 2.3859649122807016,
    "step": 9520
  },
  {
    "loss": 0.024,
    "grad_norm": 0.3692096769809723,
    "learning_rate": 2.0384294068504596e-06,
    "epoch": 2.388471177944862,
    "step": 9530
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.45051059126853943,
    "learning_rate": 2.030075187969925e-06,
    "epoch": 2.3909774436090228,
    "step": 9540
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.774425208568573,
    "learning_rate": 2.02172096908939e-06,
    "epoch": 2.393483709273183,
    "step": 9550
  },
  {
    "loss": 0.0222,
    "grad_norm": 0.08654748648405075,
    "learning_rate": 2.0133667502088554e-06,
    "epoch": 2.3959899749373434,
    "step": 9560
  },
  {
    "loss": 0.0404,
    "grad_norm": 0.5849761962890625,
    "learning_rate": 2.0050125313283207e-06,
    "epoch": 2.398496240601504,
    "step": 9570
  },
  {
    "loss": 0.026,
    "grad_norm": 0.4019128382205963,
    "learning_rate": 1.9966583124477864e-06,
    "epoch": 2.401002506265664,
    "step": 9580
  },
  {
    "loss": 0.0278,
    "grad_norm": 0.6274251341819763,
    "learning_rate": 1.9883040935672516e-06,
    "epoch": 2.4035087719298245,
    "step": 9590
  },
  {
    "loss": 0.0298,
    "grad_norm": 0.5093848705291748,
    "learning_rate": 1.979949874686717e-06,
    "epoch": 2.406015037593985,
    "step": 9600
  },
  {
    "loss": 0.042,
    "grad_norm": 0.623080849647522,
    "learning_rate": 1.971595655806182e-06,
    "epoch": 2.408521303258145,
    "step": 9610
  },
  {
    "loss": 0.0293,
    "grad_norm": 0.5602899193763733,
    "learning_rate": 1.9632414369256474e-06,
    "epoch": 2.4110275689223055,
    "step": 9620
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.4204126298427582,
    "learning_rate": 1.9548872180451127e-06,
    "epoch": 2.4135338345864663,
    "step": 9630
  },
  {
    "loss": 0.0287,
    "grad_norm": 0.04959097132086754,
    "learning_rate": 1.9465329991645784e-06,
    "epoch": 2.4160401002506267,
    "step": 9640
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.45856773853302,
    "learning_rate": 1.9381787802840436e-06,
    "epoch": 2.418546365914787,
    "step": 9650
  },
  {
    "loss": 0.0415,
    "grad_norm": 1.1244332790374756,
    "learning_rate": 1.929824561403509e-06,
    "epoch": 2.4210526315789473,
    "step": 9660
  },
  {
    "loss": 0.0356,
    "grad_norm": 0.7456576824188232,
    "learning_rate": 1.921470342522974e-06,
    "epoch": 2.4235588972431077,
    "step": 9670
  },
  {
    "loss": 0.0304,
    "grad_norm": 0.12505483627319336,
    "learning_rate": 1.9131161236424394e-06,
    "epoch": 2.426065162907268,
    "step": 9680
  },
  {
    "loss": 0.0251,
    "grad_norm": 0.43704894185066223,
    "learning_rate": 1.904761904761905e-06,
    "epoch": 2.4285714285714284,
    "step": 9690
  },
  {
    "loss": 0.0209,
    "grad_norm": 0.3287959396839142,
    "learning_rate": 1.8964076858813702e-06,
    "epoch": 2.431077694235589,
    "step": 9700
  },
  {
    "loss": 0.0417,
    "grad_norm": 0.49726325273513794,
    "learning_rate": 1.8880534670008354e-06,
    "epoch": 2.4335839598997495,
    "step": 9710
  },
  {
    "loss": 0.0348,
    "grad_norm": 0.19789224863052368,
    "learning_rate": 1.8796992481203007e-06,
    "epoch": 2.43609022556391,
    "step": 9720
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.4537668824195862,
    "learning_rate": 1.8713450292397662e-06,
    "epoch": 2.43859649122807,
    "step": 9730
  },
  {
    "loss": 0.0273,
    "grad_norm": 0.1008949726819992,
    "learning_rate": 1.8629908103592314e-06,
    "epoch": 2.4411027568922306,
    "step": 9740
  },
  {
    "loss": 0.038,
    "grad_norm": 0.13826027512550354,
    "learning_rate": 1.8546365914786967e-06,
    "epoch": 2.443609022556391,
    "step": 9750
  },
  {
    "eval_loss": 0.03767462819814682,
    "eval_roc_auc_macro": 0.9897622890569474,
    "eval_runtime": 40.1976,
    "eval_samples_per_second": 793.952,
    "eval_steps_per_second": 24.827,
    "epoch": 2.443609022556391,
    "step": 9750
  },
  {
    "train_loss": 0.030462877824902534,
    "train_roc_auc_macro": 0.9927722528521413,
    "train_runtime": 160.2348,
    "train_samples_per_second": 796.681,
    "train_steps_per_second": 24.901,
    "epoch": 2.443609022556391,
    "step": 9750
  },
  {
    "loss": 0.0287,
    "grad_norm": 0.5006328225135803,
    "learning_rate": 1.8462823725981622e-06,
    "epoch": 2.4461152882205512,
    "step": 9760
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.6261559724807739,
    "learning_rate": 1.8379281537176275e-06,
    "epoch": 2.4486215538847116,
    "step": 9770
  },
  {
    "loss": 0.0324,
    "grad_norm": 0.23276782035827637,
    "learning_rate": 1.8295739348370927e-06,
    "epoch": 2.451127819548872,
    "step": 9780
  },
  {
    "loss": 0.0315,
    "grad_norm": 0.4256986677646637,
    "learning_rate": 1.8212197159565582e-06,
    "epoch": 2.4536340852130327,
    "step": 9790
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.38379186391830444,
    "learning_rate": 1.8128654970760235e-06,
    "epoch": 2.456140350877193,
    "step": 9800
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.5457902550697327,
    "learning_rate": 1.8045112781954887e-06,
    "epoch": 2.4586466165413534,
    "step": 9810
  },
  {
    "loss": 0.0452,
    "grad_norm": 0.7023930549621582,
    "learning_rate": 1.7961570593149542e-06,
    "epoch": 2.4611528822055138,
    "step": 9820
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.6211687326431274,
    "learning_rate": 1.7878028404344195e-06,
    "epoch": 2.463659147869674,
    "step": 9830
  },
  {
    "loss": 0.0247,
    "grad_norm": 0.5709470510482788,
    "learning_rate": 1.7794486215538847e-06,
    "epoch": 2.4661654135338344,
    "step": 9840
  },
  {
    "loss": 0.0217,
    "grad_norm": 0.2595890462398529,
    "learning_rate": 1.77109440267335e-06,
    "epoch": 2.468671679197995,
    "step": 9850
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.48021024465560913,
    "learning_rate": 1.7627401837928155e-06,
    "epoch": 2.4711779448621556,
    "step": 9860
  },
  {
    "loss": 0.0327,
    "grad_norm": 0.42119449377059937,
    "learning_rate": 1.7543859649122807e-06,
    "epoch": 2.473684210526316,
    "step": 9870
  },
  {
    "loss": 0.0274,
    "grad_norm": 0.2645619213581085,
    "learning_rate": 1.746031746031746e-06,
    "epoch": 2.4761904761904763,
    "step": 9880
  },
  {
    "loss": 0.0272,
    "grad_norm": 0.5356482863426208,
    "learning_rate": 1.7376775271512115e-06,
    "epoch": 2.4786967418546366,
    "step": 9890
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.6755302548408508,
    "learning_rate": 1.7293233082706767e-06,
    "epoch": 2.481203007518797,
    "step": 9900
  },
  {
    "loss": 0.0256,
    "grad_norm": 0.29442957043647766,
    "learning_rate": 1.720969089390142e-06,
    "epoch": 2.4837092731829573,
    "step": 9910
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.7748575806617737,
    "learning_rate": 1.7126148705096075e-06,
    "epoch": 2.4862155388471177,
    "step": 9920
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.3432294428348541,
    "learning_rate": 1.7042606516290728e-06,
    "epoch": 2.488721804511278,
    "step": 9930
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.6330589056015015,
    "learning_rate": 1.695906432748538e-06,
    "epoch": 2.4912280701754383,
    "step": 9940
  },
  {
    "loss": 0.0342,
    "grad_norm": 0.4399418532848358,
    "learning_rate": 1.6875522138680033e-06,
    "epoch": 2.493734335839599,
    "step": 9950
  },
  {
    "loss": 0.0366,
    "grad_norm": 0.4733338952064514,
    "learning_rate": 1.6791979949874688e-06,
    "epoch": 2.4962406015037595,
    "step": 9960
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.8313702940940857,
    "learning_rate": 1.670843776106934e-06,
    "epoch": 2.49874686716792,
    "step": 9970
  },
  {
    "loss": 0.0269,
    "grad_norm": 0.19477996230125427,
    "learning_rate": 1.6624895572263993e-06,
    "epoch": 2.50125313283208,
    "step": 9980
  },
  {
    "loss": 0.044,
    "grad_norm": 0.5216085910797119,
    "learning_rate": 1.6541353383458648e-06,
    "epoch": 2.5037593984962405,
    "step": 9990
  },
  {
    "loss": 0.0244,
    "grad_norm": 0.161115825176239,
    "learning_rate": 1.64578111946533e-06,
    "epoch": 2.506265664160401,
    "step": 10000
  },
  {
    "eval_loss": 0.03852172568440437,
    "eval_roc_auc_macro": 0.9901690294748281,
    "eval_runtime": 40.1132,
    "eval_samples_per_second": 795.624,
    "eval_steps_per_second": 24.88,
    "epoch": 2.506265664160401,
    "step": 10000
  },
  {
    "train_loss": 0.03173445910215378,
    "train_roc_auc_macro": 0.9929614618824703,
    "train_runtime": 160.2561,
    "train_samples_per_second": 796.575,
    "train_steps_per_second": 24.898,
    "epoch": 2.506265664160401,
    "step": 10000
  },
  {
    "loss": 0.0451,
    "grad_norm": 0.5975719690322876,
    "learning_rate": 1.6374269005847953e-06,
    "epoch": 2.5087719298245617,
    "step": 10010
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.6843013763427734,
    "learning_rate": 1.6290726817042608e-06,
    "epoch": 2.511278195488722,
    "step": 10020
  },
  {
    "loss": 0.0334,
    "grad_norm": 0.7418139576911926,
    "learning_rate": 1.620718462823726e-06,
    "epoch": 2.5137844611528823,
    "step": 10030
  },
  {
    "loss": 0.029,
    "grad_norm": 0.5631676912307739,
    "learning_rate": 1.6123642439431913e-06,
    "epoch": 2.5162907268170427,
    "step": 10040
  },
  {
    "loss": 0.0215,
    "grad_norm": 0.5840798616409302,
    "learning_rate": 1.6040100250626568e-06,
    "epoch": 2.518796992481203,
    "step": 10050
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.7225999236106873,
    "learning_rate": 1.595655806182122e-06,
    "epoch": 2.5213032581453634,
    "step": 10060
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.2939155399799347,
    "learning_rate": 1.5873015873015873e-06,
    "epoch": 2.5238095238095237,
    "step": 10070
  },
  {
    "loss": 0.0234,
    "grad_norm": 0.41485366225242615,
    "learning_rate": 1.5789473684210526e-06,
    "epoch": 2.526315789473684,
    "step": 10080
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.515923023223877,
    "learning_rate": 1.570593149540518e-06,
    "epoch": 2.5288220551378444,
    "step": 10090
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.44459083676338196,
    "learning_rate": 1.5622389306599833e-06,
    "epoch": 2.5313283208020048,
    "step": 10100
  },
  {
    "loss": 0.0318,
    "grad_norm": 0.42089396715164185,
    "learning_rate": 1.5538847117794486e-06,
    "epoch": 2.5338345864661656,
    "step": 10110
  },
  {
    "loss": 0.045,
    "grad_norm": 0.7969127893447876,
    "learning_rate": 1.545530492898914e-06,
    "epoch": 2.536340852130326,
    "step": 10120
  },
  {
    "loss": 0.0333,
    "grad_norm": 0.5975101590156555,
    "learning_rate": 1.5371762740183793e-06,
    "epoch": 2.5388471177944862,
    "step": 10130
  },
  {
    "loss": 0.0262,
    "grad_norm": 0.2964077591896057,
    "learning_rate": 1.5288220551378446e-06,
    "epoch": 2.5413533834586466,
    "step": 10140
  },
  {
    "loss": 0.0242,
    "grad_norm": 0.23749768733978271,
    "learning_rate": 1.52046783625731e-06,
    "epoch": 2.543859649122807,
    "step": 10150
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.6475991010665894,
    "learning_rate": 1.5121136173767753e-06,
    "epoch": 2.5463659147869673,
    "step": 10160
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.37045204639434814,
    "learning_rate": 1.5037593984962406e-06,
    "epoch": 2.548872180451128,
    "step": 10170
  },
  {
    "loss": 0.0217,
    "grad_norm": 0.42988210916519165,
    "learning_rate": 1.4954051796157059e-06,
    "epoch": 2.5513784461152884,
    "step": 10180
  },
  {
    "loss": 0.0291,
    "grad_norm": 0.4101215600967407,
    "learning_rate": 1.4870509607351713e-06,
    "epoch": 2.5538847117794488,
    "step": 10190
  },
  {
    "loss": 0.045,
    "grad_norm": 1.0115289688110352,
    "learning_rate": 1.4786967418546366e-06,
    "epoch": 2.556390977443609,
    "step": 10200
  },
  {
    "loss": 0.0369,
    "grad_norm": 0.16376230120658875,
    "learning_rate": 1.4703425229741019e-06,
    "epoch": 2.5588972431077694,
    "step": 10210
  },
  {
    "loss": 0.0268,
    "grad_norm": 0.3537858724594116,
    "learning_rate": 1.4619883040935674e-06,
    "epoch": 2.56140350877193,
    "step": 10220
  },
  {
    "loss": 0.0272,
    "grad_norm": 0.31141453981399536,
    "learning_rate": 1.4536340852130326e-06,
    "epoch": 2.56390977443609,
    "step": 10230
  },
  {
    "loss": 0.0258,
    "grad_norm": 0.49527403712272644,
    "learning_rate": 1.4452798663324979e-06,
    "epoch": 2.5664160401002505,
    "step": 10240
  },
  {
    "loss": 0.0284,
    "grad_norm": 0.31461194157600403,
    "learning_rate": 1.4369256474519634e-06,
    "epoch": 2.568922305764411,
    "step": 10250
  },
  {
    "eval_loss": 0.03699873760342598,
    "eval_roc_auc_macro": 0.9901110495958595,
    "eval_runtime": 40.2101,
    "eval_samples_per_second": 793.705,
    "eval_steps_per_second": 24.82,
    "epoch": 2.568922305764411,
    "step": 10250
  },
  {
    "train_loss": 0.030269498005509377,
    "train_roc_auc_macro": 0.9930948325422054,
    "train_runtime": 160.3848,
    "train_samples_per_second": 795.936,
    "train_steps_per_second": 24.878,
    "epoch": 2.568922305764411,
    "step": 10250
  },
  {
    "loss": 0.0335,
    "grad_norm": 1.208336591720581,
    "learning_rate": 1.4285714285714286e-06,
    "epoch": 2.571428571428571,
    "step": 10260
  },
  {
    "loss": 0.0413,
    "grad_norm": 0.32603511214256287,
    "learning_rate": 1.4202172096908939e-06,
    "epoch": 2.573934837092732,
    "step": 10270
  },
  {
    "loss": 0.0356,
    "grad_norm": 0.3202715814113617,
    "learning_rate": 1.4118629908103594e-06,
    "epoch": 2.5764411027568923,
    "step": 10280
  },
  {
    "loss": 0.0249,
    "grad_norm": 0.25523293018341064,
    "learning_rate": 1.4035087719298246e-06,
    "epoch": 2.5789473684210527,
    "step": 10290
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.4335561990737915,
    "learning_rate": 1.39515455304929e-06,
    "epoch": 2.581453634085213,
    "step": 10300
  },
  {
    "loss": 0.0283,
    "grad_norm": 0.5725107789039612,
    "learning_rate": 1.3868003341687552e-06,
    "epoch": 2.5839598997493733,
    "step": 10310
  },
  {
    "loss": 0.0442,
    "grad_norm": 0.7191370725631714,
    "learning_rate": 1.3784461152882206e-06,
    "epoch": 2.5864661654135337,
    "step": 10320
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.46912485361099243,
    "learning_rate": 1.370091896407686e-06,
    "epoch": 2.5889724310776945,
    "step": 10330
  },
  {
    "loss": 0.0224,
    "grad_norm": 0.2230214774608612,
    "learning_rate": 1.3617376775271512e-06,
    "epoch": 2.591478696741855,
    "step": 10340
  },
  {
    "loss": 0.0243,
    "grad_norm": 0.4991748631000519,
    "learning_rate": 1.3533834586466167e-06,
    "epoch": 2.593984962406015,
    "step": 10350
  },
  {
    "loss": 0.0412,
    "grad_norm": 0.6996052265167236,
    "learning_rate": 1.345029239766082e-06,
    "epoch": 2.5964912280701755,
    "step": 10360
  },
  {
    "loss": 0.0401,
    "grad_norm": 0.2376055270433426,
    "learning_rate": 1.3366750208855472e-06,
    "epoch": 2.598997493734336,
    "step": 10370
  },
  {
    "loss": 0.0356,
    "grad_norm": 0.31752845644950867,
    "learning_rate": 1.3283208020050127e-06,
    "epoch": 2.601503759398496,
    "step": 10380
  },
  {
    "loss": 0.0401,
    "grad_norm": 0.8117901682853699,
    "learning_rate": 1.319966583124478e-06,
    "epoch": 2.6040100250626566,
    "step": 10390
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.5920041799545288,
    "learning_rate": 1.3116123642439432e-06,
    "epoch": 2.606516290726817,
    "step": 10400
  },
  {
    "loss": 0.0406,
    "grad_norm": 0.4210878312587738,
    "learning_rate": 1.3032581453634085e-06,
    "epoch": 2.6090225563909772,
    "step": 10410
  },
  {
    "loss": 0.0291,
    "grad_norm": 0.8331306576728821,
    "learning_rate": 1.294903926482874e-06,
    "epoch": 2.6115288220551376,
    "step": 10420
  },
  {
    "loss": 0.0221,
    "grad_norm": 0.6671725511550903,
    "learning_rate": 1.2865497076023392e-06,
    "epoch": 2.6140350877192984,
    "step": 10430
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.78399258852005,
    "learning_rate": 1.2781954887218045e-06,
    "epoch": 2.6165413533834587,
    "step": 10440
  },
  {
    "loss": 0.0281,
    "grad_norm": 0.13355650007724762,
    "learning_rate": 1.26984126984127e-06,
    "epoch": 2.619047619047619,
    "step": 10450
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.2026764303445816,
    "learning_rate": 1.2614870509607352e-06,
    "epoch": 2.6215538847117794,
    "step": 10460
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.7874214053153992,
    "learning_rate": 1.2531328320802005e-06,
    "epoch": 2.6240601503759398,
    "step": 10470
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.7163360714912415,
    "learning_rate": 1.244778613199666e-06,
    "epoch": 2.6265664160401,
    "step": 10480
  },
  {
    "loss": 0.0229,
    "grad_norm": 0.6902948617935181,
    "learning_rate": 1.2364243943191312e-06,
    "epoch": 2.629072681704261,
    "step": 10490
  },
  {
    "loss": 0.0338,
    "grad_norm": 0.5255025625228882,
    "learning_rate": 1.2280701754385965e-06,
    "epoch": 2.6315789473684212,
    "step": 10500
  },
  {
    "eval_loss": 0.03777753561735153,
    "eval_roc_auc_macro": 0.9902457849914469,
    "eval_runtime": 40.1533,
    "eval_samples_per_second": 794.83,
    "eval_steps_per_second": 24.855,
    "epoch": 2.6315789473684212,
    "step": 10500
  },
  {
    "train_loss": 0.031074615195393562,
    "train_roc_auc_macro": 0.9932434721532751,
    "train_runtime": 160.2606,
    "train_samples_per_second": 796.553,
    "train_steps_per_second": 24.897,
    "epoch": 2.6315789473684212,
    "step": 10500
  },
  {
    "loss": 0.0304,
    "grad_norm": 1.0725170373916626,
    "learning_rate": 1.219715956558062e-06,
    "epoch": 2.6340852130325816,
    "step": 10510
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.6774224638938904,
    "learning_rate": 1.2113617376775272e-06,
    "epoch": 2.636591478696742,
    "step": 10520
  },
  {
    "loss": 0.0285,
    "grad_norm": 0.08452552556991577,
    "learning_rate": 1.2030075187969925e-06,
    "epoch": 2.6390977443609023,
    "step": 10530
  },
  {
    "loss": 0.0207,
    "grad_norm": 0.2273654192686081,
    "learning_rate": 1.1946532999164577e-06,
    "epoch": 2.6416040100250626,
    "step": 10540
  },
  {
    "loss": 0.0353,
    "grad_norm": 0.4464521110057831,
    "learning_rate": 1.1862990810359232e-06,
    "epoch": 2.644110275689223,
    "step": 10550
  },
  {
    "loss": 0.0285,
    "grad_norm": 0.5669863820075989,
    "learning_rate": 1.1779448621553885e-06,
    "epoch": 2.6466165413533833,
    "step": 10560
  },
  {
    "loss": 0.0266,
    "grad_norm": 0.27860790491104126,
    "learning_rate": 1.1695906432748538e-06,
    "epoch": 2.6491228070175437,
    "step": 10570
  },
  {
    "loss": 0.0294,
    "grad_norm": 0.6325942873954773,
    "learning_rate": 1.1612364243943192e-06,
    "epoch": 2.651629072681704,
    "step": 10580
  },
  {
    "loss": 0.0452,
    "grad_norm": 0.6738615036010742,
    "learning_rate": 1.1528822055137845e-06,
    "epoch": 2.654135338345865,
    "step": 10590
  },
  {
    "loss": 0.0262,
    "grad_norm": 0.9164474010467529,
    "learning_rate": 1.1445279866332498e-06,
    "epoch": 2.656641604010025,
    "step": 10600
  },
  {
    "loss": 0.0333,
    "grad_norm": 0.5691553950309753,
    "learning_rate": 1.1361737677527152e-06,
    "epoch": 2.6591478696741855,
    "step": 10610
  },
  {
    "loss": 0.0387,
    "grad_norm": 0.7242293357849121,
    "learning_rate": 1.1278195488721805e-06,
    "epoch": 2.661654135338346,
    "step": 10620
  },
  {
    "loss": 0.0283,
    "grad_norm": 0.1562175154685974,
    "learning_rate": 1.1194653299916458e-06,
    "epoch": 2.664160401002506,
    "step": 10630
  },
  {
    "loss": 0.0306,
    "grad_norm": 0.5204936861991882,
    "learning_rate": 1.111111111111111e-06,
    "epoch": 2.6666666666666665,
    "step": 10640
  },
  {
    "loss": 0.0269,
    "grad_norm": 0.5363943576812744,
    "learning_rate": 1.1027568922305765e-06,
    "epoch": 2.6691729323308273,
    "step": 10650
  },
  {
    "loss": 0.0304,
    "grad_norm": 0.46650922298431396,
    "learning_rate": 1.0944026733500418e-06,
    "epoch": 2.6716791979949877,
    "step": 10660
  },
  {
    "loss": 0.0202,
    "grad_norm": 0.42687714099884033,
    "learning_rate": 1.086048454469507e-06,
    "epoch": 2.674185463659148,
    "step": 10670
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.3603135645389557,
    "learning_rate": 1.0776942355889725e-06,
    "epoch": 2.6766917293233083,
    "step": 10680
  },
  {
    "loss": 0.0287,
    "grad_norm": 0.48576679825782776,
    "learning_rate": 1.0693400167084378e-06,
    "epoch": 2.6791979949874687,
    "step": 10690
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.8697581887245178,
    "learning_rate": 1.060985797827903e-06,
    "epoch": 2.681704260651629,
    "step": 10700
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.770537793636322,
    "learning_rate": 1.0526315789473685e-06,
    "epoch": 2.6842105263157894,
    "step": 10710
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.9888026118278503,
    "learning_rate": 1.0442773600668338e-06,
    "epoch": 2.6867167919799497,
    "step": 10720
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.47419336438179016,
    "learning_rate": 1.035923141186299e-06,
    "epoch": 2.68922305764411,
    "step": 10730
  },
  {
    "loss": 0.0454,
    "grad_norm": 0.6173542141914368,
    "learning_rate": 1.0275689223057645e-06,
    "epoch": 2.6917293233082704,
    "step": 10740
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.13347993791103363,
    "learning_rate": 1.0192147034252298e-06,
    "epoch": 2.694235588972431,
    "step": 10750
  },
  {
    "eval_loss": 0.03916085138916969,
    "eval_roc_auc_macro": 0.9901840417452107,
    "eval_runtime": 40.159,
    "eval_samples_per_second": 794.715,
    "eval_steps_per_second": 24.851,
    "epoch": 2.694235588972431,
    "step": 10750
  },
  {
    "train_loss": 0.03260062262415886,
    "train_roc_auc_macro": 0.993170855562051,
    "train_runtime": 160.248,
    "train_samples_per_second": 796.615,
    "train_steps_per_second": 24.899,
    "epoch": 2.694235588972431,
    "step": 10750
  },
  {
    "loss": 0.0441,
    "grad_norm": 0.4407140612602234,
    "learning_rate": 1.010860484544695e-06,
    "epoch": 2.6967418546365916,
    "step": 10760
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.17892833054065704,
    "learning_rate": 1.0025062656641603e-06,
    "epoch": 2.699248120300752,
    "step": 10770
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.3620603680610657,
    "learning_rate": 9.941520467836258e-07,
    "epoch": 2.7017543859649122,
    "step": 10780
  },
  {
    "loss": 0.0296,
    "grad_norm": 0.5335192084312439,
    "learning_rate": 9.85797827903091e-07,
    "epoch": 2.7042606516290726,
    "step": 10790
  },
  {
    "loss": 0.0393,
    "grad_norm": 0.6474443674087524,
    "learning_rate": 9.774436090225563e-07,
    "epoch": 2.706766917293233,
    "step": 10800
  },
  {
    "loss": 0.0356,
    "grad_norm": 0.2895991802215576,
    "learning_rate": 9.690893901420218e-07,
    "epoch": 2.7092731829573937,
    "step": 10810
  },
  {
    "loss": 0.0264,
    "grad_norm": 0.5545089840888977,
    "learning_rate": 9.60735171261487e-07,
    "epoch": 2.711779448621554,
    "step": 10820
  },
  {
    "loss": 0.0315,
    "grad_norm": 0.5178359150886536,
    "learning_rate": 9.523809523809525e-07,
    "epoch": 2.7142857142857144,
    "step": 10830
  },
  {
    "loss": 0.0256,
    "grad_norm": 0.18281468749046326,
    "learning_rate": 9.440267335004177e-07,
    "epoch": 2.7167919799498748,
    "step": 10840
  },
  {
    "loss": 0.0331,
    "grad_norm": 0.6440363526344299,
    "learning_rate": 9.356725146198831e-07,
    "epoch": 2.719298245614035,
    "step": 10850
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.4836181700229645,
    "learning_rate": 9.273182957393484e-07,
    "epoch": 2.7218045112781954,
    "step": 10860
  },
  {
    "loss": 0.0234,
    "grad_norm": 0.5847817659378052,
    "learning_rate": 9.189640768588137e-07,
    "epoch": 2.724310776942356,
    "step": 10870
  },
  {
    "loss": 0.0407,
    "grad_norm": 0.5536840558052063,
    "learning_rate": 9.106098579782791e-07,
    "epoch": 2.726817042606516,
    "step": 10880
  },
  {
    "loss": 0.027,
    "grad_norm": 0.5463034510612488,
    "learning_rate": 9.022556390977444e-07,
    "epoch": 2.7293233082706765,
    "step": 10890
  },
  {
    "loss": 0.0373,
    "grad_norm": 0.6974138617515564,
    "learning_rate": 8.939014202172097e-07,
    "epoch": 2.731829573934837,
    "step": 10900
  },
  {
    "loss": 0.0401,
    "grad_norm": 0.4186709225177765,
    "learning_rate": 8.85547201336675e-07,
    "epoch": 2.7343358395989976,
    "step": 10910
  },
  {
    "loss": 0.0366,
    "grad_norm": 0.4590812921524048,
    "learning_rate": 8.771929824561404e-07,
    "epoch": 2.736842105263158,
    "step": 10920
  },
  {
    "loss": 0.0285,
    "grad_norm": 0.5320370197296143,
    "learning_rate": 8.688387635756057e-07,
    "epoch": 2.7393483709273183,
    "step": 10930
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.6328586339950562,
    "learning_rate": 8.60484544695071e-07,
    "epoch": 2.7418546365914787,
    "step": 10940
  },
  {
    "loss": 0.0343,
    "grad_norm": 0.31527072191238403,
    "learning_rate": 8.521303258145364e-07,
    "epoch": 2.744360902255639,
    "step": 10950
  },
  {
    "loss": 0.0246,
    "grad_norm": 0.35475972294807434,
    "learning_rate": 8.437761069340016e-07,
    "epoch": 2.7468671679197993,
    "step": 10960
  },
  {
    "loss": 0.0253,
    "grad_norm": 0.759911835193634,
    "learning_rate": 8.35421888053467e-07,
    "epoch": 2.74937343358396,
    "step": 10970
  },
  {
    "loss": 0.0264,
    "grad_norm": 0.7111902236938477,
    "learning_rate": 8.270676691729324e-07,
    "epoch": 2.7518796992481205,
    "step": 10980
  },
  {
    "loss": 0.026,
    "grad_norm": 0.7312016487121582,
    "learning_rate": 8.187134502923977e-07,
    "epoch": 2.754385964912281,
    "step": 10990
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.46614912152290344,
    "learning_rate": 8.10359231411863e-07,
    "epoch": 2.756892230576441,
    "step": 11000
  },
  {
    "eval_loss": 0.03770887851715088,
    "eval_roc_auc_macro": 0.9903599484165811,
    "eval_runtime": 40.1521,
    "eval_samples_per_second": 794.852,
    "eval_steps_per_second": 24.855,
    "epoch": 2.756892230576441,
    "step": 11000
  },
  {
    "train_loss": 0.03093373402953148,
    "train_roc_auc_macro": 0.9933706984939062,
    "train_runtime": 160.3791,
    "train_samples_per_second": 795.964,
    "train_steps_per_second": 24.879,
    "epoch": 2.756892230576441,
    "step": 11000
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.37857872247695923,
    "learning_rate": 8.020050125313284e-07,
    "epoch": 2.7593984962406015,
    "step": 11010
  },
  {
    "loss": 0.029,
    "grad_norm": 0.4153284728527069,
    "learning_rate": 7.936507936507937e-07,
    "epoch": 2.761904761904762,
    "step": 11020
  },
  {
    "loss": 0.0318,
    "grad_norm": 0.48108094930648804,
    "learning_rate": 7.85296574770259e-07,
    "epoch": 2.764411027568922,
    "step": 11030
  },
  {
    "loss": 0.0296,
    "grad_norm": 0.6105935573577881,
    "learning_rate": 7.769423558897243e-07,
    "epoch": 2.7669172932330826,
    "step": 11040
  },
  {
    "loss": 0.0171,
    "grad_norm": 0.35096991062164307,
    "learning_rate": 7.685881370091897e-07,
    "epoch": 2.769423558897243,
    "step": 11050
  },
  {
    "loss": 0.0184,
    "grad_norm": 0.6389696002006531,
    "learning_rate": 7.60233918128655e-07,
    "epoch": 2.7719298245614032,
    "step": 11060
  },
  {
    "loss": 0.0387,
    "grad_norm": 0.7581750750541687,
    "learning_rate": 7.518796992481203e-07,
    "epoch": 2.774436090225564,
    "step": 11070
  },
  {
    "loss": 0.0488,
    "grad_norm": 0.8104375004768372,
    "learning_rate": 7.435254803675857e-07,
    "epoch": 2.7769423558897244,
    "step": 11080
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.23302358388900757,
    "learning_rate": 7.351712614870509e-07,
    "epoch": 2.7794486215538847,
    "step": 11090
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.369506299495697,
    "learning_rate": 7.268170426065163e-07,
    "epoch": 2.781954887218045,
    "step": 11100
  },
  {
    "loss": 0.029,
    "grad_norm": 0.5771329402923584,
    "learning_rate": 7.184628237259817e-07,
    "epoch": 2.7844611528822054,
    "step": 11110
  },
  {
    "loss": 0.0204,
    "grad_norm": 0.6270036101341248,
    "learning_rate": 7.101086048454469e-07,
    "epoch": 2.7869674185463658,
    "step": 11120
  },
  {
    "loss": 0.0279,
    "grad_norm": 0.3940190374851227,
    "learning_rate": 7.017543859649123e-07,
    "epoch": 2.7894736842105265,
    "step": 11130
  },
  {
    "loss": 0.0302,
    "grad_norm": 0.13619768619537354,
    "learning_rate": 6.934001670843776e-07,
    "epoch": 2.791979949874687,
    "step": 11140
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.7596838474273682,
    "learning_rate": 6.85045948203843e-07,
    "epoch": 2.7944862155388472,
    "step": 11150
  },
  {
    "loss": 0.0319,
    "grad_norm": 0.33400577306747437,
    "learning_rate": 6.766917293233083e-07,
    "epoch": 2.7969924812030076,
    "step": 11160
  },
  {
    "loss": 0.0164,
    "grad_norm": 0.41788339614868164,
    "learning_rate": 6.683375104427736e-07,
    "epoch": 2.799498746867168,
    "step": 11170
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.28214970231056213,
    "learning_rate": 6.59983291562239e-07,
    "epoch": 2.8020050125313283,
    "step": 11180
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.20420266687870026,
    "learning_rate": 6.516290726817042e-07,
    "epoch": 2.8045112781954886,
    "step": 11190
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.2402353584766388,
    "learning_rate": 6.432748538011696e-07,
    "epoch": 2.807017543859649,
    "step": 11200
  },
  {
    "loss": 0.0271,
    "grad_norm": 0.5748938918113708,
    "learning_rate": 6.34920634920635e-07,
    "epoch": 2.8095238095238093,
    "step": 11210
  },
  {
    "loss": 0.0298,
    "grad_norm": 0.3820054531097412,
    "learning_rate": 6.265664160401002e-07,
    "epoch": 2.8120300751879697,
    "step": 11220
  },
  {
    "loss": 0.0288,
    "grad_norm": 0.22443833947181702,
    "learning_rate": 6.182121971595656e-07,
    "epoch": 2.8145363408521304,
    "step": 11230
  },
  {
    "loss": 0.0236,
    "grad_norm": 0.21273809671401978,
    "learning_rate": 6.09857978279031e-07,
    "epoch": 2.817042606516291,
    "step": 11240
  },
  {
    "loss": 0.0293,
    "grad_norm": 0.6791328191757202,
    "learning_rate": 6.015037593984962e-07,
    "epoch": 2.819548872180451,
    "step": 11250
  },
  {
    "eval_loss": 0.037396904081106186,
    "eval_roc_auc_macro": 0.990357876950318,
    "eval_runtime": 40.2141,
    "eval_samples_per_second": 793.627,
    "eval_steps_per_second": 24.817,
    "epoch": 2.819548872180451,
    "step": 11250
  },
  {
    "train_loss": 0.030482323840260506,
    "train_roc_auc_macro": 0.9934161968592483,
    "train_runtime": 160.2059,
    "train_samples_per_second": 796.825,
    "train_steps_per_second": 24.905,
    "epoch": 2.819548872180451,
    "step": 11250
  },
  {
    "loss": 0.0251,
    "grad_norm": 0.4639235734939575,
    "learning_rate": 5.931495405179616e-07,
    "epoch": 2.8220551378446115,
    "step": 11260
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.3832920491695404,
    "learning_rate": 5.847953216374269e-07,
    "epoch": 2.824561403508772,
    "step": 11270
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.375301331281662,
    "learning_rate": 5.764411027568922e-07,
    "epoch": 2.827067669172932,
    "step": 11280
  },
  {
    "loss": 0.0363,
    "grad_norm": 0.4234493672847748,
    "learning_rate": 5.680868838763576e-07,
    "epoch": 2.829573934837093,
    "step": 11290
  },
  {
    "loss": 0.0261,
    "grad_norm": 0.20831497013568878,
    "learning_rate": 5.597326649958229e-07,
    "epoch": 2.8320802005012533,
    "step": 11300
  },
  {
    "loss": 0.0505,
    "grad_norm": 0.6363901495933533,
    "learning_rate": 5.513784461152883e-07,
    "epoch": 2.8345864661654137,
    "step": 11310
  },
  {
    "loss": 0.0183,
    "grad_norm": 0.1441032588481903,
    "learning_rate": 5.430242272347535e-07,
    "epoch": 2.837092731829574,
    "step": 11320
  },
  {
    "loss": 0.0318,
    "grad_norm": 0.23897814750671387,
    "learning_rate": 5.346700083542189e-07,
    "epoch": 2.8395989974937343,
    "step": 11330
  },
  {
    "loss": 0.0322,
    "grad_norm": 0.9074744582176208,
    "learning_rate": 5.263157894736843e-07,
    "epoch": 2.8421052631578947,
    "step": 11340
  },
  {
    "loss": 0.0277,
    "grad_norm": 0.6375564932823181,
    "learning_rate": 5.179615705931495e-07,
    "epoch": 2.844611528822055,
    "step": 11350
  },
  {
    "loss": 0.0451,
    "grad_norm": 0.5498541593551636,
    "learning_rate": 5.096073517126149e-07,
    "epoch": 2.8471177944862154,
    "step": 11360
  },
  {
    "loss": 0.041,
    "grad_norm": 0.3464641869068146,
    "learning_rate": 5.012531328320802e-07,
    "epoch": 2.8496240601503757,
    "step": 11370
  },
  {
    "loss": 0.0289,
    "grad_norm": 0.8505610823631287,
    "learning_rate": 4.928989139515455e-07,
    "epoch": 2.852130325814536,
    "step": 11380
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.8519689440727234,
    "learning_rate": 4.845446950710109e-07,
    "epoch": 2.854636591478697,
    "step": 11390
  },
  {
    "loss": 0.031,
    "grad_norm": 0.39750492572784424,
    "learning_rate": 4.7619047619047623e-07,
    "epoch": 2.857142857142857,
    "step": 11400
  },
  {
    "loss": 0.0296,
    "grad_norm": 0.41978397965431213,
    "learning_rate": 4.6783625730994155e-07,
    "epoch": 2.8596491228070176,
    "step": 11410
  },
  {
    "loss": 0.0202,
    "grad_norm": 0.4671071469783783,
    "learning_rate": 4.5948203842940686e-07,
    "epoch": 2.862155388471178,
    "step": 11420
  },
  {
    "loss": 0.0268,
    "grad_norm": 0.2790091037750244,
    "learning_rate": 4.511278195488722e-07,
    "epoch": 2.8646616541353382,
    "step": 11430
  },
  {
    "loss": 0.0278,
    "grad_norm": 0.28471317887306213,
    "learning_rate": 4.427736006683375e-07,
    "epoch": 2.8671679197994986,
    "step": 11440
  },
  {
    "loss": 0.0312,
    "grad_norm": 0.4978635311126709,
    "learning_rate": 4.3441938178780287e-07,
    "epoch": 2.8696741854636594,
    "step": 11450
  },
  {
    "loss": 0.0332,
    "grad_norm": 0.420259565114975,
    "learning_rate": 4.260651629072682e-07,
    "epoch": 2.8721804511278197,
    "step": 11460
  },
  {
    "loss": 0.0348,
    "grad_norm": 0.41147997975349426,
    "learning_rate": 4.177109440267335e-07,
    "epoch": 2.87468671679198,
    "step": 11470
  },
  {
    "loss": 0.0204,
    "grad_norm": 0.24851687252521515,
    "learning_rate": 4.093567251461988e-07,
    "epoch": 2.8771929824561404,
    "step": 11480
  },
  {
    "loss": 0.0331,
    "grad_norm": 0.5804381370544434,
    "learning_rate": 4.010025062656642e-07,
    "epoch": 2.8796992481203008,
    "step": 11490
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.4657159745693207,
    "learning_rate": 3.926482873851295e-07,
    "epoch": 2.882205513784461,
    "step": 11500
  },
  {
    "eval_loss": 0.037568800151348114,
    "eval_roc_auc_macro": 0.9903202013377582,
    "eval_runtime": 40.1589,
    "eval_samples_per_second": 794.718,
    "eval_steps_per_second": 24.851,
    "epoch": 2.882205513784461,
    "step": 11500
  },
  {
    "train_loss": 0.03067978471517563,
    "train_roc_auc_macro": 0.9934262504562977,
    "train_runtime": 160.1918,
    "train_samples_per_second": 796.895,
    "train_steps_per_second": 24.908,
    "epoch": 2.882205513784461,
    "step": 11500
  },
  {
    "loss": 0.0365,
    "grad_norm": 0.5864138007164001,
    "learning_rate": 3.8429406850459483e-07,
    "epoch": 2.8847117794486214,
    "step": 11510
  },
  {
    "loss": 0.0275,
    "grad_norm": 0.4554823637008667,
    "learning_rate": 3.7593984962406015e-07,
    "epoch": 2.887218045112782,
    "step": 11520
  },
  {
    "loss": 0.0299,
    "grad_norm": 0.5398305058479309,
    "learning_rate": 3.6758563074352547e-07,
    "epoch": 2.889724310776942,
    "step": 11530
  },
  {
    "loss": 0.036,
    "grad_norm": 0.501132607460022,
    "learning_rate": 3.5923141186299084e-07,
    "epoch": 2.8922305764411025,
    "step": 11540
  },
  {
    "loss": 0.0207,
    "grad_norm": 0.16459909081459045,
    "learning_rate": 3.5087719298245616e-07,
    "epoch": 2.8947368421052633,
    "step": 11550
  },
  {
    "loss": 0.0267,
    "grad_norm": 0.4563211500644684,
    "learning_rate": 3.425229741019215e-07,
    "epoch": 2.8972431077694236,
    "step": 11560
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.48846739530563354,
    "learning_rate": 3.341687552213868e-07,
    "epoch": 2.899749373433584,
    "step": 11570
  },
  {
    "loss": 0.0398,
    "grad_norm": 1.6213197708129883,
    "learning_rate": 3.258145363408521e-07,
    "epoch": 2.9022556390977443,
    "step": 11580
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.9542672038078308,
    "learning_rate": 3.174603174603175e-07,
    "epoch": 2.9047619047619047,
    "step": 11590
  },
  {
    "loss": 0.0346,
    "grad_norm": 0.37002578377723694,
    "learning_rate": 3.091060985797828e-07,
    "epoch": 2.907268170426065,
    "step": 11600
  },
  {
    "loss": 0.022,
    "grad_norm": 0.3984764516353607,
    "learning_rate": 3.007518796992481e-07,
    "epoch": 2.909774436090226,
    "step": 11610
  },
  {
    "loss": 0.0256,
    "grad_norm": 0.34438571333885193,
    "learning_rate": 2.9239766081871344e-07,
    "epoch": 2.912280701754386,
    "step": 11620
  },
  {
    "loss": 0.032,
    "grad_norm": 0.51559978723526,
    "learning_rate": 2.840434419381788e-07,
    "epoch": 2.9147869674185465,
    "step": 11630
  },
  {
    "loss": 0.0248,
    "grad_norm": 0.16446341574192047,
    "learning_rate": 2.7568922305764413e-07,
    "epoch": 2.917293233082707,
    "step": 11640
  },
  {
    "loss": 0.0306,
    "grad_norm": 0.7420496940612793,
    "learning_rate": 2.6733500417710945e-07,
    "epoch": 2.919799498746867,
    "step": 11650
  },
  {
    "loss": 0.0353,
    "grad_norm": 0.9776769280433655,
    "learning_rate": 2.5898078529657476e-07,
    "epoch": 2.9223057644110275,
    "step": 11660
  },
  {
    "loss": 0.0261,
    "grad_norm": 0.7282204627990723,
    "learning_rate": 2.506265664160401e-07,
    "epoch": 2.924812030075188,
    "step": 11670
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.5655794739723206,
    "learning_rate": 2.4227234753550545e-07,
    "epoch": 2.927318295739348,
    "step": 11680
  },
  {
    "loss": 0.0312,
    "grad_norm": 0.5939706563949585,
    "learning_rate": 2.3391812865497077e-07,
    "epoch": 2.9298245614035086,
    "step": 11690
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.3767237663269043,
    "learning_rate": 2.255639097744361e-07,
    "epoch": 2.932330827067669,
    "step": 11700
  },
  {
    "loss": 0.029,
    "grad_norm": 0.3110455870628357,
    "learning_rate": 2.1720969089390144e-07,
    "epoch": 2.9348370927318297,
    "step": 11710
  },
  {
    "loss": 0.0319,
    "grad_norm": 0.30223768949508667,
    "learning_rate": 2.0885547201336675e-07,
    "epoch": 2.93734335839599,
    "step": 11720
  },
  {
    "loss": 0.0348,
    "grad_norm": 0.35296234488487244,
    "learning_rate": 2.005012531328321e-07,
    "epoch": 2.9398496240601504,
    "step": 11730
  },
  {
    "loss": 0.0182,
    "grad_norm": 0.3200439512729645,
    "learning_rate": 1.9214703425229742e-07,
    "epoch": 2.9423558897243107,
    "step": 11740
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.13579075038433075,
    "learning_rate": 1.8379281537176273e-07,
    "epoch": 2.944862155388471,
    "step": 11750
  },
  {
    "eval_loss": 0.03731177747249603,
    "eval_roc_auc_macro": 0.9903528816169284,
    "eval_runtime": 40.1899,
    "eval_samples_per_second": 794.105,
    "eval_steps_per_second": 24.832,
    "epoch": 2.944862155388471,
    "step": 11750
  },
  {
    "train_loss": 0.030162736773490906,
    "train_roc_auc_macro": 0.9934294974929267,
    "train_runtime": 160.2288,
    "train_samples_per_second": 796.711,
    "train_steps_per_second": 24.902,
    "epoch": 2.944862155388471,
    "step": 11750
  },
  {
    "loss": 0.0202,
    "grad_norm": 0.4836093783378601,
    "learning_rate": 1.7543859649122808e-07,
    "epoch": 2.9473684210526314,
    "step": 11760
  },
  {
    "loss": 0.0304,
    "grad_norm": 0.7386309504508972,
    "learning_rate": 1.670843776106934e-07,
    "epoch": 2.949874686716792,
    "step": 11770
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.7879928350448608,
    "learning_rate": 1.5873015873015874e-07,
    "epoch": 2.9523809523809526,
    "step": 11780
  },
  {
    "loss": 0.0247,
    "grad_norm": 0.8872471451759338,
    "learning_rate": 1.5037593984962406e-07,
    "epoch": 2.954887218045113,
    "step": 11790
  },
  {
    "loss": 0.0167,
    "grad_norm": 0.30444708466529846,
    "learning_rate": 1.420217209690894e-07,
    "epoch": 2.9573934837092732,
    "step": 11800
  },
  {
    "loss": 0.0468,
    "grad_norm": 0.9338070154190063,
    "learning_rate": 1.3366750208855472e-07,
    "epoch": 2.9598997493734336,
    "step": 11810
  },
  {
    "loss": 0.0281,
    "grad_norm": 0.4727936089038849,
    "learning_rate": 1.2531328320802004e-07,
    "epoch": 2.962406015037594,
    "step": 11820
  },
  {
    "loss": 0.0392,
    "grad_norm": 0.35716962814331055,
    "learning_rate": 1.1695906432748539e-07,
    "epoch": 2.9649122807017543,
    "step": 11830
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.28577086329460144,
    "learning_rate": 1.0860484544695072e-07,
    "epoch": 2.9674185463659146,
    "step": 11840
  },
  {
    "loss": 0.034,
    "grad_norm": 0.09829504787921906,
    "learning_rate": 1.0025062656641605e-07,
    "epoch": 2.969924812030075,
    "step": 11850
  },
  {
    "loss": 0.0369,
    "grad_norm": 0.3248502016067505,
    "learning_rate": 9.189640768588137e-08,
    "epoch": 2.9724310776942353,
    "step": 11860
  },
  {
    "loss": 0.0297,
    "grad_norm": 0.657076358795166,
    "learning_rate": 8.35421888053467e-08,
    "epoch": 2.974937343358396,
    "step": 11870
  },
  {
    "loss": 0.0233,
    "grad_norm": 0.3253311812877655,
    "learning_rate": 7.518796992481203e-08,
    "epoch": 2.9774436090225564,
    "step": 11880
  },
  {
    "loss": 0.0298,
    "grad_norm": 0.9060254693031311,
    "learning_rate": 6.683375104427736e-08,
    "epoch": 2.979949874686717,
    "step": 11890
  },
  {
    "loss": 0.0302,
    "grad_norm": 1.2086280584335327,
    "learning_rate": 5.847953216374269e-08,
    "epoch": 2.982456140350877,
    "step": 11900
  },
  {
    "loss": 0.0276,
    "grad_norm": 0.8438724875450134,
    "learning_rate": 5.0125313283208025e-08,
    "epoch": 2.9849624060150375,
    "step": 11910
  },
  {
    "loss": 0.0311,
    "grad_norm": 0.9647027850151062,
    "learning_rate": 4.177109440267335e-08,
    "epoch": 2.987468671679198,
    "step": 11920
  },
  {
    "loss": 0.0343,
    "grad_norm": 0.5393106341362,
    "learning_rate": 3.341687552213868e-08,
    "epoch": 2.9899749373433586,
    "step": 11930
  },
  {
    "loss": 0.037,
    "grad_norm": 0.4040217101573944,
    "learning_rate": 2.5062656641604012e-08,
    "epoch": 2.992481203007519,
    "step": 11940
  },
  {
    "loss": 0.0392,
    "grad_norm": 1.09925377368927,
    "learning_rate": 1.670843776106934e-08,
    "epoch": 2.9949874686716793,
    "step": 11950
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.32008999586105347,
    "learning_rate": 8.35421888053467e-09,
    "epoch": 2.9974937343358397,
    "step": 11960
  },
  {
    "loss": 0.032,
    "grad_norm": 0.7862289547920227,
    "learning_rate": 0.0,
    "epoch": 3.0,
    "step": 11970
  },
  {
    "train_runtime": 11227.6129,
    "train_samples_per_second": 34.109,
    "train_steps_per_second": 1.066,
    "total_flos": 5.038427028212122e+16,
    "train_loss": 0.040644366379419566,
    "epoch": 3.0,
    "step": 11970
  }
]