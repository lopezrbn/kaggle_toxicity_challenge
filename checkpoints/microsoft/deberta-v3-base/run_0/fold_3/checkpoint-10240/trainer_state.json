{
  "best_metric": 0.9900226678585309,
  "best_model_checkpoint": "checkpoints/microsoft/deberta-v3-base/fold_3/checkpoint-10240",
  "epoch": 2.5664160401002505,
  "eval_steps": 2048,
  "global_step": 10240,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012531328320802004,
      "grad_norm": 1.50016450881958,
      "learning_rate": 9.958228905597328e-06,
      "loss": 0.483,
      "step": 50
    },
    {
      "epoch": 0.02506265664160401,
      "grad_norm": 0.7972807288169861,
      "learning_rate": 9.916457811194654e-06,
      "loss": 0.1711,
      "step": 100
    },
    {
      "epoch": 0.03759398496240601,
      "grad_norm": 0.39620932936668396,
      "learning_rate": 9.87468671679198e-06,
      "loss": 0.1086,
      "step": 150
    },
    {
      "epoch": 0.05012531328320802,
      "grad_norm": 0.39581477642059326,
      "learning_rate": 9.832915622389308e-06,
      "loss": 0.0825,
      "step": 200
    },
    {
      "epoch": 0.06265664160401002,
      "grad_norm": 0.7469569444656372,
      "learning_rate": 9.791144527986633e-06,
      "loss": 0.0688,
      "step": 250
    },
    {
      "epoch": 0.07518796992481203,
      "grad_norm": 0.7693713903427124,
      "learning_rate": 9.749373433583961e-06,
      "loss": 0.0614,
      "step": 300
    },
    {
      "epoch": 0.08771929824561403,
      "grad_norm": 0.3354478180408478,
      "learning_rate": 9.707602339181286e-06,
      "loss": 0.0536,
      "step": 350
    },
    {
      "epoch": 0.10025062656641603,
      "grad_norm": 0.7113072276115417,
      "learning_rate": 9.665831244778615e-06,
      "loss": 0.0594,
      "step": 400
    },
    {
      "epoch": 0.11278195488721804,
      "grad_norm": 0.751029908657074,
      "learning_rate": 9.62406015037594e-06,
      "loss": 0.0567,
      "step": 450
    },
    {
      "epoch": 0.12531328320802004,
      "grad_norm": 0.5735636949539185,
      "learning_rate": 9.582289055973267e-06,
      "loss": 0.0501,
      "step": 500
    },
    {
      "epoch": 0.13784461152882205,
      "grad_norm": 1.0619261264801025,
      "learning_rate": 9.540517961570593e-06,
      "loss": 0.044,
      "step": 550
    },
    {
      "epoch": 0.15037593984962405,
      "grad_norm": 0.6579523086547852,
      "learning_rate": 9.49874686716792e-06,
      "loss": 0.0432,
      "step": 600
    },
    {
      "epoch": 0.16290726817042606,
      "grad_norm": 0.4451639652252197,
      "learning_rate": 9.456975772765247e-06,
      "loss": 0.0535,
      "step": 650
    },
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 0.3289870321750641,
      "learning_rate": 9.415204678362574e-06,
      "loss": 0.0489,
      "step": 700
    },
    {
      "epoch": 0.18796992481203006,
      "grad_norm": 0.3336046636104584,
      "learning_rate": 9.3734335839599e-06,
      "loss": 0.0436,
      "step": 750
    },
    {
      "epoch": 0.20050125313283207,
      "grad_norm": 0.3662491738796234,
      "learning_rate": 9.331662489557227e-06,
      "loss": 0.0449,
      "step": 800
    },
    {
      "epoch": 0.21303258145363407,
      "grad_norm": 1.0740591287612915,
      "learning_rate": 9.289891395154554e-06,
      "loss": 0.0449,
      "step": 850
    },
    {
      "epoch": 0.22556390977443608,
      "grad_norm": 0.3982132375240326,
      "learning_rate": 9.24812030075188e-06,
      "loss": 0.0458,
      "step": 900
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 0.4694053530693054,
      "learning_rate": 9.206349206349207e-06,
      "loss": 0.0396,
      "step": 950
    },
    {
      "epoch": 0.2506265664160401,
      "grad_norm": 0.7609370946884155,
      "learning_rate": 9.164578111946534e-06,
      "loss": 0.0488,
      "step": 1000
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 0.37435612082481384,
      "learning_rate": 9.12280701754386e-06,
      "loss": 0.051,
      "step": 1050
    },
    {
      "epoch": 0.2756892230576441,
      "grad_norm": 0.5921792387962341,
      "learning_rate": 9.081035923141188e-06,
      "loss": 0.0461,
      "step": 1100
    },
    {
      "epoch": 0.2882205513784461,
      "grad_norm": 0.5937215685844421,
      "learning_rate": 9.039264828738513e-06,
      "loss": 0.0473,
      "step": 1150
    },
    {
      "epoch": 0.3007518796992481,
      "grad_norm": 1.0917446613311768,
      "learning_rate": 8.997493734335841e-06,
      "loss": 0.0429,
      "step": 1200
    },
    {
      "epoch": 0.3132832080200501,
      "grad_norm": 0.46937310695648193,
      "learning_rate": 8.955722639933166e-06,
      "loss": 0.0412,
      "step": 1250
    },
    {
      "epoch": 0.3258145363408521,
      "grad_norm": 0.4972187578678131,
      "learning_rate": 8.913951545530493e-06,
      "loss": 0.0453,
      "step": 1300
    },
    {
      "epoch": 0.3383458646616541,
      "grad_norm": 0.3736644983291626,
      "learning_rate": 8.87218045112782e-06,
      "loss": 0.0477,
      "step": 1350
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.8129123449325562,
      "learning_rate": 8.830409356725146e-06,
      "loss": 0.0487,
      "step": 1400
    },
    {
      "epoch": 0.3634085213032581,
      "grad_norm": 0.5598111748695374,
      "learning_rate": 8.788638262322473e-06,
      "loss": 0.0457,
      "step": 1450
    },
    {
      "epoch": 0.37593984962406013,
      "grad_norm": 0.5041198134422302,
      "learning_rate": 8.7468671679198e-06,
      "loss": 0.0415,
      "step": 1500
    },
    {
      "epoch": 0.38847117794486213,
      "grad_norm": 0.8720322847366333,
      "learning_rate": 8.705096073517127e-06,
      "loss": 0.0449,
      "step": 1550
    },
    {
      "epoch": 0.40100250626566414,
      "grad_norm": 0.3607367277145386,
      "learning_rate": 8.663324979114453e-06,
      "loss": 0.0475,
      "step": 1600
    },
    {
      "epoch": 0.41353383458646614,
      "grad_norm": 0.2995574176311493,
      "learning_rate": 8.62155388471178e-06,
      "loss": 0.048,
      "step": 1650
    },
    {
      "epoch": 0.42606516290726815,
      "grad_norm": 0.5700094699859619,
      "learning_rate": 8.579782790309107e-06,
      "loss": 0.0437,
      "step": 1700
    },
    {
      "epoch": 0.43859649122807015,
      "grad_norm": 0.8153439164161682,
      "learning_rate": 8.538011695906434e-06,
      "loss": 0.0421,
      "step": 1750
    },
    {
      "epoch": 0.45112781954887216,
      "grad_norm": 0.39466145634651184,
      "learning_rate": 8.49624060150376e-06,
      "loss": 0.0423,
      "step": 1800
    },
    {
      "epoch": 0.46365914786967416,
      "grad_norm": 0.8748339414596558,
      "learning_rate": 8.454469507101085e-06,
      "loss": 0.043,
      "step": 1850
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 0.5152288675308228,
      "learning_rate": 8.412698412698414e-06,
      "loss": 0.0414,
      "step": 1900
    },
    {
      "epoch": 0.48872180451127817,
      "grad_norm": 1.0420788526535034,
      "learning_rate": 8.370927318295739e-06,
      "loss": 0.0332,
      "step": 1950
    },
    {
      "epoch": 0.5012531328320802,
      "grad_norm": 0.24533577263355255,
      "learning_rate": 8.329156223893067e-06,
      "loss": 0.041,
      "step": 2000
    },
    {
      "epoch": 0.5132832080200501,
      "eval_loss": 0.042854759842157364,
      "eval_roc_auc_macro": 0.9800485637061978,
      "eval_runtime": 205.0906,
      "eval_samples_per_second": 155.614,
      "eval_steps_per_second": 4.866,
      "step": 2048
    },
    {
      "epoch": 0.5137844611528822,
      "grad_norm": 0.8912257552146912,
      "learning_rate": 8.287385129490392e-06,
      "loss": 0.0416,
      "step": 2050
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 0.7380490899085999,
      "learning_rate": 8.24561403508772e-06,
      "loss": 0.0432,
      "step": 2100
    },
    {
      "epoch": 0.5388471177944862,
      "grad_norm": 0.4562911093235016,
      "learning_rate": 8.203842940685046e-06,
      "loss": 0.0512,
      "step": 2150
    },
    {
      "epoch": 0.5513784461152882,
      "grad_norm": 0.7343425154685974,
      "learning_rate": 8.162071846282373e-06,
      "loss": 0.0437,
      "step": 2200
    },
    {
      "epoch": 0.5639097744360902,
      "grad_norm": 0.9330258965492249,
      "learning_rate": 8.1203007518797e-06,
      "loss": 0.0369,
      "step": 2250
    },
    {
      "epoch": 0.5764411027568922,
      "grad_norm": 0.3054485023021698,
      "learning_rate": 8.078529657477026e-06,
      "loss": 0.039,
      "step": 2300
    },
    {
      "epoch": 0.5889724310776943,
      "grad_norm": 0.44990062713623047,
      "learning_rate": 8.036758563074353e-06,
      "loss": 0.0396,
      "step": 2350
    },
    {
      "epoch": 0.6015037593984962,
      "grad_norm": 0.43769338726997375,
      "learning_rate": 7.99498746867168e-06,
      "loss": 0.0441,
      "step": 2400
    },
    {
      "epoch": 0.6140350877192983,
      "grad_norm": 0.5956687331199646,
      "learning_rate": 7.953216374269006e-06,
      "loss": 0.0436,
      "step": 2450
    },
    {
      "epoch": 0.6265664160401002,
      "grad_norm": 0.32028424739837646,
      "learning_rate": 7.911445279866333e-06,
      "loss": 0.0501,
      "step": 2500
    },
    {
      "epoch": 0.6390977443609023,
      "grad_norm": 0.4148586392402649,
      "learning_rate": 7.86967418546366e-06,
      "loss": 0.04,
      "step": 2550
    },
    {
      "epoch": 0.6516290726817042,
      "grad_norm": 0.29938775300979614,
      "learning_rate": 7.827903091060987e-06,
      "loss": 0.0428,
      "step": 2600
    },
    {
      "epoch": 0.6641604010025063,
      "grad_norm": 0.31848207116127014,
      "learning_rate": 7.786131996658313e-06,
      "loss": 0.0433,
      "step": 2650
    },
    {
      "epoch": 0.6766917293233082,
      "grad_norm": 0.3074900805950165,
      "learning_rate": 7.74436090225564e-06,
      "loss": 0.042,
      "step": 2700
    },
    {
      "epoch": 0.6892230576441103,
      "grad_norm": 0.5543693900108337,
      "learning_rate": 7.702589807852965e-06,
      "loss": 0.04,
      "step": 2750
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.17382006347179413,
      "learning_rate": 7.660818713450294e-06,
      "loss": 0.037,
      "step": 2800
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.6775243878364563,
      "learning_rate": 7.61904761904762e-06,
      "loss": 0.0438,
      "step": 2850
    },
    {
      "epoch": 0.7268170426065163,
      "grad_norm": 0.4491253197193146,
      "learning_rate": 7.577276524644946e-06,
      "loss": 0.0455,
      "step": 2900
    },
    {
      "epoch": 0.7393483709273183,
      "grad_norm": 0.3457690179347992,
      "learning_rate": 7.535505430242272e-06,
      "loss": 0.0456,
      "step": 2950
    },
    {
      "epoch": 0.7518796992481203,
      "grad_norm": 0.39497342705726624,
      "learning_rate": 7.4937343358396e-06,
      "loss": 0.0371,
      "step": 3000
    },
    {
      "epoch": 0.7644110275689223,
      "grad_norm": 0.477537602186203,
      "learning_rate": 7.451963241436926e-06,
      "loss": 0.0492,
      "step": 3050
    },
    {
      "epoch": 0.7769423558897243,
      "grad_norm": 0.5832775235176086,
      "learning_rate": 7.410192147034253e-06,
      "loss": 0.0418,
      "step": 3100
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.43685710430145264,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0386,
      "step": 3150
    },
    {
      "epoch": 0.8020050125313283,
      "grad_norm": 0.3691268861293793,
      "learning_rate": 7.326649958228906e-06,
      "loss": 0.0423,
      "step": 3200
    },
    {
      "epoch": 0.8145363408521303,
      "grad_norm": 0.8567330837249756,
      "learning_rate": 7.284878863826233e-06,
      "loss": 0.0452,
      "step": 3250
    },
    {
      "epoch": 0.8270676691729323,
      "grad_norm": 0.48553863167762756,
      "learning_rate": 7.2431077694235595e-06,
      "loss": 0.0389,
      "step": 3300
    },
    {
      "epoch": 0.8395989974937343,
      "grad_norm": 0.3075849413871765,
      "learning_rate": 7.2013366750208854e-06,
      "loss": 0.0397,
      "step": 3350
    },
    {
      "epoch": 0.8521303258145363,
      "grad_norm": 1.0784523487091064,
      "learning_rate": 7.159565580618213e-06,
      "loss": 0.0323,
      "step": 3400
    },
    {
      "epoch": 0.8646616541353384,
      "grad_norm": 0.4490525424480438,
      "learning_rate": 7.117794486215539e-06,
      "loss": 0.0378,
      "step": 3450
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 0.5601378083229065,
      "learning_rate": 7.0760233918128665e-06,
      "loss": 0.0402,
      "step": 3500
    },
    {
      "epoch": 0.8897243107769424,
      "grad_norm": 0.8927842974662781,
      "learning_rate": 7.0342522974101924e-06,
      "loss": 0.0408,
      "step": 3550
    },
    {
      "epoch": 0.9022556390977443,
      "grad_norm": 0.2859978675842285,
      "learning_rate": 6.992481203007519e-06,
      "loss": 0.0395,
      "step": 3600
    },
    {
      "epoch": 0.9147869674185464,
      "grad_norm": 0.44441139698028564,
      "learning_rate": 6.950710108604846e-06,
      "loss": 0.0442,
      "step": 3650
    },
    {
      "epoch": 0.9273182957393483,
      "grad_norm": 0.6817256212234497,
      "learning_rate": 6.908939014202173e-06,
      "loss": 0.0425,
      "step": 3700
    },
    {
      "epoch": 0.9398496240601504,
      "grad_norm": 0.9003338813781738,
      "learning_rate": 6.867167919799499e-06,
      "loss": 0.0481,
      "step": 3750
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.32879018783569336,
      "learning_rate": 6.825396825396826e-06,
      "loss": 0.0414,
      "step": 3800
    },
    {
      "epoch": 0.9649122807017544,
      "grad_norm": 0.3982410430908203,
      "learning_rate": 6.783625730994152e-06,
      "loss": 0.0406,
      "step": 3850
    },
    {
      "epoch": 0.9774436090225563,
      "grad_norm": 0.17258690297603607,
      "learning_rate": 6.74185463659148e-06,
      "loss": 0.0378,
      "step": 3900
    },
    {
      "epoch": 0.9899749373433584,
      "grad_norm": 0.4303897023200989,
      "learning_rate": 6.700083542188806e-06,
      "loss": 0.0373,
      "step": 3950
    },
    {
      "epoch": 1.0025062656641603,
      "grad_norm": 0.5235496163368225,
      "learning_rate": 6.658312447786132e-06,
      "loss": 0.0391,
      "step": 4000
    },
    {
      "epoch": 1.0150375939849625,
      "grad_norm": 0.40508127212524414,
      "learning_rate": 6.616541353383459e-06,
      "loss": 0.0379,
      "step": 4050
    },
    {
      "epoch": 1.0265664160401002,
      "eval_loss": 0.04089922085404396,
      "eval_roc_auc_macro": 0.9855774545527636,
      "eval_runtime": 205.4514,
      "eval_samples_per_second": 155.341,
      "eval_steps_per_second": 4.858,
      "step": 4096
    },
    {
      "epoch": 1.0275689223057645,
      "grad_norm": 0.25279948115348816,
      "learning_rate": 6.574770258980786e-06,
      "loss": 0.0389,
      "step": 4100
    },
    {
      "epoch": 1.0401002506265664,
      "grad_norm": 0.2922361195087433,
      "learning_rate": 6.532999164578112e-06,
      "loss": 0.0381,
      "step": 4150
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 1.005252718925476,
      "learning_rate": 6.491228070175439e-06,
      "loss": 0.0405,
      "step": 4200
    },
    {
      "epoch": 1.0651629072681703,
      "grad_norm": 0.6467723846435547,
      "learning_rate": 6.449456975772765e-06,
      "loss": 0.0389,
      "step": 4250
    },
    {
      "epoch": 1.0776942355889725,
      "grad_norm": 0.8791892528533936,
      "learning_rate": 6.407685881370093e-06,
      "loss": 0.035,
      "step": 4300
    },
    {
      "epoch": 1.0902255639097744,
      "grad_norm": 0.4353872239589691,
      "learning_rate": 6.365914786967419e-06,
      "loss": 0.0378,
      "step": 4350
    },
    {
      "epoch": 1.1027568922305764,
      "grad_norm": 0.5425330996513367,
      "learning_rate": 6.324143692564746e-06,
      "loss": 0.0429,
      "step": 4400
    },
    {
      "epoch": 1.1152882205513786,
      "grad_norm": 0.38693875074386597,
      "learning_rate": 6.282372598162072e-06,
      "loss": 0.0348,
      "step": 4450
    },
    {
      "epoch": 1.1278195488721805,
      "grad_norm": 0.21245020627975464,
      "learning_rate": 6.240601503759399e-06,
      "loss": 0.0388,
      "step": 4500
    },
    {
      "epoch": 1.1403508771929824,
      "grad_norm": 0.8144527077674866,
      "learning_rate": 6.198830409356725e-06,
      "loss": 0.0364,
      "step": 4550
    },
    {
      "epoch": 1.1528822055137844,
      "grad_norm": 0.32393044233322144,
      "learning_rate": 6.1570593149540525e-06,
      "loss": 0.0368,
      "step": 4600
    },
    {
      "epoch": 1.1654135338345863,
      "grad_norm": 0.5118604302406311,
      "learning_rate": 6.115288220551378e-06,
      "loss": 0.043,
      "step": 4650
    },
    {
      "epoch": 1.1779448621553885,
      "grad_norm": 0.3607121407985687,
      "learning_rate": 6.073517126148706e-06,
      "loss": 0.0393,
      "step": 4700
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.024451324716210365,
      "learning_rate": 6.031746031746032e-06,
      "loss": 0.0336,
      "step": 4750
    },
    {
      "epoch": 1.2030075187969924,
      "grad_norm": 0.5412734150886536,
      "learning_rate": 5.9899749373433595e-06,
      "loss": 0.0389,
      "step": 4800
    },
    {
      "epoch": 1.2155388471177946,
      "grad_norm": 0.5995043516159058,
      "learning_rate": 5.948203842940685e-06,
      "loss": 0.035,
      "step": 4850
    },
    {
      "epoch": 1.2280701754385965,
      "grad_norm": 0.30055347084999084,
      "learning_rate": 5.906432748538012e-06,
      "loss": 0.0329,
      "step": 4900
    },
    {
      "epoch": 1.2406015037593985,
      "grad_norm": 0.36447253823280334,
      "learning_rate": 5.864661654135339e-06,
      "loss": 0.0323,
      "step": 4950
    },
    {
      "epoch": 1.2531328320802004,
      "grad_norm": 0.5999072790145874,
      "learning_rate": 5.822890559732666e-06,
      "loss": 0.0328,
      "step": 5000
    },
    {
      "epoch": 1.2656641604010024,
      "grad_norm": 0.46675679087638855,
      "learning_rate": 5.7811194653299915e-06,
      "loss": 0.0375,
      "step": 5050
    },
    {
      "epoch": 1.2781954887218046,
      "grad_norm": 0.7216480374336243,
      "learning_rate": 5.739348370927319e-06,
      "loss": 0.0378,
      "step": 5100
    },
    {
      "epoch": 1.2907268170426065,
      "grad_norm": 0.02561361715197563,
      "learning_rate": 5.697577276524645e-06,
      "loss": 0.0317,
      "step": 5150
    },
    {
      "epoch": 1.3032581453634084,
      "grad_norm": 0.6552239656448364,
      "learning_rate": 5.655806182121973e-06,
      "loss": 0.0352,
      "step": 5200
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.38601407408714294,
      "learning_rate": 5.6140350877192985e-06,
      "loss": 0.0304,
      "step": 5250
    },
    {
      "epoch": 1.3283208020050126,
      "grad_norm": 0.30575793981552124,
      "learning_rate": 5.572263993316625e-06,
      "loss": 0.0371,
      "step": 5300
    },
    {
      "epoch": 1.3408521303258145,
      "grad_norm": 0.23468659818172455,
      "learning_rate": 5.530492898913952e-06,
      "loss": 0.0396,
      "step": 5350
    },
    {
      "epoch": 1.3533834586466165,
      "grad_norm": 0.4065181016921997,
      "learning_rate": 5.488721804511279e-06,
      "loss": 0.0322,
      "step": 5400
    },
    {
      "epoch": 1.3659147869674184,
      "grad_norm": 0.46222802996635437,
      "learning_rate": 5.446950710108605e-06,
      "loss": 0.0378,
      "step": 5450
    },
    {
      "epoch": 1.3784461152882206,
      "grad_norm": 0.4779195487499237,
      "learning_rate": 5.405179615705932e-06,
      "loss": 0.0322,
      "step": 5500
    },
    {
      "epoch": 1.3909774436090225,
      "grad_norm": 0.26653116941452026,
      "learning_rate": 5.363408521303258e-06,
      "loss": 0.0351,
      "step": 5550
    },
    {
      "epoch": 1.4035087719298245,
      "grad_norm": 0.2960876524448395,
      "learning_rate": 5.321637426900586e-06,
      "loss": 0.0334,
      "step": 5600
    },
    {
      "epoch": 1.4160401002506267,
      "grad_norm": 0.8372505903244019,
      "learning_rate": 5.279866332497912e-06,
      "loss": 0.0336,
      "step": 5650
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.5404213070869446,
      "learning_rate": 5.2380952380952384e-06,
      "loss": 0.0371,
      "step": 5700
    },
    {
      "epoch": 1.4411027568922306,
      "grad_norm": 0.9646403193473816,
      "learning_rate": 5.196324143692565e-06,
      "loss": 0.0377,
      "step": 5750
    },
    {
      "epoch": 1.4536340852130325,
      "grad_norm": 0.4611656665802002,
      "learning_rate": 5.154553049289892e-06,
      "loss": 0.0397,
      "step": 5800
    },
    {
      "epoch": 1.4661654135338344,
      "grad_norm": 0.3520549237728119,
      "learning_rate": 5.112781954887218e-06,
      "loss": 0.0423,
      "step": 5850
    },
    {
      "epoch": 1.4786967418546366,
      "grad_norm": 0.40404996275901794,
      "learning_rate": 5.0710108604845454e-06,
      "loss": 0.0394,
      "step": 5900
    },
    {
      "epoch": 1.4912280701754386,
      "grad_norm": 0.3148086369037628,
      "learning_rate": 5.029239766081871e-06,
      "loss": 0.0334,
      "step": 5950
    },
    {
      "epoch": 1.5037593984962405,
      "grad_norm": 0.7916272878646851,
      "learning_rate": 4.987468671679198e-06,
      "loss": 0.0384,
      "step": 6000
    },
    {
      "epoch": 1.5162907268170427,
      "grad_norm": 0.5831426382064819,
      "learning_rate": 4.945697577276525e-06,
      "loss": 0.0344,
      "step": 6050
    },
    {
      "epoch": 1.5288220551378446,
      "grad_norm": 0.31679216027259827,
      "learning_rate": 4.903926482873852e-06,
      "loss": 0.0364,
      "step": 6100
    },
    {
      "epoch": 1.5398496240601505,
      "eval_loss": 0.03990728780627251,
      "eval_roc_auc_macro": 0.9885541932029568,
      "eval_runtime": 205.2709,
      "eval_samples_per_second": 155.477,
      "eval_steps_per_second": 4.862,
      "step": 6144
    },
    {
      "epoch": 1.5413533834586466,
      "grad_norm": 0.9289356470108032,
      "learning_rate": 4.862155388471178e-06,
      "loss": 0.0327,
      "step": 6150
    },
    {
      "epoch": 1.5538847117794488,
      "grad_norm": 0.1624455749988556,
      "learning_rate": 4.820384294068505e-06,
      "loss": 0.0391,
      "step": 6200
    },
    {
      "epoch": 1.5664160401002505,
      "grad_norm": 0.44478839635849,
      "learning_rate": 4.778613199665831e-06,
      "loss": 0.0359,
      "step": 6250
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 0.3778977394104004,
      "learning_rate": 4.736842105263158e-06,
      "loss": 0.0331,
      "step": 6300
    },
    {
      "epoch": 1.5914786967418546,
      "grad_norm": 0.1471123993396759,
      "learning_rate": 4.6950710108604845e-06,
      "loss": 0.0343,
      "step": 6350
    },
    {
      "epoch": 1.6040100250626566,
      "grad_norm": 0.6749012470245361,
      "learning_rate": 4.653299916457811e-06,
      "loss": 0.0352,
      "step": 6400
    },
    {
      "epoch": 1.6165413533834587,
      "grad_norm": 0.2905793786048889,
      "learning_rate": 4.611528822055138e-06,
      "loss": 0.0373,
      "step": 6450
    },
    {
      "epoch": 1.6290726817042607,
      "grad_norm": 0.40672746300697327,
      "learning_rate": 4.569757727652465e-06,
      "loss": 0.0334,
      "step": 6500
    },
    {
      "epoch": 1.6416040100250626,
      "grad_norm": 1.3996355533599854,
      "learning_rate": 4.5279866332497915e-06,
      "loss": 0.0331,
      "step": 6550
    },
    {
      "epoch": 1.6541353383458648,
      "grad_norm": 0.6457287073135376,
      "learning_rate": 4.486215538847118e-06,
      "loss": 0.0326,
      "step": 6600
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.34787654876708984,
      "learning_rate": 4.444444444444444e-06,
      "loss": 0.0294,
      "step": 6650
    },
    {
      "epoch": 1.6791979949874687,
      "grad_norm": 0.29062941670417786,
      "learning_rate": 4.402673350041771e-06,
      "loss": 0.0464,
      "step": 6700
    },
    {
      "epoch": 1.6917293233082706,
      "grad_norm": 0.7618814706802368,
      "learning_rate": 4.360902255639098e-06,
      "loss": 0.0377,
      "step": 6750
    },
    {
      "epoch": 1.7042606516290726,
      "grad_norm": 0.4722866714000702,
      "learning_rate": 4.319131161236424e-06,
      "loss": 0.0397,
      "step": 6800
    },
    {
      "epoch": 1.7167919799498748,
      "grad_norm": 0.32760024070739746,
      "learning_rate": 4.277360066833751e-06,
      "loss": 0.0326,
      "step": 6850
    },
    {
      "epoch": 1.7293233082706767,
      "grad_norm": 0.5484768748283386,
      "learning_rate": 4.235588972431078e-06,
      "loss": 0.0361,
      "step": 6900
    },
    {
      "epoch": 1.7418546365914787,
      "grad_norm": 0.4624728262424469,
      "learning_rate": 4.193817878028405e-06,
      "loss": 0.0399,
      "step": 6950
    },
    {
      "epoch": 1.7543859649122808,
      "grad_norm": 0.8783512711524963,
      "learning_rate": 4.152046783625731e-06,
      "loss": 0.0345,
      "step": 7000
    },
    {
      "epoch": 1.7669172932330826,
      "grad_norm": 0.818062961101532,
      "learning_rate": 4.110275689223058e-06,
      "loss": 0.0318,
      "step": 7050
    },
    {
      "epoch": 1.7794486215538847,
      "grad_norm": 0.6123325228691101,
      "learning_rate": 4.068504594820384e-06,
      "loss": 0.0378,
      "step": 7100
    },
    {
      "epoch": 1.7919799498746867,
      "grad_norm": 0.7007585763931274,
      "learning_rate": 4.026733500417711e-06,
      "loss": 0.0306,
      "step": 7150
    },
    {
      "epoch": 1.8045112781954886,
      "grad_norm": 0.490296334028244,
      "learning_rate": 3.9849624060150376e-06,
      "loss": 0.0344,
      "step": 7200
    },
    {
      "epoch": 1.8170426065162908,
      "grad_norm": 0.654496431350708,
      "learning_rate": 3.943191311612364e-06,
      "loss": 0.0363,
      "step": 7250
    },
    {
      "epoch": 1.8295739348370927,
      "grad_norm": 0.34424981474876404,
      "learning_rate": 3.901420217209691e-06,
      "loss": 0.0315,
      "step": 7300
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 0.7323870658874512,
      "learning_rate": 3.859649122807018e-06,
      "loss": 0.0374,
      "step": 7350
    },
    {
      "epoch": 1.8546365914786969,
      "grad_norm": 0.4897249937057495,
      "learning_rate": 3.8178780284043446e-06,
      "loss": 0.0298,
      "step": 7400
    },
    {
      "epoch": 1.8671679197994986,
      "grad_norm": 0.5809547305107117,
      "learning_rate": 3.776106934001671e-06,
      "loss": 0.0352,
      "step": 7450
    },
    {
      "epoch": 1.8796992481203008,
      "grad_norm": 0.42910444736480713,
      "learning_rate": 3.7343358395989976e-06,
      "loss": 0.0334,
      "step": 7500
    },
    {
      "epoch": 1.8922305764411027,
      "grad_norm": 0.3250572383403778,
      "learning_rate": 3.6925647451963244e-06,
      "loss": 0.0304,
      "step": 7550
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 0.20117437839508057,
      "learning_rate": 3.6507936507936507e-06,
      "loss": 0.0319,
      "step": 7600
    },
    {
      "epoch": 1.9172932330827068,
      "grad_norm": 0.19741195440292358,
      "learning_rate": 3.6090225563909775e-06,
      "loss": 0.0423,
      "step": 7650
    },
    {
      "epoch": 1.9298245614035088,
      "grad_norm": 0.2251666635274887,
      "learning_rate": 3.567251461988304e-06,
      "loss": 0.035,
      "step": 7700
    },
    {
      "epoch": 1.9423558897243107,
      "grad_norm": 0.07495496422052383,
      "learning_rate": 3.525480367585631e-06,
      "loss": 0.0351,
      "step": 7750
    },
    {
      "epoch": 1.954887218045113,
      "grad_norm": 0.4537632167339325,
      "learning_rate": 3.4837092731829573e-06,
      "loss": 0.0312,
      "step": 7800
    },
    {
      "epoch": 1.9674185463659146,
      "grad_norm": 0.21735209226608276,
      "learning_rate": 3.441938178780284e-06,
      "loss": 0.0351,
      "step": 7850
    },
    {
      "epoch": 1.9799498746867168,
      "grad_norm": 0.6255443692207336,
      "learning_rate": 3.4001670843776108e-06,
      "loss": 0.0333,
      "step": 7900
    },
    {
      "epoch": 1.9924812030075187,
      "grad_norm": 0.4998700022697449,
      "learning_rate": 3.3583959899749375e-06,
      "loss": 0.0278,
      "step": 7950
    },
    {
      "epoch": 2.0050125313283207,
      "grad_norm": 0.1261240392923355,
      "learning_rate": 3.3166248955722643e-06,
      "loss": 0.0362,
      "step": 8000
    },
    {
      "epoch": 2.017543859649123,
      "grad_norm": 0.38606253266334534,
      "learning_rate": 3.2748538011695906e-06,
      "loss": 0.0382,
      "step": 8050
    },
    {
      "epoch": 2.030075187969925,
      "grad_norm": 0.5654016137123108,
      "learning_rate": 3.2330827067669174e-06,
      "loss": 0.0262,
      "step": 8100
    },
    {
      "epoch": 2.0426065162907268,
      "grad_norm": 1.1164287328720093,
      "learning_rate": 3.191311612364244e-06,
      "loss": 0.0318,
      "step": 8150
    },
    {
      "epoch": 2.0531328320802005,
      "eval_loss": 0.03843051940202713,
      "eval_roc_auc_macro": 0.9890502697248168,
      "eval_runtime": 205.1578,
      "eval_samples_per_second": 155.563,
      "eval_steps_per_second": 4.865,
      "step": 8192
    },
    {
      "epoch": 2.055137844611529,
      "grad_norm": 0.2855725884437561,
      "learning_rate": 3.149540517961571e-06,
      "loss": 0.0325,
      "step": 8200
    },
    {
      "epoch": 2.0676691729323307,
      "grad_norm": 0.5965391397476196,
      "learning_rate": 3.107769423558897e-06,
      "loss": 0.0338,
      "step": 8250
    },
    {
      "epoch": 2.080200501253133,
      "grad_norm": 0.7605625987052917,
      "learning_rate": 3.065998329156224e-06,
      "loss": 0.0329,
      "step": 8300
    },
    {
      "epoch": 2.092731829573935,
      "grad_norm": 0.5887974500656128,
      "learning_rate": 3.0242272347535507e-06,
      "loss": 0.0322,
      "step": 8350
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 1.4295824766159058,
      "learning_rate": 2.9824561403508774e-06,
      "loss": 0.0291,
      "step": 8400
    },
    {
      "epoch": 2.117794486215539,
      "grad_norm": 0.5438517928123474,
      "learning_rate": 2.9406850459482038e-06,
      "loss": 0.032,
      "step": 8450
    },
    {
      "epoch": 2.1303258145363406,
      "grad_norm": 0.2152388095855713,
      "learning_rate": 2.8989139515455305e-06,
      "loss": 0.0258,
      "step": 8500
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.5519949793815613,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.0313,
      "step": 8550
    },
    {
      "epoch": 2.155388471177945,
      "grad_norm": 0.29579034447669983,
      "learning_rate": 2.815371762740184e-06,
      "loss": 0.0287,
      "step": 8600
    },
    {
      "epoch": 2.1679197994987467,
      "grad_norm": 0.8419066071510315,
      "learning_rate": 2.7736006683375103e-06,
      "loss": 0.0339,
      "step": 8650
    },
    {
      "epoch": 2.180451127819549,
      "grad_norm": 0.3512049615383148,
      "learning_rate": 2.731829573934837e-06,
      "loss": 0.0341,
      "step": 8700
    },
    {
      "epoch": 2.192982456140351,
      "grad_norm": 0.6037883162498474,
      "learning_rate": 2.690058479532164e-06,
      "loss": 0.0262,
      "step": 8750
    },
    {
      "epoch": 2.2055137844611528,
      "grad_norm": 1.1755012273788452,
      "learning_rate": 2.6482873851294906e-06,
      "loss": 0.0294,
      "step": 8800
    },
    {
      "epoch": 2.218045112781955,
      "grad_norm": 0.8621319532394409,
      "learning_rate": 2.606516290726817e-06,
      "loss": 0.0315,
      "step": 8850
    },
    {
      "epoch": 2.230576441102757,
      "grad_norm": 0.4970499873161316,
      "learning_rate": 2.5647451963241437e-06,
      "loss": 0.0313,
      "step": 8900
    },
    {
      "epoch": 2.243107769423559,
      "grad_norm": 0.45494797825813293,
      "learning_rate": 2.5229741019214704e-06,
      "loss": 0.0341,
      "step": 8950
    },
    {
      "epoch": 2.255639097744361,
      "grad_norm": 0.1720077097415924,
      "learning_rate": 2.481203007518797e-06,
      "loss": 0.0258,
      "step": 9000
    },
    {
      "epoch": 2.2681704260651627,
      "grad_norm": 0.5138341188430786,
      "learning_rate": 2.439431913116124e-06,
      "loss": 0.033,
      "step": 9050
    },
    {
      "epoch": 2.280701754385965,
      "grad_norm": 0.6126503944396973,
      "learning_rate": 2.3976608187134502e-06,
      "loss": 0.0285,
      "step": 9100
    },
    {
      "epoch": 2.293233082706767,
      "grad_norm": 0.5290638208389282,
      "learning_rate": 2.355889724310777e-06,
      "loss": 0.0334,
      "step": 9150
    },
    {
      "epoch": 2.305764411027569,
      "grad_norm": 0.6185222268104553,
      "learning_rate": 2.3141186299081037e-06,
      "loss": 0.0323,
      "step": 9200
    },
    {
      "epoch": 2.318295739348371,
      "grad_norm": 0.35758957266807556,
      "learning_rate": 2.2723475355054305e-06,
      "loss": 0.0303,
      "step": 9250
    },
    {
      "epoch": 2.3308270676691727,
      "grad_norm": 0.4987870156764984,
      "learning_rate": 2.230576441102757e-06,
      "loss": 0.0336,
      "step": 9300
    },
    {
      "epoch": 2.343358395989975,
      "grad_norm": 0.4643130302429199,
      "learning_rate": 2.1888053467000836e-06,
      "loss": 0.026,
      "step": 9350
    },
    {
      "epoch": 2.355889724310777,
      "grad_norm": 0.8211076855659485,
      "learning_rate": 2.1470342522974103e-06,
      "loss": 0.0305,
      "step": 9400
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 0.29751479625701904,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.0281,
      "step": 9450
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.39281296730041504,
      "learning_rate": 2.0634920634920634e-06,
      "loss": 0.0315,
      "step": 9500
    },
    {
      "epoch": 2.393483709273183,
      "grad_norm": 0.744412362575531,
      "learning_rate": 2.02172096908939e-06,
      "loss": 0.0307,
      "step": 9550
    },
    {
      "epoch": 2.406015037593985,
      "grad_norm": 0.5602295398712158,
      "learning_rate": 1.979949874686717e-06,
      "loss": 0.0349,
      "step": 9600
    },
    {
      "epoch": 2.418546365914787,
      "grad_norm": 0.4343479573726654,
      "learning_rate": 1.9381787802840436e-06,
      "loss": 0.0289,
      "step": 9650
    },
    {
      "epoch": 2.431077694235589,
      "grad_norm": 0.35688477754592896,
      "learning_rate": 1.8964076858813702e-06,
      "loss": 0.0321,
      "step": 9700
    },
    {
      "epoch": 2.443609022556391,
      "grad_norm": 0.6827260255813599,
      "learning_rate": 1.8546365914786967e-06,
      "loss": 0.0313,
      "step": 9750
    },
    {
      "epoch": 2.456140350877193,
      "grad_norm": 1.488417387008667,
      "learning_rate": 1.8128654970760235e-06,
      "loss": 0.0333,
      "step": 9800
    },
    {
      "epoch": 2.468671679197995,
      "grad_norm": 0.3463316261768341,
      "learning_rate": 1.77109440267335e-06,
      "loss": 0.0319,
      "step": 9850
    },
    {
      "epoch": 2.481203007518797,
      "grad_norm": 0.42110612988471985,
      "learning_rate": 1.7293233082706767e-06,
      "loss": 0.0308,
      "step": 9900
    },
    {
      "epoch": 2.493734335839599,
      "grad_norm": 0.26423871517181396,
      "learning_rate": 1.6875522138680033e-06,
      "loss": 0.034,
      "step": 9950
    },
    {
      "epoch": 2.506265664160401,
      "grad_norm": 0.08491396903991699,
      "learning_rate": 1.64578111946533e-06,
      "loss": 0.0334,
      "step": 10000
    },
    {
      "epoch": 2.518796992481203,
      "grad_norm": 0.24617736041545868,
      "learning_rate": 1.6040100250626568e-06,
      "loss": 0.0296,
      "step": 10050
    },
    {
      "epoch": 2.5313283208020048,
      "grad_norm": 0.7930958271026611,
      "learning_rate": 1.5622389306599833e-06,
      "loss": 0.0274,
      "step": 10100
    },
    {
      "epoch": 2.543859649122807,
      "grad_norm": 0.43870437145233154,
      "learning_rate": 1.52046783625731e-06,
      "loss": 0.0321,
      "step": 10150
    },
    {
      "epoch": 2.556390977443609,
      "grad_norm": 0.5685437321662903,
      "learning_rate": 1.4786967418546366e-06,
      "loss": 0.0353,
      "step": 10200
    },
    {
      "epoch": 2.5664160401002505,
      "eval_loss": 0.03727053105831146,
      "eval_roc_auc_macro": 0.9900226678585309,
      "eval_runtime": 205.2786,
      "eval_samples_per_second": 155.472,
      "eval_steps_per_second": 4.862,
      "step": 10240
    }
  ],
  "logging_steps": 50,
  "max_steps": 11970,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2048,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.310412160042598e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
