{
  "best_metric": 0.988389049763495,
  "best_model_checkpoint": "checkpoints/microsoft/deberta-v3-base/fold_4/checkpoint-4096",
  "epoch": 1.0265664160401002,
  "eval_steps": 2048,
  "global_step": 4096,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012531328320802004,
      "grad_norm": 1.8084521293640137,
      "learning_rate": 9.958228905597328e-06,
      "loss": 0.4862,
      "step": 50
    },
    {
      "epoch": 0.02506265664160401,
      "grad_norm": 0.5436710119247437,
      "learning_rate": 9.916457811194654e-06,
      "loss": 0.1776,
      "step": 100
    },
    {
      "epoch": 0.03759398496240601,
      "grad_norm": 0.5082206726074219,
      "learning_rate": 9.87468671679198e-06,
      "loss": 0.1176,
      "step": 150
    },
    {
      "epoch": 0.05012531328320802,
      "grad_norm": 0.5639649629592896,
      "learning_rate": 9.832915622389308e-06,
      "loss": 0.088,
      "step": 200
    },
    {
      "epoch": 0.06265664160401002,
      "grad_norm": 0.33497241139411926,
      "learning_rate": 9.791144527986633e-06,
      "loss": 0.0626,
      "step": 250
    },
    {
      "epoch": 0.07518796992481203,
      "grad_norm": 0.4259442687034607,
      "learning_rate": 9.749373433583961e-06,
      "loss": 0.0588,
      "step": 300
    },
    {
      "epoch": 0.08771929824561403,
      "grad_norm": 0.7760387659072876,
      "learning_rate": 9.707602339181286e-06,
      "loss": 0.0581,
      "step": 350
    },
    {
      "epoch": 0.10025062656641603,
      "grad_norm": 0.7786241173744202,
      "learning_rate": 9.665831244778615e-06,
      "loss": 0.0507,
      "step": 400
    },
    {
      "epoch": 0.11278195488721804,
      "grad_norm": 0.4364984631538391,
      "learning_rate": 9.62406015037594e-06,
      "loss": 0.0486,
      "step": 450
    },
    {
      "epoch": 0.12531328320802004,
      "grad_norm": 0.7650657892227173,
      "learning_rate": 9.582289055973267e-06,
      "loss": 0.0556,
      "step": 500
    },
    {
      "epoch": 0.13784461152882205,
      "grad_norm": 0.8297820687294006,
      "learning_rate": 9.540517961570593e-06,
      "loss": 0.0533,
      "step": 550
    },
    {
      "epoch": 0.15037593984962405,
      "grad_norm": 0.4075804650783539,
      "learning_rate": 9.49874686716792e-06,
      "loss": 0.0487,
      "step": 600
    },
    {
      "epoch": 0.16290726817042606,
      "grad_norm": 0.6505123972892761,
      "learning_rate": 9.456975772765247e-06,
      "loss": 0.0497,
      "step": 650
    },
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 0.5129314064979553,
      "learning_rate": 9.415204678362574e-06,
      "loss": 0.0468,
      "step": 700
    },
    {
      "epoch": 0.18796992481203006,
      "grad_norm": 0.8783798217773438,
      "learning_rate": 9.3734335839599e-06,
      "loss": 0.0473,
      "step": 750
    },
    {
      "epoch": 0.20050125313283207,
      "grad_norm": 0.6311241984367371,
      "learning_rate": 9.331662489557227e-06,
      "loss": 0.0418,
      "step": 800
    },
    {
      "epoch": 0.21303258145363407,
      "grad_norm": 0.37381845712661743,
      "learning_rate": 9.289891395154554e-06,
      "loss": 0.0424,
      "step": 850
    },
    {
      "epoch": 0.22556390977443608,
      "grad_norm": 0.3396286368370056,
      "learning_rate": 9.24812030075188e-06,
      "loss": 0.0524,
      "step": 900
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 0.43401604890823364,
      "learning_rate": 9.206349206349207e-06,
      "loss": 0.0487,
      "step": 950
    },
    {
      "epoch": 0.2506265664160401,
      "grad_norm": 0.37987834215164185,
      "learning_rate": 9.164578111946534e-06,
      "loss": 0.0492,
      "step": 1000
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 0.744529664516449,
      "learning_rate": 9.12280701754386e-06,
      "loss": 0.0432,
      "step": 1050
    },
    {
      "epoch": 0.2756892230576441,
      "grad_norm": 0.31447485089302063,
      "learning_rate": 9.081035923141188e-06,
      "loss": 0.0462,
      "step": 1100
    },
    {
      "epoch": 0.2882205513784461,
      "grad_norm": 0.3806232511997223,
      "learning_rate": 9.039264828738513e-06,
      "loss": 0.0486,
      "step": 1150
    },
    {
      "epoch": 0.3007518796992481,
      "grad_norm": 0.31607359647750854,
      "learning_rate": 8.997493734335841e-06,
      "loss": 0.0468,
      "step": 1200
    },
    {
      "epoch": 0.3132832080200501,
      "grad_norm": 0.6941623687744141,
      "learning_rate": 8.955722639933166e-06,
      "loss": 0.0421,
      "step": 1250
    },
    {
      "epoch": 0.3258145363408521,
      "grad_norm": 0.5330937504768372,
      "learning_rate": 8.913951545530493e-06,
      "loss": 0.0454,
      "step": 1300
    },
    {
      "epoch": 0.3383458646616541,
      "grad_norm": 0.5928820371627808,
      "learning_rate": 8.87218045112782e-06,
      "loss": 0.0402,
      "step": 1350
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.36352768540382385,
      "learning_rate": 8.830409356725146e-06,
      "loss": 0.0395,
      "step": 1400
    },
    {
      "epoch": 0.3634085213032581,
      "grad_norm": 0.48478463292121887,
      "learning_rate": 8.788638262322473e-06,
      "loss": 0.0477,
      "step": 1450
    },
    {
      "epoch": 0.37593984962406013,
      "grad_norm": 0.388150691986084,
      "learning_rate": 8.7468671679198e-06,
      "loss": 0.046,
      "step": 1500
    },
    {
      "epoch": 0.38847117794486213,
      "grad_norm": 0.505228579044342,
      "learning_rate": 8.705096073517127e-06,
      "loss": 0.0436,
      "step": 1550
    },
    {
      "epoch": 0.40100250626566414,
      "grad_norm": 0.652536153793335,
      "learning_rate": 8.663324979114453e-06,
      "loss": 0.0405,
      "step": 1600
    },
    {
      "epoch": 0.41353383458646614,
      "grad_norm": 0.18035836517810822,
      "learning_rate": 8.62155388471178e-06,
      "loss": 0.047,
      "step": 1650
    },
    {
      "epoch": 0.42606516290726815,
      "grad_norm": 0.509881854057312,
      "learning_rate": 8.579782790309107e-06,
      "loss": 0.0464,
      "step": 1700
    },
    {
      "epoch": 0.43859649122807015,
      "grad_norm": 0.4107625484466553,
      "learning_rate": 8.538011695906434e-06,
      "loss": 0.0423,
      "step": 1750
    },
    {
      "epoch": 0.45112781954887216,
      "grad_norm": 0.19405093789100647,
      "learning_rate": 8.49624060150376e-06,
      "loss": 0.0372,
      "step": 1800
    },
    {
      "epoch": 0.46365914786967416,
      "grad_norm": 0.7683060765266418,
      "learning_rate": 8.454469507101085e-06,
      "loss": 0.0407,
      "step": 1850
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 0.3879780173301697,
      "learning_rate": 8.412698412698414e-06,
      "loss": 0.0398,
      "step": 1900
    },
    {
      "epoch": 0.48872180451127817,
      "grad_norm": 0.5383102297782898,
      "learning_rate": 8.370927318295739e-06,
      "loss": 0.0486,
      "step": 1950
    },
    {
      "epoch": 0.5012531328320802,
      "grad_norm": 0.47342151403427124,
      "learning_rate": 8.329156223893067e-06,
      "loss": 0.0376,
      "step": 2000
    },
    {
      "epoch": 0.5132832080200501,
      "eval_loss": 0.049338437616825104,
      "eval_roc_auc_macro": 0.9823229352320473,
      "eval_runtime": 205.1994,
      "eval_samples_per_second": 155.512,
      "eval_steps_per_second": 4.864,
      "step": 2048
    },
    {
      "epoch": 0.5137844611528822,
      "grad_norm": 0.3356001377105713,
      "learning_rate": 8.287385129490392e-06,
      "loss": 0.0438,
      "step": 2050
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 0.0891415998339653,
      "learning_rate": 8.24561403508772e-06,
      "loss": 0.042,
      "step": 2100
    },
    {
      "epoch": 0.5388471177944862,
      "grad_norm": 1.0676987171173096,
      "learning_rate": 8.203842940685046e-06,
      "loss": 0.0351,
      "step": 2150
    },
    {
      "epoch": 0.5513784461152882,
      "grad_norm": 0.64323490858078,
      "learning_rate": 8.162071846282373e-06,
      "loss": 0.0444,
      "step": 2200
    },
    {
      "epoch": 0.5639097744360902,
      "grad_norm": 0.7462549209594727,
      "learning_rate": 8.1203007518797e-06,
      "loss": 0.0388,
      "step": 2250
    },
    {
      "epoch": 0.5764411027568922,
      "grad_norm": 0.3625158965587616,
      "learning_rate": 8.078529657477026e-06,
      "loss": 0.0383,
      "step": 2300
    },
    {
      "epoch": 0.5889724310776943,
      "grad_norm": 0.5813345909118652,
      "learning_rate": 8.036758563074353e-06,
      "loss": 0.0441,
      "step": 2350
    },
    {
      "epoch": 0.6015037593984962,
      "grad_norm": 0.3367924690246582,
      "learning_rate": 7.99498746867168e-06,
      "loss": 0.0436,
      "step": 2400
    },
    {
      "epoch": 0.6140350877192983,
      "grad_norm": 0.4483126401901245,
      "learning_rate": 7.953216374269006e-06,
      "loss": 0.0435,
      "step": 2450
    },
    {
      "epoch": 0.6265664160401002,
      "grad_norm": 0.8029713034629822,
      "learning_rate": 7.911445279866333e-06,
      "loss": 0.0428,
      "step": 2500
    },
    {
      "epoch": 0.6390977443609023,
      "grad_norm": 0.6795172691345215,
      "learning_rate": 7.86967418546366e-06,
      "loss": 0.0462,
      "step": 2550
    },
    {
      "epoch": 0.6516290726817042,
      "grad_norm": 0.46561530232429504,
      "learning_rate": 7.827903091060987e-06,
      "loss": 0.0446,
      "step": 2600
    },
    {
      "epoch": 0.6641604010025063,
      "grad_norm": 0.6652255654335022,
      "learning_rate": 7.786131996658313e-06,
      "loss": 0.0391,
      "step": 2650
    },
    {
      "epoch": 0.6766917293233082,
      "grad_norm": 0.29180508852005005,
      "learning_rate": 7.74436090225564e-06,
      "loss": 0.0414,
      "step": 2700
    },
    {
      "epoch": 0.6892230576441103,
      "grad_norm": 0.6450728178024292,
      "learning_rate": 7.702589807852965e-06,
      "loss": 0.0407,
      "step": 2750
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.5378121733665466,
      "learning_rate": 7.660818713450294e-06,
      "loss": 0.0383,
      "step": 2800
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.45167276263237,
      "learning_rate": 7.61904761904762e-06,
      "loss": 0.0433,
      "step": 2850
    },
    {
      "epoch": 0.7268170426065163,
      "grad_norm": 0.33260324597358704,
      "learning_rate": 7.577276524644946e-06,
      "loss": 0.0435,
      "step": 2900
    },
    {
      "epoch": 0.7393483709273183,
      "grad_norm": 0.30296289920806885,
      "learning_rate": 7.535505430242272e-06,
      "loss": 0.0379,
      "step": 2950
    },
    {
      "epoch": 0.7518796992481203,
      "grad_norm": 0.7928813099861145,
      "learning_rate": 7.4937343358396e-06,
      "loss": 0.0467,
      "step": 3000
    },
    {
      "epoch": 0.7644110275689223,
      "grad_norm": 0.16328191757202148,
      "learning_rate": 7.451963241436926e-06,
      "loss": 0.0415,
      "step": 3050
    },
    {
      "epoch": 0.7769423558897243,
      "grad_norm": 1.106583833694458,
      "learning_rate": 7.410192147034253e-06,
      "loss": 0.0413,
      "step": 3100
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.5218818187713623,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0465,
      "step": 3150
    },
    {
      "epoch": 0.8020050125313283,
      "grad_norm": 0.3240223824977875,
      "learning_rate": 7.326649958228906e-06,
      "loss": 0.043,
      "step": 3200
    },
    {
      "epoch": 0.8145363408521303,
      "grad_norm": 0.48475930094718933,
      "learning_rate": 7.284878863826233e-06,
      "loss": 0.0349,
      "step": 3250
    },
    {
      "epoch": 0.8270676691729323,
      "grad_norm": 0.6863238215446472,
      "learning_rate": 7.2431077694235595e-06,
      "loss": 0.0401,
      "step": 3300
    },
    {
      "epoch": 0.8395989974937343,
      "grad_norm": 0.5198488235473633,
      "learning_rate": 7.2013366750208854e-06,
      "loss": 0.0401,
      "step": 3350
    },
    {
      "epoch": 0.8521303258145363,
      "grad_norm": 0.5832604169845581,
      "learning_rate": 7.159565580618213e-06,
      "loss": 0.038,
      "step": 3400
    },
    {
      "epoch": 0.8646616541353384,
      "grad_norm": 0.5049284100532532,
      "learning_rate": 7.117794486215539e-06,
      "loss": 0.0383,
      "step": 3450
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 0.5139366388320923,
      "learning_rate": 7.0760233918128665e-06,
      "loss": 0.0373,
      "step": 3500
    },
    {
      "epoch": 0.8897243107769424,
      "grad_norm": 0.07320224493741989,
      "learning_rate": 7.0342522974101924e-06,
      "loss": 0.0384,
      "step": 3550
    },
    {
      "epoch": 0.9022556390977443,
      "grad_norm": 0.3546138107776642,
      "learning_rate": 6.992481203007519e-06,
      "loss": 0.0432,
      "step": 3600
    },
    {
      "epoch": 0.9147869674185464,
      "grad_norm": 0.4860749840736389,
      "learning_rate": 6.950710108604846e-06,
      "loss": 0.0399,
      "step": 3650
    },
    {
      "epoch": 0.9273182957393483,
      "grad_norm": 0.45930981636047363,
      "learning_rate": 6.908939014202173e-06,
      "loss": 0.0319,
      "step": 3700
    },
    {
      "epoch": 0.9398496240601504,
      "grad_norm": 0.44226038455963135,
      "learning_rate": 6.867167919799499e-06,
      "loss": 0.0363,
      "step": 3750
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.5426483750343323,
      "learning_rate": 6.825396825396826e-06,
      "loss": 0.0424,
      "step": 3800
    },
    {
      "epoch": 0.9649122807017544,
      "grad_norm": 1.0827975273132324,
      "learning_rate": 6.783625730994152e-06,
      "loss": 0.0424,
      "step": 3850
    },
    {
      "epoch": 0.9774436090225563,
      "grad_norm": 0.6715779900550842,
      "learning_rate": 6.74185463659148e-06,
      "loss": 0.0338,
      "step": 3900
    },
    {
      "epoch": 0.9899749373433584,
      "grad_norm": 0.5311267375946045,
      "learning_rate": 6.700083542188806e-06,
      "loss": 0.0405,
      "step": 3950
    },
    {
      "epoch": 1.0025062656641603,
      "grad_norm": 0.7137766480445862,
      "learning_rate": 6.658312447786132e-06,
      "loss": 0.046,
      "step": 4000
    },
    {
      "epoch": 1.0150375939849625,
      "grad_norm": 0.3624595105648041,
      "learning_rate": 6.616541353383459e-06,
      "loss": 0.0407,
      "step": 4050
    },
    {
      "epoch": 1.0265664160401002,
      "eval_loss": 0.043013423681259155,
      "eval_roc_auc_macro": 0.988389049763495,
      "eval_runtime": 205.3163,
      "eval_samples_per_second": 155.424,
      "eval_steps_per_second": 4.861,
      "step": 4096
    }
  ],
  "logging_steps": 50,
  "max_steps": 11970,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2048,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7241543390081024e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
