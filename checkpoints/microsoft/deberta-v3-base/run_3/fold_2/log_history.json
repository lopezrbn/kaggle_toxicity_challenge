[
  {
    "loss": 0.6508,
    "grad_norm": 1.5122854709625244,
    "learning_rate": 9.991645781119465e-06,
    "epoch": 0.002506265664160401,
    "step": 10
  },
  {
    "loss": 0.6047,
    "grad_norm": 1.8744125366210938,
    "learning_rate": 9.983291562238932e-06,
    "epoch": 0.005012531328320802,
    "step": 20
  },
  {
    "loss": 0.4938,
    "grad_norm": 1.8042975664138794,
    "learning_rate": 9.974937343358396e-06,
    "epoch": 0.007518796992481203,
    "step": 30
  },
  {
    "loss": 0.3431,
    "grad_norm": 1.9444022178649902,
    "learning_rate": 9.966583124477862e-06,
    "epoch": 0.010025062656641603,
    "step": 40
  },
  {
    "loss": 0.2608,
    "grad_norm": 1.6351975202560425,
    "learning_rate": 9.958228905597328e-06,
    "epoch": 0.012531328320802004,
    "step": 50
  },
  {
    "loss": 0.2041,
    "grad_norm": 1.3715571165084839,
    "learning_rate": 9.949874686716793e-06,
    "epoch": 0.015037593984962405,
    "step": 60
  },
  {
    "loss": 0.1971,
    "grad_norm": 0.5730945467948914,
    "learning_rate": 9.941520467836257e-06,
    "epoch": 0.017543859649122806,
    "step": 70
  },
  {
    "loss": 0.1613,
    "grad_norm": 0.9882879257202148,
    "learning_rate": 9.933166248955723e-06,
    "epoch": 0.020050125313283207,
    "step": 80
  },
  {
    "loss": 0.152,
    "grad_norm": 0.6344394087791443,
    "learning_rate": 9.924812030075189e-06,
    "epoch": 0.022556390977443608,
    "step": 90
  },
  {
    "loss": 0.1395,
    "grad_norm": 0.8603101968765259,
    "learning_rate": 9.916457811194654e-06,
    "epoch": 0.02506265664160401,
    "step": 100
  },
  {
    "loss": 0.1322,
    "grad_norm": 0.7136549949645996,
    "learning_rate": 9.908103592314118e-06,
    "epoch": 0.02756892230576441,
    "step": 110
  },
  {
    "loss": 0.1329,
    "grad_norm": 0.8769981861114502,
    "learning_rate": 9.899749373433584e-06,
    "epoch": 0.03007518796992481,
    "step": 120
  },
  {
    "loss": 0.0992,
    "grad_norm": 0.3919753432273865,
    "learning_rate": 9.89139515455305e-06,
    "epoch": 0.03258145363408521,
    "step": 130
  },
  {
    "loss": 0.099,
    "grad_norm": 0.7275142669677734,
    "learning_rate": 9.883040935672515e-06,
    "epoch": 0.03508771929824561,
    "step": 140
  },
  {
    "loss": 0.099,
    "grad_norm": 0.6823203563690186,
    "learning_rate": 9.87468671679198e-06,
    "epoch": 0.03759398496240601,
    "step": 150
  },
  {
    "loss": 0.0801,
    "grad_norm": 0.7968409061431885,
    "learning_rate": 9.866332497911447e-06,
    "epoch": 0.040100250626566414,
    "step": 160
  },
  {
    "loss": 0.0764,
    "grad_norm": 0.3948768973350525,
    "learning_rate": 9.85797827903091e-06,
    "epoch": 0.042606516290726815,
    "step": 170
  },
  {
    "loss": 0.0783,
    "grad_norm": 0.4865081012248993,
    "learning_rate": 9.849624060150376e-06,
    "epoch": 0.045112781954887216,
    "step": 180
  },
  {
    "loss": 0.071,
    "grad_norm": 0.6186314821243286,
    "learning_rate": 9.841269841269842e-06,
    "epoch": 0.047619047619047616,
    "step": 190
  },
  {
    "loss": 0.072,
    "grad_norm": 0.3905611038208008,
    "learning_rate": 9.832915622389308e-06,
    "epoch": 0.05012531328320802,
    "step": 200
  },
  {
    "loss": 0.0794,
    "grad_norm": 0.4109288454055786,
    "learning_rate": 9.824561403508772e-06,
    "epoch": 0.05263157894736842,
    "step": 210
  },
  {
    "loss": 0.0584,
    "grad_norm": 0.5974076986312866,
    "learning_rate": 9.816207184628238e-06,
    "epoch": 0.05513784461152882,
    "step": 220
  },
  {
    "loss": 0.0739,
    "grad_norm": 0.793779730796814,
    "learning_rate": 9.807852965747703e-06,
    "epoch": 0.05764411027568922,
    "step": 230
  },
  {
    "loss": 0.1039,
    "grad_norm": 1.0579777956008911,
    "learning_rate": 9.799498746867169e-06,
    "epoch": 0.06015037593984962,
    "step": 240
  },
  {
    "loss": 0.0683,
    "grad_norm": 1.1528210639953613,
    "learning_rate": 9.791144527986633e-06,
    "epoch": 0.06265664160401002,
    "step": 250
  },
  {
    "eval_loss": 0.0669977217912674,
    "eval_roc_auc_macro": 0.9123502391228097,
    "eval_runtime": 40.068,
    "eval_samples_per_second": 796.521,
    "eval_steps_per_second": 24.908,
    "epoch": 0.06265664160401002,
    "step": 250
  },
  {
    "train_loss": 0.06380470842123032,
    "train_roc_auc_macro": 0.9188880399436176,
    "train_runtime": 160.129,
    "train_samples_per_second": 797.207,
    "train_steps_per_second": 24.917,
    "epoch": 0.06265664160401002,
    "step": 250
  },
  {
    "loss": 0.0693,
    "grad_norm": 0.4880621135234833,
    "learning_rate": 9.782790309106099e-06,
    "epoch": 0.06516290726817042,
    "step": 260
  },
  {
    "loss": 0.0641,
    "grad_norm": 0.6079771518707275,
    "learning_rate": 9.774436090225564e-06,
    "epoch": 0.06766917293233082,
    "step": 270
  },
  {
    "loss": 0.0582,
    "grad_norm": 0.6290320754051208,
    "learning_rate": 9.76608187134503e-06,
    "epoch": 0.07017543859649122,
    "step": 280
  },
  {
    "loss": 0.0725,
    "grad_norm": 0.8659104704856873,
    "learning_rate": 9.757727652464496e-06,
    "epoch": 0.07268170426065163,
    "step": 290
  },
  {
    "loss": 0.0671,
    "grad_norm": 1.1172879934310913,
    "learning_rate": 9.749373433583961e-06,
    "epoch": 0.07518796992481203,
    "step": 300
  },
  {
    "loss": 0.0568,
    "grad_norm": 0.6563979983329773,
    "learning_rate": 9.741019214703425e-06,
    "epoch": 0.07769423558897243,
    "step": 310
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.4763532876968384,
    "learning_rate": 9.732664995822891e-06,
    "epoch": 0.08020050125313283,
    "step": 320
  },
  {
    "loss": 0.0596,
    "grad_norm": 0.5992743372917175,
    "learning_rate": 9.724310776942357e-06,
    "epoch": 0.08270676691729323,
    "step": 330
  },
  {
    "loss": 0.0556,
    "grad_norm": 0.8384435772895813,
    "learning_rate": 9.715956558061822e-06,
    "epoch": 0.08521303258145363,
    "step": 340
  },
  {
    "loss": 0.0542,
    "grad_norm": 0.719002366065979,
    "learning_rate": 9.707602339181286e-06,
    "epoch": 0.08771929824561403,
    "step": 350
  },
  {
    "loss": 0.0574,
    "grad_norm": 1.111079454421997,
    "learning_rate": 9.699248120300752e-06,
    "epoch": 0.09022556390977443,
    "step": 360
  },
  {
    "loss": 0.0519,
    "grad_norm": 0.4403300881385803,
    "learning_rate": 9.690893901420218e-06,
    "epoch": 0.09273182957393483,
    "step": 370
  },
  {
    "loss": 0.0668,
    "grad_norm": 0.2731269598007202,
    "learning_rate": 9.682539682539683e-06,
    "epoch": 0.09523809523809523,
    "step": 380
  },
  {
    "loss": 0.0537,
    "grad_norm": 0.3766747713088989,
    "learning_rate": 9.674185463659147e-06,
    "epoch": 0.09774436090225563,
    "step": 390
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.8527994751930237,
    "learning_rate": 9.665831244778615e-06,
    "epoch": 0.10025062656641603,
    "step": 400
  },
  {
    "loss": 0.0567,
    "grad_norm": 0.6690875291824341,
    "learning_rate": 9.657477025898079e-06,
    "epoch": 0.10275689223057644,
    "step": 410
  },
  {
    "loss": 0.0554,
    "grad_norm": 0.5500859022140503,
    "learning_rate": 9.649122807017545e-06,
    "epoch": 0.10526315789473684,
    "step": 420
  },
  {
    "loss": 0.0505,
    "grad_norm": 0.3268950879573822,
    "learning_rate": 9.64076858813701e-06,
    "epoch": 0.10776942355889724,
    "step": 430
  },
  {
    "loss": 0.044,
    "grad_norm": 0.43507444858551025,
    "learning_rate": 9.632414369256476e-06,
    "epoch": 0.11027568922305764,
    "step": 440
  },
  {
    "loss": 0.0384,
    "grad_norm": 0.42076992988586426,
    "learning_rate": 9.62406015037594e-06,
    "epoch": 0.11278195488721804,
    "step": 450
  },
  {
    "loss": 0.0624,
    "grad_norm": 0.6031091809272766,
    "learning_rate": 9.615705931495406e-06,
    "epoch": 0.11528822055137844,
    "step": 460
  },
  {
    "loss": 0.0601,
    "grad_norm": 0.5141172409057617,
    "learning_rate": 9.607351712614871e-06,
    "epoch": 0.11779448621553884,
    "step": 470
  },
  {
    "loss": 0.0473,
    "grad_norm": 0.6284107565879822,
    "learning_rate": 9.598997493734337e-06,
    "epoch": 0.12030075187969924,
    "step": 480
  },
  {
    "loss": 0.0565,
    "grad_norm": 0.6707596778869629,
    "learning_rate": 9.590643274853801e-06,
    "epoch": 0.12280701754385964,
    "step": 490
  },
  {
    "loss": 0.0502,
    "grad_norm": 0.5402504801750183,
    "learning_rate": 9.582289055973267e-06,
    "epoch": 0.12531328320802004,
    "step": 500
  },
  {
    "eval_loss": 0.05022672191262245,
    "eval_roc_auc_macro": 0.9682687998934592,
    "eval_runtime": 40.016,
    "eval_samples_per_second": 797.556,
    "eval_steps_per_second": 24.94,
    "epoch": 0.12531328320802004,
    "step": 500
  },
  {
    "train_loss": 0.04767395555973053,
    "train_roc_auc_macro": 0.9684896326721768,
    "train_runtime": 159.8359,
    "train_samples_per_second": 798.669,
    "train_steps_per_second": 24.963,
    "epoch": 0.12531328320802004,
    "step": 500
  },
  {
    "loss": 0.0445,
    "grad_norm": 0.7308852076530457,
    "learning_rate": 9.573934837092732e-06,
    "epoch": 0.12781954887218044,
    "step": 510
  },
  {
    "loss": 0.0645,
    "grad_norm": 0.6048034429550171,
    "learning_rate": 9.565580618212198e-06,
    "epoch": 0.13032581453634084,
    "step": 520
  },
  {
    "loss": 0.0504,
    "grad_norm": 0.4323185384273529,
    "learning_rate": 9.557226399331662e-06,
    "epoch": 0.13283208020050125,
    "step": 530
  },
  {
    "loss": 0.045,
    "grad_norm": 0.4142928719520569,
    "learning_rate": 9.54887218045113e-06,
    "epoch": 0.13533834586466165,
    "step": 540
  },
  {
    "loss": 0.0473,
    "grad_norm": 0.47644874453544617,
    "learning_rate": 9.540517961570593e-06,
    "epoch": 0.13784461152882205,
    "step": 550
  },
  {
    "loss": 0.0571,
    "grad_norm": 0.42361047863960266,
    "learning_rate": 9.532163742690059e-06,
    "epoch": 0.14035087719298245,
    "step": 560
  },
  {
    "loss": 0.0465,
    "grad_norm": 0.4822247624397278,
    "learning_rate": 9.523809523809525e-06,
    "epoch": 0.14285714285714285,
    "step": 570
  },
  {
    "loss": 0.0467,
    "grad_norm": 0.3032316267490387,
    "learning_rate": 9.51545530492899e-06,
    "epoch": 0.14536340852130325,
    "step": 580
  },
  {
    "loss": 0.0666,
    "grad_norm": 0.3913317918777466,
    "learning_rate": 9.507101086048454e-06,
    "epoch": 0.14786967418546365,
    "step": 590
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.3825397789478302,
    "learning_rate": 9.49874686716792e-06,
    "epoch": 0.15037593984962405,
    "step": 600
  },
  {
    "loss": 0.0518,
    "grad_norm": 0.7516184449195862,
    "learning_rate": 9.490392648287386e-06,
    "epoch": 0.15288220551378445,
    "step": 610
  },
  {
    "loss": 0.0552,
    "grad_norm": 0.7624557614326477,
    "learning_rate": 9.482038429406851e-06,
    "epoch": 0.15538847117794485,
    "step": 620
  },
  {
    "loss": 0.0391,
    "grad_norm": 0.5146228075027466,
    "learning_rate": 9.473684210526315e-06,
    "epoch": 0.15789473684210525,
    "step": 630
  },
  {
    "loss": 0.0537,
    "grad_norm": 0.1221945583820343,
    "learning_rate": 9.465329991645781e-06,
    "epoch": 0.16040100250626566,
    "step": 640
  },
  {
    "loss": 0.0607,
    "grad_norm": 0.8758361339569092,
    "learning_rate": 9.456975772765247e-06,
    "epoch": 0.16290726817042606,
    "step": 650
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.6583282947540283,
    "learning_rate": 9.448621553884713e-06,
    "epoch": 0.16541353383458646,
    "step": 660
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.3277597427368164,
    "learning_rate": 9.440267335004177e-06,
    "epoch": 0.16791979949874686,
    "step": 670
  },
  {
    "loss": 0.0489,
    "grad_norm": 0.4791186451911926,
    "learning_rate": 9.431913116123644e-06,
    "epoch": 0.17042606516290726,
    "step": 680
  },
  {
    "loss": 0.0443,
    "grad_norm": 1.1659269332885742,
    "learning_rate": 9.423558897243108e-06,
    "epoch": 0.17293233082706766,
    "step": 690
  },
  {
    "loss": 0.0538,
    "grad_norm": 0.3523624837398529,
    "learning_rate": 9.415204678362574e-06,
    "epoch": 0.17543859649122806,
    "step": 700
  },
  {
    "loss": 0.0428,
    "grad_norm": 0.272870272397995,
    "learning_rate": 9.40685045948204e-06,
    "epoch": 0.17794486215538846,
    "step": 710
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.46756985783576965,
    "learning_rate": 9.398496240601505e-06,
    "epoch": 0.18045112781954886,
    "step": 720
  },
  {
    "loss": 0.0552,
    "grad_norm": 0.6124539971351624,
    "learning_rate": 9.390142021720969e-06,
    "epoch": 0.18295739348370926,
    "step": 730
  },
  {
    "loss": 0.0504,
    "grad_norm": 0.6453602313995361,
    "learning_rate": 9.381787802840435e-06,
    "epoch": 0.18546365914786966,
    "step": 740
  },
  {
    "loss": 0.0484,
    "grad_norm": 0.4493260681629181,
    "learning_rate": 9.3734335839599e-06,
    "epoch": 0.18796992481203006,
    "step": 750
  },
  {
    "eval_loss": 0.0491914227604866,
    "eval_roc_auc_macro": 0.9708162473127296,
    "eval_runtime": 40.0212,
    "eval_samples_per_second": 797.453,
    "eval_steps_per_second": 24.937,
    "epoch": 0.18796992481203006,
    "step": 750
  },
  {
    "train_loss": 0.04633156955242157,
    "train_roc_auc_macro": 0.9717099245571988,
    "train_runtime": 159.9157,
    "train_samples_per_second": 798.271,
    "train_steps_per_second": 24.951,
    "epoch": 0.18796992481203006,
    "step": 750
  },
  {
    "loss": 0.0538,
    "grad_norm": 1.182786226272583,
    "learning_rate": 9.365079365079366e-06,
    "epoch": 0.19047619047619047,
    "step": 760
  },
  {
    "loss": 0.0442,
    "grad_norm": 0.4701171815395355,
    "learning_rate": 9.35672514619883e-06,
    "epoch": 0.19298245614035087,
    "step": 770
  },
  {
    "loss": 0.0636,
    "grad_norm": 0.4628957211971283,
    "learning_rate": 9.348370927318296e-06,
    "epoch": 0.19548872180451127,
    "step": 780
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.3746095299720764,
    "learning_rate": 9.340016708437761e-06,
    "epoch": 0.19799498746867167,
    "step": 790
  },
  {
    "loss": 0.0524,
    "grad_norm": 0.46982434391975403,
    "learning_rate": 9.331662489557227e-06,
    "epoch": 0.20050125313283207,
    "step": 800
  },
  {
    "loss": 0.055,
    "grad_norm": 0.3932502567768097,
    "learning_rate": 9.323308270676693e-06,
    "epoch": 0.20300751879699247,
    "step": 810
  },
  {
    "loss": 0.0463,
    "grad_norm": 0.3419709801673889,
    "learning_rate": 9.314954051796158e-06,
    "epoch": 0.20551378446115287,
    "step": 820
  },
  {
    "loss": 0.0628,
    "grad_norm": 0.4315136969089508,
    "learning_rate": 9.306599832915622e-06,
    "epoch": 0.20802005012531327,
    "step": 830
  },
  {
    "loss": 0.0521,
    "grad_norm": 0.4346712827682495,
    "learning_rate": 9.298245614035088e-06,
    "epoch": 0.21052631578947367,
    "step": 840
  },
  {
    "loss": 0.0549,
    "grad_norm": 0.923220694065094,
    "learning_rate": 9.289891395154554e-06,
    "epoch": 0.21303258145363407,
    "step": 850
  },
  {
    "loss": 0.0558,
    "grad_norm": 0.7666468620300293,
    "learning_rate": 9.28153717627402e-06,
    "epoch": 0.21553884711779447,
    "step": 860
  },
  {
    "loss": 0.0474,
    "grad_norm": 0.22890861332416534,
    "learning_rate": 9.273182957393484e-06,
    "epoch": 0.21804511278195488,
    "step": 870
  },
  {
    "loss": 0.0442,
    "grad_norm": 0.4383106231689453,
    "learning_rate": 9.26482873851295e-06,
    "epoch": 0.22055137844611528,
    "step": 880
  },
  {
    "loss": 0.0538,
    "grad_norm": 0.7612981796264648,
    "learning_rate": 9.256474519632415e-06,
    "epoch": 0.22305764411027568,
    "step": 890
  },
  {
    "loss": 0.0562,
    "grad_norm": 0.5537427067756653,
    "learning_rate": 9.24812030075188e-06,
    "epoch": 0.22556390977443608,
    "step": 900
  },
  {
    "loss": 0.0532,
    "grad_norm": 0.3479657769203186,
    "learning_rate": 9.239766081871345e-06,
    "epoch": 0.22807017543859648,
    "step": 910
  },
  {
    "loss": 0.0595,
    "grad_norm": 0.6369321942329407,
    "learning_rate": 9.231411862990812e-06,
    "epoch": 0.23057644110275688,
    "step": 920
  },
  {
    "loss": 0.0523,
    "grad_norm": 0.23994341492652893,
    "learning_rate": 9.223057644110276e-06,
    "epoch": 0.23308270676691728,
    "step": 930
  },
  {
    "loss": 0.0578,
    "grad_norm": 1.4642174243927002,
    "learning_rate": 9.214703425229742e-06,
    "epoch": 0.23558897243107768,
    "step": 940
  },
  {
    "loss": 0.0542,
    "grad_norm": 0.27198079228401184,
    "learning_rate": 9.206349206349207e-06,
    "epoch": 0.23809523809523808,
    "step": 950
  },
  {
    "loss": 0.0521,
    "grad_norm": 0.40117746591567993,
    "learning_rate": 9.197994987468673e-06,
    "epoch": 0.24060150375939848,
    "step": 960
  },
  {
    "loss": 0.051,
    "grad_norm": 0.791231095790863,
    "learning_rate": 9.189640768588137e-06,
    "epoch": 0.24310776942355888,
    "step": 970
  },
  {
    "loss": 0.039,
    "grad_norm": 0.21401555836200714,
    "learning_rate": 9.181286549707603e-06,
    "epoch": 0.24561403508771928,
    "step": 980
  },
  {
    "loss": 0.0625,
    "grad_norm": 0.7197697758674622,
    "learning_rate": 9.172932330827068e-06,
    "epoch": 0.24812030075187969,
    "step": 990
  },
  {
    "loss": 0.0433,
    "grad_norm": 0.7714987397193909,
    "learning_rate": 9.164578111946534e-06,
    "epoch": 0.2506265664160401,
    "step": 1000
  },
  {
    "eval_loss": 0.048708412796258926,
    "eval_roc_auc_macro": 0.976462833441207,
    "eval_runtime": 40.0797,
    "eval_samples_per_second": 796.289,
    "eval_steps_per_second": 24.9,
    "epoch": 0.2506265664160401,
    "step": 1000
  },
  {
    "train_loss": 0.046276457607746124,
    "train_roc_auc_macro": 0.9781670297604216,
    "train_runtime": 159.8661,
    "train_samples_per_second": 798.518,
    "train_steps_per_second": 24.958,
    "epoch": 0.2506265664160401,
    "step": 1000
  },
  {
    "loss": 0.0466,
    "grad_norm": 0.5571300387382507,
    "learning_rate": 9.156223893065998e-06,
    "epoch": 0.2531328320802005,
    "step": 1010
  },
  {
    "loss": 0.0387,
    "grad_norm": 0.632965087890625,
    "learning_rate": 9.147869674185464e-06,
    "epoch": 0.2556390977443609,
    "step": 1020
  },
  {
    "loss": 0.06,
    "grad_norm": 0.810592770576477,
    "learning_rate": 9.13951545530493e-06,
    "epoch": 0.2581453634085213,
    "step": 1030
  },
  {
    "loss": 0.042,
    "grad_norm": 0.5553373098373413,
    "learning_rate": 9.131161236424395e-06,
    "epoch": 0.2606516290726817,
    "step": 1040
  },
  {
    "loss": 0.0415,
    "grad_norm": 0.5877141952514648,
    "learning_rate": 9.12280701754386e-06,
    "epoch": 0.2631578947368421,
    "step": 1050
  },
  {
    "loss": 0.0526,
    "grad_norm": 0.630028486251831,
    "learning_rate": 9.114452798663327e-06,
    "epoch": 0.2656641604010025,
    "step": 1060
  },
  {
    "loss": 0.0507,
    "grad_norm": 0.2440822869539261,
    "learning_rate": 9.10609857978279e-06,
    "epoch": 0.2681704260651629,
    "step": 1070
  },
  {
    "loss": 0.0555,
    "grad_norm": 1.6052160263061523,
    "learning_rate": 9.097744360902256e-06,
    "epoch": 0.2706766917293233,
    "step": 1080
  },
  {
    "loss": 0.0497,
    "grad_norm": 0.3816676735877991,
    "learning_rate": 9.089390142021722e-06,
    "epoch": 0.2731829573934837,
    "step": 1090
  },
  {
    "loss": 0.057,
    "grad_norm": 0.49892330169677734,
    "learning_rate": 9.081035923141188e-06,
    "epoch": 0.2756892230576441,
    "step": 1100
  },
  {
    "loss": 0.0415,
    "grad_norm": 0.39308443665504456,
    "learning_rate": 9.072681704260652e-06,
    "epoch": 0.2781954887218045,
    "step": 1110
  },
  {
    "loss": 0.0445,
    "grad_norm": 0.9326597452163696,
    "learning_rate": 9.064327485380117e-06,
    "epoch": 0.2807017543859649,
    "step": 1120
  },
  {
    "loss": 0.0488,
    "grad_norm": 0.437147319316864,
    "learning_rate": 9.055973266499583e-06,
    "epoch": 0.2832080200501253,
    "step": 1130
  },
  {
    "loss": 0.0348,
    "grad_norm": 0.31908106803894043,
    "learning_rate": 9.047619047619049e-06,
    "epoch": 0.2857142857142857,
    "step": 1140
  },
  {
    "loss": 0.0537,
    "grad_norm": 0.4540470838546753,
    "learning_rate": 9.039264828738513e-06,
    "epoch": 0.2882205513784461,
    "step": 1150
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.5241429209709167,
    "learning_rate": 9.030910609857978e-06,
    "epoch": 0.2907268170426065,
    "step": 1160
  },
  {
    "loss": 0.0491,
    "grad_norm": 0.5468917489051819,
    "learning_rate": 9.022556390977444e-06,
    "epoch": 0.2932330827067669,
    "step": 1170
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.2086188942193985,
    "learning_rate": 9.01420217209691e-06,
    "epoch": 0.2957393483709273,
    "step": 1180
  },
  {
    "loss": 0.0378,
    "grad_norm": 0.6075530648231506,
    "learning_rate": 9.005847953216374e-06,
    "epoch": 0.2982456140350877,
    "step": 1190
  },
  {
    "loss": 0.0455,
    "grad_norm": 0.9364961981773376,
    "learning_rate": 8.997493734335841e-06,
    "epoch": 0.3007518796992481,
    "step": 1200
  },
  {
    "loss": 0.05,
    "grad_norm": 0.47742584347724915,
    "learning_rate": 8.989139515455305e-06,
    "epoch": 0.3032581453634085,
    "step": 1210
  },
  {
    "loss": 0.0511,
    "grad_norm": 0.564852774143219,
    "learning_rate": 8.98078529657477e-06,
    "epoch": 0.3057644110275689,
    "step": 1220
  },
  {
    "loss": 0.0436,
    "grad_norm": 0.29987549781799316,
    "learning_rate": 8.972431077694236e-06,
    "epoch": 0.3082706766917293,
    "step": 1230
  },
  {
    "loss": 0.0353,
    "grad_norm": 0.28103935718536377,
    "learning_rate": 8.964076858813702e-06,
    "epoch": 0.3107769423558897,
    "step": 1240
  },
  {
    "loss": 0.0453,
    "grad_norm": 0.5316480994224548,
    "learning_rate": 8.955722639933166e-06,
    "epoch": 0.3132832080200501,
    "step": 1250
  },
  {
    "eval_loss": 0.046837691217660904,
    "eval_roc_auc_macro": 0.9736864036981038,
    "eval_runtime": 40.038,
    "eval_samples_per_second": 797.118,
    "eval_steps_per_second": 24.926,
    "epoch": 0.3132832080200501,
    "step": 1250
  },
  {
    "train_loss": 0.04359480366110802,
    "train_roc_auc_macro": 0.9770808016741493,
    "train_runtime": 159.89,
    "train_samples_per_second": 798.399,
    "train_steps_per_second": 24.955,
    "epoch": 0.3132832080200501,
    "step": 1250
  },
  {
    "loss": 0.0458,
    "grad_norm": 0.6946086287498474,
    "learning_rate": 8.947368421052632e-06,
    "epoch": 0.3157894736842105,
    "step": 1260
  },
  {
    "loss": 0.0413,
    "grad_norm": 0.5471722483634949,
    "learning_rate": 8.939014202172098e-06,
    "epoch": 0.3182957393483709,
    "step": 1270
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.5847600102424622,
    "learning_rate": 8.930659983291563e-06,
    "epoch": 0.3208020050125313,
    "step": 1280
  },
  {
    "loss": 0.0471,
    "grad_norm": 1.1228384971618652,
    "learning_rate": 8.922305764411027e-06,
    "epoch": 0.3233082706766917,
    "step": 1290
  },
  {
    "loss": 0.0573,
    "grad_norm": 0.6070732474327087,
    "learning_rate": 8.913951545530493e-06,
    "epoch": 0.3258145363408521,
    "step": 1300
  },
  {
    "loss": 0.0607,
    "grad_norm": 0.5340060591697693,
    "learning_rate": 8.905597326649959e-06,
    "epoch": 0.3283208020050125,
    "step": 1310
  },
  {
    "loss": 0.0562,
    "grad_norm": 0.36770427227020264,
    "learning_rate": 8.897243107769424e-06,
    "epoch": 0.3308270676691729,
    "step": 1320
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.24605105817317963,
    "learning_rate": 8.888888888888888e-06,
    "epoch": 0.3333333333333333,
    "step": 1330
  },
  {
    "loss": 0.0455,
    "grad_norm": 0.7839940190315247,
    "learning_rate": 8.880534670008356e-06,
    "epoch": 0.3358395989974937,
    "step": 1340
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.21965795755386353,
    "learning_rate": 8.87218045112782e-06,
    "epoch": 0.3383458646616541,
    "step": 1350
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.1476830244064331,
    "learning_rate": 8.863826232247285e-06,
    "epoch": 0.3408521303258145,
    "step": 1360
  },
  {
    "loss": 0.0425,
    "grad_norm": 0.6553483605384827,
    "learning_rate": 8.855472013366751e-06,
    "epoch": 0.3433583959899749,
    "step": 1370
  },
  {
    "loss": 0.05,
    "grad_norm": 0.5316191911697388,
    "learning_rate": 8.847117794486217e-06,
    "epoch": 0.3458646616541353,
    "step": 1380
  },
  {
    "loss": 0.0323,
    "grad_norm": 0.5776317715644836,
    "learning_rate": 8.83876357560568e-06,
    "epoch": 0.3483709273182957,
    "step": 1390
  },
  {
    "loss": 0.0586,
    "grad_norm": 1.6940752267837524,
    "learning_rate": 8.830409356725146e-06,
    "epoch": 0.3508771929824561,
    "step": 1400
  },
  {
    "loss": 0.0583,
    "grad_norm": 0.7053064703941345,
    "learning_rate": 8.822055137844612e-06,
    "epoch": 0.3533834586466165,
    "step": 1410
  },
  {
    "loss": 0.0553,
    "grad_norm": 0.5825178623199463,
    "learning_rate": 8.813700918964078e-06,
    "epoch": 0.3558897243107769,
    "step": 1420
  },
  {
    "loss": 0.0441,
    "grad_norm": 0.24235959351062775,
    "learning_rate": 8.805346700083542e-06,
    "epoch": 0.3583959899749373,
    "step": 1430
  },
  {
    "loss": 0.0369,
    "grad_norm": 0.19536945223808289,
    "learning_rate": 8.796992481203007e-06,
    "epoch": 0.3609022556390977,
    "step": 1440
  },
  {
    "loss": 0.0425,
    "grad_norm": 0.5444056391716003,
    "learning_rate": 8.788638262322473e-06,
    "epoch": 0.3634085213032581,
    "step": 1450
  },
  {
    "loss": 0.0552,
    "grad_norm": 0.34463757276535034,
    "learning_rate": 8.780284043441939e-06,
    "epoch": 0.3659147869674185,
    "step": 1460
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.18697981536388397,
    "learning_rate": 8.771929824561405e-06,
    "epoch": 0.3684210526315789,
    "step": 1470
  },
  {
    "loss": 0.0436,
    "grad_norm": 0.3544918894767761,
    "learning_rate": 8.76357560568087e-06,
    "epoch": 0.37092731829573933,
    "step": 1480
  },
  {
    "loss": 0.058,
    "grad_norm": 0.5613471269607544,
    "learning_rate": 8.755221386800334e-06,
    "epoch": 0.37343358395989973,
    "step": 1490
  },
  {
    "loss": 0.0299,
    "grad_norm": 0.666437566280365,
    "learning_rate": 8.7468671679198e-06,
    "epoch": 0.37593984962406013,
    "step": 1500
  },
  {
    "eval_loss": 0.046989500522613525,
    "eval_roc_auc_macro": 0.9772135701540501,
    "eval_runtime": 40.051,
    "eval_samples_per_second": 796.859,
    "eval_steps_per_second": 24.918,
    "epoch": 0.37593984962406013,
    "step": 1500
  },
  {
    "train_loss": 0.04275623336434364,
    "train_roc_auc_macro": 0.978819516647083,
    "train_runtime": 159.8459,
    "train_samples_per_second": 798.619,
    "train_steps_per_second": 24.962,
    "epoch": 0.37593984962406013,
    "step": 1500
  },
  {
    "loss": 0.0384,
    "grad_norm": 0.31085404753685,
    "learning_rate": 8.738512949039266e-06,
    "epoch": 0.37844611528822053,
    "step": 1510
  },
  {
    "loss": 0.0503,
    "grad_norm": 0.7389799952507019,
    "learning_rate": 8.730158730158731e-06,
    "epoch": 0.38095238095238093,
    "step": 1520
  },
  {
    "loss": 0.0522,
    "grad_norm": 0.4874444603919983,
    "learning_rate": 8.721804511278195e-06,
    "epoch": 0.38345864661654133,
    "step": 1530
  },
  {
    "loss": 0.0509,
    "grad_norm": 1.0385847091674805,
    "learning_rate": 8.713450292397661e-06,
    "epoch": 0.38596491228070173,
    "step": 1540
  },
  {
    "loss": 0.0512,
    "grad_norm": 0.5943294167518616,
    "learning_rate": 8.705096073517127e-06,
    "epoch": 0.38847117794486213,
    "step": 1550
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.4383547008037567,
    "learning_rate": 8.696741854636592e-06,
    "epoch": 0.39097744360902253,
    "step": 1560
  },
  {
    "loss": 0.0321,
    "grad_norm": 0.4492035210132599,
    "learning_rate": 8.688387635756056e-06,
    "epoch": 0.39348370927318294,
    "step": 1570
  },
  {
    "loss": 0.0569,
    "grad_norm": 0.29001641273498535,
    "learning_rate": 8.680033416875524e-06,
    "epoch": 0.39598997493734334,
    "step": 1580
  },
  {
    "loss": 0.0417,
    "grad_norm": 0.42562440037727356,
    "learning_rate": 8.671679197994988e-06,
    "epoch": 0.39849624060150374,
    "step": 1590
  },
  {
    "loss": 0.0415,
    "grad_norm": 0.20619437098503113,
    "learning_rate": 8.663324979114453e-06,
    "epoch": 0.40100250626566414,
    "step": 1600
  },
  {
    "loss": 0.0484,
    "grad_norm": 0.5536016225814819,
    "learning_rate": 8.654970760233919e-06,
    "epoch": 0.40350877192982454,
    "step": 1610
  },
  {
    "loss": 0.0333,
    "grad_norm": 0.27142199873924255,
    "learning_rate": 8.646616541353385e-06,
    "epoch": 0.40601503759398494,
    "step": 1620
  },
  {
    "loss": 0.043,
    "grad_norm": 0.701874315738678,
    "learning_rate": 8.638262322472849e-06,
    "epoch": 0.40852130325814534,
    "step": 1630
  },
  {
    "loss": 0.0406,
    "grad_norm": 0.17085281014442444,
    "learning_rate": 8.629908103592314e-06,
    "epoch": 0.41102756892230574,
    "step": 1640
  },
  {
    "loss": 0.0465,
    "grad_norm": 1.040724277496338,
    "learning_rate": 8.62155388471178e-06,
    "epoch": 0.41353383458646614,
    "step": 1650
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.6298250555992126,
    "learning_rate": 8.613199665831246e-06,
    "epoch": 0.41604010025062654,
    "step": 1660
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.2100456804037094,
    "learning_rate": 8.60484544695071e-06,
    "epoch": 0.41854636591478694,
    "step": 1670
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.39914417266845703,
    "learning_rate": 8.596491228070176e-06,
    "epoch": 0.42105263157894735,
    "step": 1680
  },
  {
    "loss": 0.0537,
    "grad_norm": 0.6101951003074646,
    "learning_rate": 8.588137009189641e-06,
    "epoch": 0.42355889724310775,
    "step": 1690
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.24406355619430542,
    "learning_rate": 8.579782790309107e-06,
    "epoch": 0.42606516290726815,
    "step": 1700
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.6060771346092224,
    "learning_rate": 8.571428571428571e-06,
    "epoch": 0.42857142857142855,
    "step": 1710
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.5294204950332642,
    "learning_rate": 8.563074352548038e-06,
    "epoch": 0.43107769423558895,
    "step": 1720
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.15514399111270905,
    "learning_rate": 8.554720133667502e-06,
    "epoch": 0.43358395989974935,
    "step": 1730
  },
  {
    "loss": 0.0462,
    "grad_norm": 0.34089988470077515,
    "learning_rate": 8.546365914786968e-06,
    "epoch": 0.43609022556390975,
    "step": 1740
  },
  {
    "loss": 0.0477,
    "grad_norm": 0.27248841524124146,
    "learning_rate": 8.538011695906434e-06,
    "epoch": 0.43859649122807015,
    "step": 1750
  },
  {
    "eval_loss": 0.046893537044525146,
    "eval_roc_auc_macro": 0.9757509254698168,
    "eval_runtime": 39.9815,
    "eval_samples_per_second": 798.245,
    "eval_steps_per_second": 24.962,
    "epoch": 0.43859649122807015,
    "step": 1750
  },
  {
    "train_loss": 0.04267197847366333,
    "train_roc_auc_macro": 0.9781759135679745,
    "train_runtime": 160.0375,
    "train_samples_per_second": 797.663,
    "train_steps_per_second": 24.932,
    "epoch": 0.43859649122807015,
    "step": 1750
  },
  {
    "loss": 0.0515,
    "grad_norm": 0.5571528673171997,
    "learning_rate": 8.5296574770259e-06,
    "epoch": 0.44110275689223055,
    "step": 1760
  },
  {
    "loss": 0.0455,
    "grad_norm": 0.4942808151245117,
    "learning_rate": 8.521303258145363e-06,
    "epoch": 0.44360902255639095,
    "step": 1770
  },
  {
    "loss": 0.0477,
    "grad_norm": 0.87705397605896,
    "learning_rate": 8.512949039264829e-06,
    "epoch": 0.44611528822055135,
    "step": 1780
  },
  {
    "loss": 0.0521,
    "grad_norm": 0.5013762712478638,
    "learning_rate": 8.504594820384295e-06,
    "epoch": 0.44862155388471175,
    "step": 1790
  },
  {
    "loss": 0.0451,
    "grad_norm": 0.6596150994300842,
    "learning_rate": 8.49624060150376e-06,
    "epoch": 0.45112781954887216,
    "step": 1800
  },
  {
    "loss": 0.0457,
    "grad_norm": 0.2867409884929657,
    "learning_rate": 8.487886382623224e-06,
    "epoch": 0.45363408521303256,
    "step": 1810
  },
  {
    "loss": 0.0468,
    "grad_norm": 1.756001591682434,
    "learning_rate": 8.47953216374269e-06,
    "epoch": 0.45614035087719296,
    "step": 1820
  },
  {
    "loss": 0.0401,
    "grad_norm": 0.3588986098766327,
    "learning_rate": 8.471177944862156e-06,
    "epoch": 0.45864661654135336,
    "step": 1830
  },
  {
    "loss": 0.0399,
    "grad_norm": 0.5655599236488342,
    "learning_rate": 8.462823725981621e-06,
    "epoch": 0.46115288220551376,
    "step": 1840
  },
  {
    "loss": 0.0619,
    "grad_norm": 0.30667442083358765,
    "learning_rate": 8.454469507101085e-06,
    "epoch": 0.46365914786967416,
    "step": 1850
  },
  {
    "loss": 0.0294,
    "grad_norm": 0.3296494781970978,
    "learning_rate": 8.446115288220553e-06,
    "epoch": 0.46616541353383456,
    "step": 1860
  },
  {
    "loss": 0.0617,
    "grad_norm": 0.5435829162597656,
    "learning_rate": 8.437761069340017e-06,
    "epoch": 0.46867167919799496,
    "step": 1870
  },
  {
    "loss": 0.0493,
    "grad_norm": 0.7109293341636658,
    "learning_rate": 8.429406850459483e-06,
    "epoch": 0.47117794486215536,
    "step": 1880
  },
  {
    "loss": 0.0587,
    "grad_norm": 1.954303503036499,
    "learning_rate": 8.421052631578948e-06,
    "epoch": 0.47368421052631576,
    "step": 1890
  },
  {
    "loss": 0.0462,
    "grad_norm": 0.5432796478271484,
    "learning_rate": 8.412698412698414e-06,
    "epoch": 0.47619047619047616,
    "step": 1900
  },
  {
    "loss": 0.0363,
    "grad_norm": 0.5430574417114258,
    "learning_rate": 8.404344193817878e-06,
    "epoch": 0.47869674185463656,
    "step": 1910
  },
  {
    "loss": 0.0323,
    "grad_norm": 0.22748379409313202,
    "learning_rate": 8.395989974937344e-06,
    "epoch": 0.48120300751879697,
    "step": 1920
  },
  {
    "loss": 0.056,
    "grad_norm": 0.531769335269928,
    "learning_rate": 8.38763575605681e-06,
    "epoch": 0.48370927318295737,
    "step": 1930
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.2086697518825531,
    "learning_rate": 8.379281537176275e-06,
    "epoch": 0.48621553884711777,
    "step": 1940
  },
  {
    "loss": 0.052,
    "grad_norm": 0.33022719621658325,
    "learning_rate": 8.370927318295739e-06,
    "epoch": 0.48872180451127817,
    "step": 1950
  },
  {
    "loss": 0.0262,
    "grad_norm": 0.19596298038959503,
    "learning_rate": 8.362573099415205e-06,
    "epoch": 0.49122807017543857,
    "step": 1960
  },
  {
    "loss": 0.038,
    "grad_norm": 0.3407340347766876,
    "learning_rate": 8.35421888053467e-06,
    "epoch": 0.49373433583959897,
    "step": 1970
  },
  {
    "loss": 0.0574,
    "grad_norm": 0.5522644519805908,
    "learning_rate": 8.345864661654136e-06,
    "epoch": 0.49624060150375937,
    "step": 1980
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.3220973014831543,
    "learning_rate": 8.3375104427736e-06,
    "epoch": 0.49874686716791977,
    "step": 1990
  },
  {
    "loss": 0.0434,
    "grad_norm": 0.28938496112823486,
    "learning_rate": 8.329156223893067e-06,
    "epoch": 0.5012531328320802,
    "step": 2000
  },
  {
    "eval_loss": 0.045811790972948074,
    "eval_roc_auc_macro": 0.9789821542595808,
    "eval_runtime": 40.052,
    "eval_samples_per_second": 796.839,
    "eval_steps_per_second": 24.918,
    "epoch": 0.5012531328320802,
    "step": 2000
  },
  {
    "train_loss": 0.04135306924581528,
    "train_roc_auc_macro": 0.9799288386124334,
    "train_runtime": 159.8976,
    "train_samples_per_second": 798.361,
    "train_steps_per_second": 24.953,
    "epoch": 0.5012531328320802,
    "step": 2000
  },
  {
    "loss": 0.0391,
    "grad_norm": 0.42675861716270447,
    "learning_rate": 8.320802005012531e-06,
    "epoch": 0.5037593984962406,
    "step": 2010
  },
  {
    "loss": 0.0244,
    "grad_norm": 0.23082102835178375,
    "learning_rate": 8.312447786131997e-06,
    "epoch": 0.506265664160401,
    "step": 2020
  },
  {
    "loss": 0.0461,
    "grad_norm": 0.23936894536018372,
    "learning_rate": 8.304093567251463e-06,
    "epoch": 0.5087719298245614,
    "step": 2030
  },
  {
    "loss": 0.0434,
    "grad_norm": 0.48211637139320374,
    "learning_rate": 8.295739348370928e-06,
    "epoch": 0.5112781954887218,
    "step": 2040
  },
  {
    "loss": 0.0481,
    "grad_norm": 0.2592555284500122,
    "learning_rate": 8.287385129490392e-06,
    "epoch": 0.5137844611528822,
    "step": 2050
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.48725008964538574,
    "learning_rate": 8.279030910609858e-06,
    "epoch": 0.5162907268170426,
    "step": 2060
  },
  {
    "loss": 0.0434,
    "grad_norm": 0.8241057395935059,
    "learning_rate": 8.270676691729324e-06,
    "epoch": 0.518796992481203,
    "step": 2070
  },
  {
    "loss": 0.0481,
    "grad_norm": 0.6768342852592468,
    "learning_rate": 8.26232247284879e-06,
    "epoch": 0.5213032581453634,
    "step": 2080
  },
  {
    "loss": 0.0585,
    "grad_norm": 0.3817325830459595,
    "learning_rate": 8.253968253968254e-06,
    "epoch": 0.5238095238095238,
    "step": 2090
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.5583608746528625,
    "learning_rate": 8.24561403508772e-06,
    "epoch": 0.5263157894736842,
    "step": 2100
  },
  {
    "loss": 0.0395,
    "grad_norm": 0.3769037127494812,
    "learning_rate": 8.237259816207185e-06,
    "epoch": 0.5288220551378446,
    "step": 2110
  },
  {
    "loss": 0.0581,
    "grad_norm": 0.5510460734367371,
    "learning_rate": 8.22890559732665e-06,
    "epoch": 0.531328320802005,
    "step": 2120
  },
  {
    "loss": 0.0466,
    "grad_norm": 0.2463127225637436,
    "learning_rate": 8.220551378446116e-06,
    "epoch": 0.5338345864661654,
    "step": 2130
  },
  {
    "loss": 0.0415,
    "grad_norm": 0.3871579170227051,
    "learning_rate": 8.212197159565582e-06,
    "epoch": 0.5363408521303258,
    "step": 2140
  },
  {
    "loss": 0.0352,
    "grad_norm": 0.5274417996406555,
    "learning_rate": 8.203842940685046e-06,
    "epoch": 0.5388471177944862,
    "step": 2150
  },
  {
    "loss": 0.0323,
    "grad_norm": 0.2629837989807129,
    "learning_rate": 8.195488721804512e-06,
    "epoch": 0.5413533834586466,
    "step": 2160
  },
  {
    "loss": 0.0457,
    "grad_norm": 0.36247918009757996,
    "learning_rate": 8.187134502923977e-06,
    "epoch": 0.543859649122807,
    "step": 2170
  },
  {
    "loss": 0.0558,
    "grad_norm": 0.8411960601806641,
    "learning_rate": 8.178780284043443e-06,
    "epoch": 0.5463659147869674,
    "step": 2180
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.33378809690475464,
    "learning_rate": 8.170426065162907e-06,
    "epoch": 0.5488721804511278,
    "step": 2190
  },
  {
    "loss": 0.0499,
    "grad_norm": 0.5261527299880981,
    "learning_rate": 8.162071846282373e-06,
    "epoch": 0.5513784461152882,
    "step": 2200
  },
  {
    "loss": 0.0524,
    "grad_norm": 0.5781334638595581,
    "learning_rate": 8.153717627401838e-06,
    "epoch": 0.5538847117794486,
    "step": 2210
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.4905671179294586,
    "learning_rate": 8.145363408521304e-06,
    "epoch": 0.556390977443609,
    "step": 2220
  },
  {
    "loss": 0.0408,
    "grad_norm": 0.39552953839302063,
    "learning_rate": 8.137009189640768e-06,
    "epoch": 0.5588972431077694,
    "step": 2230
  },
  {
    "loss": 0.0434,
    "grad_norm": 0.47216400504112244,
    "learning_rate": 8.128654970760235e-06,
    "epoch": 0.5614035087719298,
    "step": 2240
  },
  {
    "loss": 0.0456,
    "grad_norm": 0.7808021306991577,
    "learning_rate": 8.1203007518797e-06,
    "epoch": 0.5639097744360902,
    "step": 2250
  },
  {
    "eval_loss": 0.046755336225032806,
    "eval_roc_auc_macro": 0.9791183883356993,
    "eval_runtime": 40.0547,
    "eval_samples_per_second": 796.785,
    "eval_steps_per_second": 24.916,
    "epoch": 0.5639097744360902,
    "step": 2250
  },
  {
    "train_loss": 0.04282251000404358,
    "train_roc_auc_macro": 0.9814080374132846,
    "train_runtime": 160.0923,
    "train_samples_per_second": 797.39,
    "train_steps_per_second": 24.923,
    "epoch": 0.5639097744360902,
    "step": 2250
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.3058179020881653,
    "learning_rate": 8.111946532999165e-06,
    "epoch": 0.5664160401002506,
    "step": 2260
  },
  {
    "loss": 0.0525,
    "grad_norm": 0.6068707704544067,
    "learning_rate": 8.103592314118631e-06,
    "epoch": 0.568922305764411,
    "step": 2270
  },
  {
    "loss": 0.0466,
    "grad_norm": 0.5318282842636108,
    "learning_rate": 8.095238095238097e-06,
    "epoch": 0.5714285714285714,
    "step": 2280
  },
  {
    "loss": 0.042,
    "grad_norm": 0.2085951417684555,
    "learning_rate": 8.08688387635756e-06,
    "epoch": 0.5739348370927319,
    "step": 2290
  },
  {
    "loss": 0.0269,
    "grad_norm": 0.774880588054657,
    "learning_rate": 8.078529657477026e-06,
    "epoch": 0.5764411027568922,
    "step": 2300
  },
  {
    "loss": 0.0534,
    "grad_norm": 0.8749837875366211,
    "learning_rate": 8.070175438596492e-06,
    "epoch": 0.5789473684210527,
    "step": 2310
  },
  {
    "loss": 0.053,
    "grad_norm": 0.6688475608825684,
    "learning_rate": 8.061821219715958e-06,
    "epoch": 0.581453634085213,
    "step": 2320
  },
  {
    "loss": 0.0395,
    "grad_norm": 0.28910547494888306,
    "learning_rate": 8.053467000835422e-06,
    "epoch": 0.5839598997493735,
    "step": 2330
  },
  {
    "loss": 0.0483,
    "grad_norm": 0.5761030912399292,
    "learning_rate": 8.045112781954887e-06,
    "epoch": 0.5864661654135338,
    "step": 2340
  },
  {
    "loss": 0.0498,
    "grad_norm": 0.36647549271583557,
    "learning_rate": 8.036758563074353e-06,
    "epoch": 0.5889724310776943,
    "step": 2350
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.23151908814907074,
    "learning_rate": 8.028404344193819e-06,
    "epoch": 0.5914786967418546,
    "step": 2360
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.35237935185432434,
    "learning_rate": 8.020050125313283e-06,
    "epoch": 0.5939849624060151,
    "step": 2370
  },
  {
    "loss": 0.0445,
    "grad_norm": 0.2376294732093811,
    "learning_rate": 8.01169590643275e-06,
    "epoch": 0.5964912280701754,
    "step": 2380
  },
  {
    "loss": 0.0438,
    "grad_norm": 0.7909745573997498,
    "learning_rate": 8.003341687552214e-06,
    "epoch": 0.5989974937343359,
    "step": 2390
  },
  {
    "loss": 0.0389,
    "grad_norm": 0.32648521661758423,
    "learning_rate": 7.99498746867168e-06,
    "epoch": 0.6015037593984962,
    "step": 2400
  },
  {
    "loss": 0.0391,
    "grad_norm": 0.410068154335022,
    "learning_rate": 7.986633249791145e-06,
    "epoch": 0.6040100250626567,
    "step": 2410
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.19874683022499084,
    "learning_rate": 7.978279030910611e-06,
    "epoch": 0.606516290726817,
    "step": 2420
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.10280625522136688,
    "learning_rate": 7.969924812030075e-06,
    "epoch": 0.6090225563909775,
    "step": 2430
  },
  {
    "loss": 0.0445,
    "grad_norm": 0.4521344006061554,
    "learning_rate": 7.96157059314954e-06,
    "epoch": 0.6115288220551378,
    "step": 2440
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.1261381208896637,
    "learning_rate": 7.953216374269006e-06,
    "epoch": 0.6140350877192983,
    "step": 2450
  },
  {
    "loss": 0.036,
    "grad_norm": 0.5373885035514832,
    "learning_rate": 7.944862155388472e-06,
    "epoch": 0.6165413533834586,
    "step": 2460
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.5740786790847778,
    "learning_rate": 7.936507936507936e-06,
    "epoch": 0.6190476190476191,
    "step": 2470
  },
  {
    "loss": 0.0505,
    "grad_norm": 0.2933928966522217,
    "learning_rate": 7.928153717627402e-06,
    "epoch": 0.6215538847117794,
    "step": 2480
  },
  {
    "loss": 0.0509,
    "grad_norm": 0.5295627117156982,
    "learning_rate": 7.919799498746868e-06,
    "epoch": 0.6240601503759399,
    "step": 2490
  },
  {
    "loss": 0.0373,
    "grad_norm": 0.2952877879142761,
    "learning_rate": 7.911445279866333e-06,
    "epoch": 0.6265664160401002,
    "step": 2500
  },
  {
    "eval_loss": 0.04490691423416138,
    "eval_roc_auc_macro": 0.980701792539604,
    "eval_runtime": 40.1252,
    "eval_samples_per_second": 795.386,
    "eval_steps_per_second": 24.872,
    "epoch": 0.6265664160401002,
    "step": 2500
  },
  {
    "train_loss": 0.04104500636458397,
    "train_roc_auc_macro": 0.9821967879482453,
    "train_runtime": 160.0137,
    "train_samples_per_second": 797.782,
    "train_steps_per_second": 24.935,
    "epoch": 0.6265664160401002,
    "step": 2500
  },
  {
    "loss": 0.0382,
    "grad_norm": 0.32634252309799194,
    "learning_rate": 7.903091060985797e-06,
    "epoch": 0.6290726817042607,
    "step": 2510
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.5040091276168823,
    "learning_rate": 7.894736842105265e-06,
    "epoch": 0.631578947368421,
    "step": 2520
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.5769519209861755,
    "learning_rate": 7.886382623224729e-06,
    "epoch": 0.6340852130325815,
    "step": 2530
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.17105033993721008,
    "learning_rate": 7.878028404344194e-06,
    "epoch": 0.6365914786967418,
    "step": 2540
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.5136848092079163,
    "learning_rate": 7.86967418546366e-06,
    "epoch": 0.6390977443609023,
    "step": 2550
  },
  {
    "loss": 0.0519,
    "grad_norm": 0.40381094813346863,
    "learning_rate": 7.861319966583126e-06,
    "epoch": 0.6416040100250626,
    "step": 2560
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.41431134939193726,
    "learning_rate": 7.85296574770259e-06,
    "epoch": 0.6441102756892231,
    "step": 2570
  },
  {
    "loss": 0.0532,
    "grad_norm": 0.32213103771209717,
    "learning_rate": 7.844611528822055e-06,
    "epoch": 0.6466165413533834,
    "step": 2580
  },
  {
    "loss": 0.0461,
    "grad_norm": 0.5115065574645996,
    "learning_rate": 7.836257309941521e-06,
    "epoch": 0.6491228070175439,
    "step": 2590
  },
  {
    "loss": 0.0513,
    "grad_norm": 0.38854309916496277,
    "learning_rate": 7.827903091060987e-06,
    "epoch": 0.6516290726817042,
    "step": 2600
  },
  {
    "loss": 0.0469,
    "grad_norm": 0.8332545161247253,
    "learning_rate": 7.81954887218045e-06,
    "epoch": 0.6541353383458647,
    "step": 2610
  },
  {
    "loss": 0.0452,
    "grad_norm": 0.5922619104385376,
    "learning_rate": 7.811194653299916e-06,
    "epoch": 0.656641604010025,
    "step": 2620
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.32009780406951904,
    "learning_rate": 7.802840434419382e-06,
    "epoch": 0.6591478696741855,
    "step": 2630
  },
  {
    "loss": 0.0436,
    "grad_norm": 0.3035378158092499,
    "learning_rate": 7.794486215538848e-06,
    "epoch": 0.6616541353383458,
    "step": 2640
  },
  {
    "loss": 0.0379,
    "grad_norm": 0.41231071949005127,
    "learning_rate": 7.786131996658313e-06,
    "epoch": 0.6641604010025063,
    "step": 2650
  },
  {
    "loss": 0.0404,
    "grad_norm": 0.6598318815231323,
    "learning_rate": 7.77777777777778e-06,
    "epoch": 0.6666666666666666,
    "step": 2660
  },
  {
    "loss": 0.049,
    "grad_norm": 0.3010219633579254,
    "learning_rate": 7.769423558897243e-06,
    "epoch": 0.6691729323308271,
    "step": 2670
  },
  {
    "loss": 0.0511,
    "grad_norm": 0.5570711493492126,
    "learning_rate": 7.761069340016709e-06,
    "epoch": 0.6716791979949874,
    "step": 2680
  },
  {
    "loss": 0.0559,
    "grad_norm": 0.5006952285766602,
    "learning_rate": 7.752715121136175e-06,
    "epoch": 0.6741854636591479,
    "step": 2690
  },
  {
    "loss": 0.0514,
    "grad_norm": 0.4029986560344696,
    "learning_rate": 7.74436090225564e-06,
    "epoch": 0.6766917293233082,
    "step": 2700
  },
  {
    "loss": 0.0566,
    "grad_norm": 0.5382102131843567,
    "learning_rate": 7.736006683375104e-06,
    "epoch": 0.6791979949874687,
    "step": 2710
  },
  {
    "loss": 0.0406,
    "grad_norm": 0.3294801115989685,
    "learning_rate": 7.72765246449457e-06,
    "epoch": 0.681704260651629,
    "step": 2720
  },
  {
    "loss": 0.0458,
    "grad_norm": 0.29193994402885437,
    "learning_rate": 7.719298245614036e-06,
    "epoch": 0.6842105263157895,
    "step": 2730
  },
  {
    "loss": 0.0424,
    "grad_norm": 0.2828572690486908,
    "learning_rate": 7.710944026733501e-06,
    "epoch": 0.6867167919799498,
    "step": 2740
  },
  {
    "loss": 0.0318,
    "grad_norm": 0.1189131811261177,
    "learning_rate": 7.702589807852965e-06,
    "epoch": 0.6892230576441103,
    "step": 2750
  },
  {
    "eval_loss": 0.04299458488821983,
    "eval_roc_auc_macro": 0.9820245953578509,
    "eval_runtime": 40.1451,
    "eval_samples_per_second": 794.992,
    "eval_steps_per_second": 24.86,
    "epoch": 0.6892230576441103,
    "step": 2750
  },
  {
    "train_loss": 0.03872327879071236,
    "train_roc_auc_macro": 0.9838895393011658,
    "train_runtime": 160.0823,
    "train_samples_per_second": 797.44,
    "train_steps_per_second": 24.925,
    "epoch": 0.6892230576441103,
    "step": 2750
  },
  {
    "loss": 0.044,
    "grad_norm": 0.34565895795822144,
    "learning_rate": 7.694235588972433e-06,
    "epoch": 0.6917293233082706,
    "step": 2760
  },
  {
    "loss": 0.0383,
    "grad_norm": 0.476915568113327,
    "learning_rate": 7.685881370091897e-06,
    "epoch": 0.6942355889724311,
    "step": 2770
  },
  {
    "loss": 0.0422,
    "grad_norm": 1.3066436052322388,
    "learning_rate": 7.677527151211362e-06,
    "epoch": 0.6967418546365914,
    "step": 2780
  },
  {
    "loss": 0.0378,
    "grad_norm": 0.28593453764915466,
    "learning_rate": 7.669172932330828e-06,
    "epoch": 0.6992481203007519,
    "step": 2790
  },
  {
    "loss": 0.046,
    "grad_norm": 0.4218984842300415,
    "learning_rate": 7.660818713450294e-06,
    "epoch": 0.7017543859649122,
    "step": 2800
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.7330279350280762,
    "learning_rate": 7.652464494569758e-06,
    "epoch": 0.7042606516290727,
    "step": 2810
  },
  {
    "loss": 0.041,
    "grad_norm": 0.4116862118244171,
    "learning_rate": 7.644110275689223e-06,
    "epoch": 0.706766917293233,
    "step": 2820
  },
  {
    "loss": 0.0484,
    "grad_norm": 3.5461418628692627,
    "learning_rate": 7.635756056808689e-06,
    "epoch": 0.7092731829573935,
    "step": 2830
  },
  {
    "loss": 0.0482,
    "grad_norm": 0.9723710417747498,
    "learning_rate": 7.627401837928155e-06,
    "epoch": 0.7117794486215538,
    "step": 2840
  },
  {
    "loss": 0.0484,
    "grad_norm": 0.39086174964904785,
    "learning_rate": 7.61904761904762e-06,
    "epoch": 0.7142857142857143,
    "step": 2850
  },
  {
    "loss": 0.0605,
    "grad_norm": 0.5554119348526001,
    "learning_rate": 7.610693400167085e-06,
    "epoch": 0.7167919799498746,
    "step": 2860
  },
  {
    "loss": 0.0335,
    "grad_norm": 0.2631545960903168,
    "learning_rate": 7.60233918128655e-06,
    "epoch": 0.7192982456140351,
    "step": 2870
  },
  {
    "loss": 0.0486,
    "grad_norm": 0.7617390155792236,
    "learning_rate": 7.593984962406016e-06,
    "epoch": 0.7218045112781954,
    "step": 2880
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.34402230381965637,
    "learning_rate": 7.585630743525481e-06,
    "epoch": 0.7243107769423559,
    "step": 2890
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.3316960036754608,
    "learning_rate": 7.577276524644946e-06,
    "epoch": 0.7268170426065163,
    "step": 2900
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.3933026194572449,
    "learning_rate": 7.568922305764411e-06,
    "epoch": 0.7293233082706767,
    "step": 2910
  },
  {
    "loss": 0.0365,
    "grad_norm": 0.6534650325775146,
    "learning_rate": 7.560568086883877e-06,
    "epoch": 0.731829573934837,
    "step": 2920
  },
  {
    "loss": 0.04,
    "grad_norm": 0.07360972464084625,
    "learning_rate": 7.552213868003342e-06,
    "epoch": 0.7343358395989975,
    "step": 2930
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.36446091532707214,
    "learning_rate": 7.5438596491228074e-06,
    "epoch": 0.7368421052631579,
    "step": 2940
  },
  {
    "loss": 0.036,
    "grad_norm": 0.6677126884460449,
    "learning_rate": 7.535505430242272e-06,
    "epoch": 0.7393483709273183,
    "step": 2950
  },
  {
    "loss": 0.043,
    "grad_norm": 0.38900890946388245,
    "learning_rate": 7.527151211361739e-06,
    "epoch": 0.7418546365914787,
    "step": 2960
  },
  {
    "loss": 0.0367,
    "grad_norm": 0.44910991191864014,
    "learning_rate": 7.518796992481203e-06,
    "epoch": 0.7443609022556391,
    "step": 2970
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.2629150152206421,
    "learning_rate": 7.510442773600669e-06,
    "epoch": 0.7468671679197995,
    "step": 2980
  },
  {
    "loss": 0.0526,
    "grad_norm": 1.0222283601760864,
    "learning_rate": 7.502088554720134e-06,
    "epoch": 0.7493734335839599,
    "step": 2990
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.9469670653343201,
    "learning_rate": 7.4937343358396e-06,
    "epoch": 0.7518796992481203,
    "step": 3000
  },
  {
    "eval_loss": 0.044911254197359085,
    "eval_roc_auc_macro": 0.9828894587099204,
    "eval_runtime": 40.0237,
    "eval_samples_per_second": 797.403,
    "eval_steps_per_second": 24.935,
    "epoch": 0.7518796992481203,
    "step": 3000
  },
  {
    "train_loss": 0.04093064367771149,
    "train_roc_auc_macro": 0.984205577575565,
    "train_runtime": 160.0199,
    "train_samples_per_second": 797.751,
    "train_steps_per_second": 24.934,
    "epoch": 0.7518796992481203,
    "step": 3000
  },
  {
    "loss": 0.0432,
    "grad_norm": 0.5233346223831177,
    "learning_rate": 7.485380116959065e-06,
    "epoch": 0.7543859649122807,
    "step": 3010
  },
  {
    "loss": 0.0364,
    "grad_norm": 0.3410477638244629,
    "learning_rate": 7.47702589807853e-06,
    "epoch": 0.7568922305764411,
    "step": 3020
  },
  {
    "loss": 0.0506,
    "grad_norm": 0.404791921377182,
    "learning_rate": 7.468671679197995e-06,
    "epoch": 0.7593984962406015,
    "step": 3030
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.6998955607414246,
    "learning_rate": 7.460317460317461e-06,
    "epoch": 0.7619047619047619,
    "step": 3040
  },
  {
    "loss": 0.0526,
    "grad_norm": 0.7367052435874939,
    "learning_rate": 7.451963241436926e-06,
    "epoch": 0.7644110275689223,
    "step": 3050
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.3583686947822571,
    "learning_rate": 7.4436090225563915e-06,
    "epoch": 0.7669172932330827,
    "step": 3060
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.4628041088581085,
    "learning_rate": 7.435254803675856e-06,
    "epoch": 0.7694235588972431,
    "step": 3070
  },
  {
    "loss": 0.0416,
    "grad_norm": 0.366388738155365,
    "learning_rate": 7.426900584795322e-06,
    "epoch": 0.7719298245614035,
    "step": 3080
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.17758934199810028,
    "learning_rate": 7.418546365914787e-06,
    "epoch": 0.7744360902255639,
    "step": 3090
  },
  {
    "loss": 0.0431,
    "grad_norm": 0.5324889421463013,
    "learning_rate": 7.410192147034253e-06,
    "epoch": 0.7769423558897243,
    "step": 3100
  },
  {
    "loss": 0.0524,
    "grad_norm": 0.28818556666374207,
    "learning_rate": 7.401837928153718e-06,
    "epoch": 0.7794486215538847,
    "step": 3110
  },
  {
    "loss": 0.0353,
    "grad_norm": 0.4007064998149872,
    "learning_rate": 7.393483709273184e-06,
    "epoch": 0.7819548872180451,
    "step": 3120
  },
  {
    "loss": 0.0422,
    "grad_norm": 0.4579210877418518,
    "learning_rate": 7.385129490392649e-06,
    "epoch": 0.7844611528822055,
    "step": 3130
  },
  {
    "loss": 0.0403,
    "grad_norm": 0.36468520760536194,
    "learning_rate": 7.3767752715121144e-06,
    "epoch": 0.7869674185463659,
    "step": 3140
  },
  {
    "loss": 0.0422,
    "grad_norm": 0.4480423033237457,
    "learning_rate": 7.368421052631579e-06,
    "epoch": 0.7894736842105263,
    "step": 3150
  },
  {
    "loss": 0.0312,
    "grad_norm": 0.25135353207588196,
    "learning_rate": 7.360066833751045e-06,
    "epoch": 0.7919799498746867,
    "step": 3160
  },
  {
    "loss": 0.0379,
    "grad_norm": 0.20900152623653412,
    "learning_rate": 7.35171261487051e-06,
    "epoch": 0.7944862155388471,
    "step": 3170
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.974284291267395,
    "learning_rate": 7.3433583959899755e-06,
    "epoch": 0.7969924812030075,
    "step": 3180
  },
  {
    "loss": 0.0374,
    "grad_norm": 0.30065247416496277,
    "learning_rate": 7.33500417710944e-06,
    "epoch": 0.7994987468671679,
    "step": 3190
  },
  {
    "loss": 0.0386,
    "grad_norm": 0.4256852865219116,
    "learning_rate": 7.326649958228906e-06,
    "epoch": 0.8020050125313283,
    "step": 3200
  },
  {
    "loss": 0.0348,
    "grad_norm": 0.37798187136650085,
    "learning_rate": 7.318295739348371e-06,
    "epoch": 0.8045112781954887,
    "step": 3210
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.37754112482070923,
    "learning_rate": 7.309941520467837e-06,
    "epoch": 0.8070175438596491,
    "step": 3220
  },
  {
    "loss": 0.0497,
    "grad_norm": 0.34824177622795105,
    "learning_rate": 7.301587301587301e-06,
    "epoch": 0.8095238095238095,
    "step": 3230
  },
  {
    "loss": 0.0526,
    "grad_norm": 0.4104071259498596,
    "learning_rate": 7.293233082706768e-06,
    "epoch": 0.8120300751879699,
    "step": 3240
  },
  {
    "loss": 0.0503,
    "grad_norm": 0.6762646436691284,
    "learning_rate": 7.284878863826233e-06,
    "epoch": 0.8145363408521303,
    "step": 3250
  },
  {
    "eval_loss": 0.048811234533786774,
    "eval_roc_auc_macro": 0.9828081994658723,
    "eval_runtime": 40.0421,
    "eval_samples_per_second": 797.035,
    "eval_steps_per_second": 24.924,
    "epoch": 0.8145363408521303,
    "step": 3250
  },
  {
    "train_loss": 0.04536948725581169,
    "train_roc_auc_macro": 0.9847921423364673,
    "train_runtime": 160.1119,
    "train_samples_per_second": 797.292,
    "train_steps_per_second": 24.92,
    "epoch": 0.8145363408521303,
    "step": 3250
  },
  {
    "loss": 0.052,
    "grad_norm": 1.0593817234039307,
    "learning_rate": 7.2765246449456985e-06,
    "epoch": 0.8170426065162907,
    "step": 3260
  },
  {
    "loss": 0.0367,
    "grad_norm": 0.6887767314910889,
    "learning_rate": 7.268170426065163e-06,
    "epoch": 0.8195488721804511,
    "step": 3270
  },
  {
    "loss": 0.0436,
    "grad_norm": 0.44251400232315063,
    "learning_rate": 7.259816207184629e-06,
    "epoch": 0.8220551378446115,
    "step": 3280
  },
  {
    "loss": 0.039,
    "grad_norm": 0.5103345513343811,
    "learning_rate": 7.251461988304094e-06,
    "epoch": 0.8245614035087719,
    "step": 3290
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.2936038672924042,
    "learning_rate": 7.2431077694235595e-06,
    "epoch": 0.8270676691729323,
    "step": 3300
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.4468720257282257,
    "learning_rate": 7.234753550543024e-06,
    "epoch": 0.8295739348370927,
    "step": 3310
  },
  {
    "loss": 0.0276,
    "grad_norm": 0.33149513602256775,
    "learning_rate": 7.22639933166249e-06,
    "epoch": 0.8320802005012531,
    "step": 3320
  },
  {
    "loss": 0.0408,
    "grad_norm": 0.5854812860488892,
    "learning_rate": 7.218045112781955e-06,
    "epoch": 0.8345864661654135,
    "step": 3330
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.4162684679031372,
    "learning_rate": 7.209690893901421e-06,
    "epoch": 0.8370927318295739,
    "step": 3340
  },
  {
    "loss": 0.0475,
    "grad_norm": 0.5861561298370361,
    "learning_rate": 7.2013366750208854e-06,
    "epoch": 0.8395989974937343,
    "step": 3350
  },
  {
    "loss": 0.0449,
    "grad_norm": 0.5406683087348938,
    "learning_rate": 7.192982456140352e-06,
    "epoch": 0.8421052631578947,
    "step": 3360
  },
  {
    "loss": 0.0321,
    "grad_norm": 0.5075138807296753,
    "learning_rate": 7.184628237259817e-06,
    "epoch": 0.8446115288220551,
    "step": 3370
  },
  {
    "loss": 0.0416,
    "grad_norm": 0.4132612645626068,
    "learning_rate": 7.1762740183792825e-06,
    "epoch": 0.8471177944862155,
    "step": 3380
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.3361244201660156,
    "learning_rate": 7.167919799498747e-06,
    "epoch": 0.849624060150376,
    "step": 3390
  },
  {
    "loss": 0.042,
    "grad_norm": 0.5019863247871399,
    "learning_rate": 7.159565580618213e-06,
    "epoch": 0.8521303258145363,
    "step": 3400
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.6973429322242737,
    "learning_rate": 7.151211361737678e-06,
    "epoch": 0.8546365914786967,
    "step": 3410
  },
  {
    "loss": 0.046,
    "grad_norm": 0.6947752237319946,
    "learning_rate": 7.1428571428571436e-06,
    "epoch": 0.8571428571428571,
    "step": 3420
  },
  {
    "loss": 0.0436,
    "grad_norm": 0.16973550617694855,
    "learning_rate": 7.134502923976608e-06,
    "epoch": 0.8596491228070176,
    "step": 3430
  },
  {
    "loss": 0.0316,
    "grad_norm": 0.35363197326660156,
    "learning_rate": 7.126148705096074e-06,
    "epoch": 0.8621553884711779,
    "step": 3440
  },
  {
    "loss": 0.035,
    "grad_norm": 0.17828752100467682,
    "learning_rate": 7.117794486215539e-06,
    "epoch": 0.8646616541353384,
    "step": 3450
  },
  {
    "loss": 0.0401,
    "grad_norm": 0.2066318690776825,
    "learning_rate": 7.109440267335005e-06,
    "epoch": 0.8671679197994987,
    "step": 3460
  },
  {
    "loss": 0.0307,
    "grad_norm": 0.2536192238330841,
    "learning_rate": 7.1010860484544695e-06,
    "epoch": 0.8696741854636592,
    "step": 3470
  },
  {
    "loss": 0.0298,
    "grad_norm": 0.2414863258600235,
    "learning_rate": 7.092731829573936e-06,
    "epoch": 0.8721804511278195,
    "step": 3480
  },
  {
    "loss": 0.0367,
    "grad_norm": 0.5440540313720703,
    "learning_rate": 7.0843776106934e-06,
    "epoch": 0.87468671679198,
    "step": 3490
  },
  {
    "loss": 0.0529,
    "grad_norm": 0.4085918366909027,
    "learning_rate": 7.0760233918128665e-06,
    "epoch": 0.8771929824561403,
    "step": 3500
  },
  {
    "eval_loss": 0.04403473064303398,
    "eval_roc_auc_macro": 0.9824970000182839,
    "eval_runtime": 40.0283,
    "eval_samples_per_second": 797.312,
    "eval_steps_per_second": 24.932,
    "epoch": 0.8771929824561403,
    "step": 3500
  },
  {
    "train_loss": 0.03980768099427223,
    "train_roc_auc_macro": 0.9846718691343753,
    "train_runtime": 160.0266,
    "train_samples_per_second": 797.717,
    "train_steps_per_second": 24.933,
    "epoch": 0.8771929824561403,
    "step": 3500
  },
  {
    "loss": 0.0239,
    "grad_norm": 0.5222573280334473,
    "learning_rate": 7.067669172932331e-06,
    "epoch": 0.8796992481203008,
    "step": 3510
  },
  {
    "loss": 0.0372,
    "grad_norm": 0.19790151715278625,
    "learning_rate": 7.059314954051797e-06,
    "epoch": 0.8822055137844611,
    "step": 3520
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.5421543717384338,
    "learning_rate": 7.050960735171262e-06,
    "epoch": 0.8847117794486216,
    "step": 3530
  },
  {
    "loss": 0.0423,
    "grad_norm": 0.4811790883541107,
    "learning_rate": 7.042606516290728e-06,
    "epoch": 0.8872180451127819,
    "step": 3540
  },
  {
    "loss": 0.0371,
    "grad_norm": 0.8513017296791077,
    "learning_rate": 7.0342522974101924e-06,
    "epoch": 0.8897243107769424,
    "step": 3550
  },
  {
    "loss": 0.0407,
    "grad_norm": 0.5662989020347595,
    "learning_rate": 7.025898078529658e-06,
    "epoch": 0.8922305764411027,
    "step": 3560
  },
  {
    "loss": 0.0455,
    "grad_norm": 0.6198963522911072,
    "learning_rate": 7.017543859649123e-06,
    "epoch": 0.8947368421052632,
    "step": 3570
  },
  {
    "loss": 0.0528,
    "grad_norm": 0.47470444440841675,
    "learning_rate": 7.009189640768589e-06,
    "epoch": 0.8972431077694235,
    "step": 3580
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.2753835916519165,
    "learning_rate": 7.0008354218880535e-06,
    "epoch": 0.899749373433584,
    "step": 3590
  },
  {
    "loss": 0.0352,
    "grad_norm": 0.2347060590982437,
    "learning_rate": 6.992481203007519e-06,
    "epoch": 0.9022556390977443,
    "step": 3600
  },
  {
    "loss": 0.0402,
    "grad_norm": 0.14960871636867523,
    "learning_rate": 6.984126984126984e-06,
    "epoch": 0.9047619047619048,
    "step": 3610
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.24884693324565887,
    "learning_rate": 6.9757727652464506e-06,
    "epoch": 0.9072681704260651,
    "step": 3620
  },
  {
    "loss": 0.0548,
    "grad_norm": 0.8513985276222229,
    "learning_rate": 6.9674185463659146e-06,
    "epoch": 0.9097744360902256,
    "step": 3630
  },
  {
    "loss": 0.0434,
    "grad_norm": 0.4879763424396515,
    "learning_rate": 6.959064327485381e-06,
    "epoch": 0.9122807017543859,
    "step": 3640
  },
  {
    "loss": 0.0518,
    "grad_norm": 0.3825809061527252,
    "learning_rate": 6.950710108604846e-06,
    "epoch": 0.9147869674185464,
    "step": 3650
  },
  {
    "loss": 0.0515,
    "grad_norm": 1.3277159929275513,
    "learning_rate": 6.942355889724312e-06,
    "epoch": 0.9172932330827067,
    "step": 3660
  },
  {
    "loss": 0.0485,
    "grad_norm": 0.3743226230144501,
    "learning_rate": 6.9340016708437765e-06,
    "epoch": 0.9197994987468672,
    "step": 3670
  },
  {
    "loss": 0.047,
    "grad_norm": 0.7958501577377319,
    "learning_rate": 6.925647451963242e-06,
    "epoch": 0.9223057644110275,
    "step": 3680
  },
  {
    "loss": 0.0412,
    "grad_norm": 0.30338990688323975,
    "learning_rate": 6.917293233082707e-06,
    "epoch": 0.924812030075188,
    "step": 3690
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.3436245918273926,
    "learning_rate": 6.908939014202173e-06,
    "epoch": 0.9273182957393483,
    "step": 3700
  },
  {
    "loss": 0.0584,
    "grad_norm": 0.45915141701698303,
    "learning_rate": 6.9005847953216375e-06,
    "epoch": 0.9298245614035088,
    "step": 3710
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.5065259337425232,
    "learning_rate": 6.892230576441103e-06,
    "epoch": 0.9323308270676691,
    "step": 3720
  },
  {
    "loss": 0.0627,
    "grad_norm": 0.4830322563648224,
    "learning_rate": 6.883876357560568e-06,
    "epoch": 0.9348370927318296,
    "step": 3730
  },
  {
    "loss": 0.0367,
    "grad_norm": 0.4849262237548828,
    "learning_rate": 6.875522138680034e-06,
    "epoch": 0.9373433583959899,
    "step": 3740
  },
  {
    "loss": 0.0402,
    "grad_norm": 0.2110922932624817,
    "learning_rate": 6.867167919799499e-06,
    "epoch": 0.9398496240601504,
    "step": 3750
  },
  {
    "eval_loss": 0.042228370904922485,
    "eval_roc_auc_macro": 0.9826899671970675,
    "eval_runtime": 40.1407,
    "eval_samples_per_second": 795.079,
    "eval_steps_per_second": 24.863,
    "epoch": 0.9398496240601504,
    "step": 3750
  },
  {
    "train_loss": 0.03730303421616554,
    "train_roc_auc_macro": 0.9849391317419455,
    "train_runtime": 159.8085,
    "train_samples_per_second": 798.806,
    "train_steps_per_second": 24.967,
    "epoch": 0.9398496240601504,
    "step": 3750
  },
  {
    "loss": 0.036,
    "grad_norm": 0.444882333278656,
    "learning_rate": 6.858813700918965e-06,
    "epoch": 0.9423558897243107,
    "step": 3760
  },
  {
    "loss": 0.0298,
    "grad_norm": 0.239082470536232,
    "learning_rate": 6.85045948203843e-06,
    "epoch": 0.9448621553884712,
    "step": 3770
  },
  {
    "loss": 0.0469,
    "grad_norm": 0.1758188009262085,
    "learning_rate": 6.842105263157896e-06,
    "epoch": 0.9473684210526315,
    "step": 3780
  },
  {
    "loss": 0.028,
    "grad_norm": 0.4567941427230835,
    "learning_rate": 6.8337510442773605e-06,
    "epoch": 0.949874686716792,
    "step": 3790
  },
  {
    "loss": 0.0439,
    "grad_norm": 0.6610798835754395,
    "learning_rate": 6.825396825396826e-06,
    "epoch": 0.9523809523809523,
    "step": 3800
  },
  {
    "loss": 0.0389,
    "grad_norm": 0.3709288537502289,
    "learning_rate": 6.817042606516291e-06,
    "epoch": 0.9548872180451128,
    "step": 3810
  },
  {
    "loss": 0.0459,
    "grad_norm": 0.4340035021305084,
    "learning_rate": 6.808688387635757e-06,
    "epoch": 0.9573934837092731,
    "step": 3820
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.48093071579933167,
    "learning_rate": 6.8003341687552216e-06,
    "epoch": 0.9598997493734336,
    "step": 3830
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.2787089943885803,
    "learning_rate": 6.791979949874687e-06,
    "epoch": 0.9624060150375939,
    "step": 3840
  },
  {
    "loss": 0.0438,
    "grad_norm": 0.6081119775772095,
    "learning_rate": 6.783625730994152e-06,
    "epoch": 0.9649122807017544,
    "step": 3850
  },
  {
    "loss": 0.0389,
    "grad_norm": 0.28129294514656067,
    "learning_rate": 6.775271512113618e-06,
    "epoch": 0.9674185463659147,
    "step": 3860
  },
  {
    "loss": 0.0335,
    "grad_norm": 0.3839602768421173,
    "learning_rate": 6.766917293233083e-06,
    "epoch": 0.9699248120300752,
    "step": 3870
  },
  {
    "loss": 0.0449,
    "grad_norm": 0.9573822617530823,
    "learning_rate": 6.758563074352549e-06,
    "epoch": 0.9724310776942355,
    "step": 3880
  },
  {
    "loss": 0.0341,
    "grad_norm": 0.26318415999412537,
    "learning_rate": 6.750208855472013e-06,
    "epoch": 0.974937343358396,
    "step": 3890
  },
  {
    "loss": 0.0362,
    "grad_norm": 0.38419100642204285,
    "learning_rate": 6.74185463659148e-06,
    "epoch": 0.9774436090225563,
    "step": 3900
  },
  {
    "loss": 0.0389,
    "grad_norm": 0.4193378984928131,
    "learning_rate": 6.7335004177109445e-06,
    "epoch": 0.9799498746867168,
    "step": 3910
  },
  {
    "loss": 0.0524,
    "grad_norm": 0.24303051829338074,
    "learning_rate": 6.72514619883041e-06,
    "epoch": 0.9824561403508771,
    "step": 3920
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.07734563201665878,
    "learning_rate": 6.716791979949875e-06,
    "epoch": 0.9849624060150376,
    "step": 3930
  },
  {
    "loss": 0.0557,
    "grad_norm": 0.7086246013641357,
    "learning_rate": 6.708437761069341e-06,
    "epoch": 0.9874686716791979,
    "step": 3940
  },
  {
    "loss": 0.0531,
    "grad_norm": 0.3094368278980255,
    "learning_rate": 6.700083542188806e-06,
    "epoch": 0.9899749373433584,
    "step": 3950
  },
  {
    "loss": 0.0472,
    "grad_norm": 0.3591432273387909,
    "learning_rate": 6.691729323308271e-06,
    "epoch": 0.9924812030075187,
    "step": 3960
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.28353530168533325,
    "learning_rate": 6.683375104427736e-06,
    "epoch": 0.9949874686716792,
    "step": 3970
  },
  {
    "loss": 0.0378,
    "grad_norm": 0.7183032035827637,
    "learning_rate": 6.675020885547202e-06,
    "epoch": 0.9974937343358395,
    "step": 3980
  },
  {
    "loss": 0.0342,
    "grad_norm": 0.5414900183677673,
    "learning_rate": 6.666666666666667e-06,
    "epoch": 1.0,
    "step": 3990
  },
  {
    "loss": 0.0408,
    "grad_norm": 0.5689371228218079,
    "learning_rate": 6.658312447786132e-06,
    "epoch": 1.0025062656641603,
    "step": 4000
  },
  {
    "eval_loss": 0.048564691096544266,
    "eval_roc_auc_macro": 0.983613135510979,
    "eval_runtime": 40.0446,
    "eval_samples_per_second": 796.987,
    "eval_steps_per_second": 24.922,
    "epoch": 1.0025062656641603,
    "step": 4000
  },
  {
    "train_loss": 0.04371526464819908,
    "train_roc_auc_macro": 0.9857306314590573,
    "train_runtime": 160.079,
    "train_samples_per_second": 797.456,
    "train_steps_per_second": 24.925,
    "epoch": 1.0025062656641603,
    "step": 4000
  },
  {
    "loss": 0.0346,
    "grad_norm": 0.4032633602619171,
    "learning_rate": 6.649958228905597e-06,
    "epoch": 1.0050125313283207,
    "step": 4010
  },
  {
    "loss": 0.0368,
    "grad_norm": 0.6294888257980347,
    "learning_rate": 6.641604010025064e-06,
    "epoch": 1.0075187969924813,
    "step": 4020
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.19267767667770386,
    "learning_rate": 6.6332497911445286e-06,
    "epoch": 1.0100250626566416,
    "step": 4030
  },
  {
    "loss": 0.0294,
    "grad_norm": 0.612042248249054,
    "learning_rate": 6.624895572263994e-06,
    "epoch": 1.012531328320802,
    "step": 4040
  },
  {
    "loss": 0.0276,
    "grad_norm": 0.29186686873435974,
    "learning_rate": 6.616541353383459e-06,
    "epoch": 1.0150375939849625,
    "step": 4050
  },
  {
    "loss": 0.0277,
    "grad_norm": 0.6909663677215576,
    "learning_rate": 6.608187134502925e-06,
    "epoch": 1.0175438596491229,
    "step": 4060
  },
  {
    "loss": 0.0368,
    "grad_norm": 0.5786388516426086,
    "learning_rate": 6.59983291562239e-06,
    "epoch": 1.0200501253132832,
    "step": 4070
  },
  {
    "loss": 0.0317,
    "grad_norm": 0.3097076714038849,
    "learning_rate": 6.591478696741855e-06,
    "epoch": 1.0225563909774436,
    "step": 4080
  },
  {
    "loss": 0.0399,
    "grad_norm": 0.6215804219245911,
    "learning_rate": 6.58312447786132e-06,
    "epoch": 1.025062656641604,
    "step": 4090
  },
  {
    "loss": 0.0326,
    "grad_norm": 0.08355136215686798,
    "learning_rate": 6.574770258980786e-06,
    "epoch": 1.0275689223057645,
    "step": 4100
  },
  {
    "loss": 0.0428,
    "grad_norm": 0.5046314597129822,
    "learning_rate": 6.566416040100251e-06,
    "epoch": 1.0300751879699248,
    "step": 4110
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.2169160395860672,
    "learning_rate": 6.558061821219716e-06,
    "epoch": 1.0325814536340852,
    "step": 4120
  },
  {
    "loss": 0.0325,
    "grad_norm": 0.3464725911617279,
    "learning_rate": 6.549707602339181e-06,
    "epoch": 1.0350877192982457,
    "step": 4130
  },
  {
    "loss": 0.0441,
    "grad_norm": 0.8284466862678528,
    "learning_rate": 6.541353383458648e-06,
    "epoch": 1.037593984962406,
    "step": 4140
  },
  {
    "loss": 0.0364,
    "grad_norm": 0.423149049282074,
    "learning_rate": 6.532999164578112e-06,
    "epoch": 1.0401002506265664,
    "step": 4150
  },
  {
    "loss": 0.0463,
    "grad_norm": 0.6092456579208374,
    "learning_rate": 6.524644945697578e-06,
    "epoch": 1.0426065162907268,
    "step": 4160
  },
  {
    "loss": 0.0399,
    "grad_norm": 0.20451346039772034,
    "learning_rate": 6.516290726817043e-06,
    "epoch": 1.045112781954887,
    "step": 4170
  },
  {
    "loss": 0.0554,
    "grad_norm": 0.15516677498817444,
    "learning_rate": 6.507936507936509e-06,
    "epoch": 1.0476190476190477,
    "step": 4180
  },
  {
    "loss": 0.0522,
    "grad_norm": 0.1306852102279663,
    "learning_rate": 6.499582289055974e-06,
    "epoch": 1.050125313283208,
    "step": 4190
  },
  {
    "loss": 0.0305,
    "grad_norm": 0.45931360125541687,
    "learning_rate": 6.491228070175439e-06,
    "epoch": 1.0526315789473684,
    "step": 4200
  },
  {
    "loss": 0.0504,
    "grad_norm": 0.6807629466056824,
    "learning_rate": 6.482873851294904e-06,
    "epoch": 1.055137844611529,
    "step": 4210
  },
  {
    "loss": 0.0393,
    "grad_norm": 0.44510096311569214,
    "learning_rate": 6.47451963241437e-06,
    "epoch": 1.0576441102756893,
    "step": 4220
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.5579452514648438,
    "learning_rate": 6.466165413533835e-06,
    "epoch": 1.0601503759398496,
    "step": 4230
  },
  {
    "loss": 0.0234,
    "grad_norm": 0.24025557935237885,
    "learning_rate": 6.4578111946533e-06,
    "epoch": 1.06265664160401,
    "step": 4240
  },
  {
    "loss": 0.0457,
    "grad_norm": 0.5433552265167236,
    "learning_rate": 6.449456975772765e-06,
    "epoch": 1.0651629072681703,
    "step": 4250
  },
  {
    "eval_loss": 0.042404863983392715,
    "eval_roc_auc_macro": 0.9830436877567545,
    "eval_runtime": 40.0474,
    "eval_samples_per_second": 796.931,
    "eval_steps_per_second": 24.92,
    "epoch": 1.0651629072681703,
    "step": 4250
  },
  {
    "train_loss": 0.036870114505290985,
    "train_roc_auc_macro": 0.986117098478741,
    "train_runtime": 160.097,
    "train_samples_per_second": 797.367,
    "train_steps_per_second": 24.922,
    "epoch": 1.0651629072681703,
    "step": 4250
  },
  {
    "loss": 0.0332,
    "grad_norm": 0.4276326298713684,
    "learning_rate": 6.441102756892231e-06,
    "epoch": 1.0676691729323309,
    "step": 4260
  },
  {
    "loss": 0.0402,
    "grad_norm": 0.6373987793922424,
    "learning_rate": 6.432748538011696e-06,
    "epoch": 1.0701754385964912,
    "step": 4270
  },
  {
    "loss": 0.0259,
    "grad_norm": 0.37270480394363403,
    "learning_rate": 6.424394319131162e-06,
    "epoch": 1.0726817042606516,
    "step": 4280
  },
  {
    "loss": 0.0482,
    "grad_norm": 0.19603340327739716,
    "learning_rate": 6.416040100250627e-06,
    "epoch": 1.0751879699248121,
    "step": 4290
  },
  {
    "loss": 0.0549,
    "grad_norm": 0.764324426651001,
    "learning_rate": 6.407685881370093e-06,
    "epoch": 1.0776942355889725,
    "step": 4300
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.5592923760414124,
    "learning_rate": 6.399331662489558e-06,
    "epoch": 1.0802005012531328,
    "step": 4310
  },
  {
    "loss": 0.0317,
    "grad_norm": 1.003185510635376,
    "learning_rate": 6.390977443609023e-06,
    "epoch": 1.0827067669172932,
    "step": 4320
  },
  {
    "loss": 0.024,
    "grad_norm": 0.3875623643398285,
    "learning_rate": 6.382623224728488e-06,
    "epoch": 1.0852130325814535,
    "step": 4330
  },
  {
    "loss": 0.0349,
    "grad_norm": 0.5592448711395264,
    "learning_rate": 6.374269005847954e-06,
    "epoch": 1.087719298245614,
    "step": 4340
  },
  {
    "loss": 0.0447,
    "grad_norm": 0.2722276747226715,
    "learning_rate": 6.365914786967419e-06,
    "epoch": 1.0902255639097744,
    "step": 4350
  },
  {
    "loss": 0.0363,
    "grad_norm": 0.4046996831893921,
    "learning_rate": 6.3575605680868844e-06,
    "epoch": 1.0927318295739348,
    "step": 4360
  },
  {
    "loss": 0.0396,
    "grad_norm": 0.14314375817775726,
    "learning_rate": 6.349206349206349e-06,
    "epoch": 1.0952380952380953,
    "step": 4370
  },
  {
    "loss": 0.0354,
    "grad_norm": 0.7204777002334595,
    "learning_rate": 6.340852130325815e-06,
    "epoch": 1.0977443609022557,
    "step": 4380
  },
  {
    "loss": 0.0428,
    "grad_norm": 0.6643456816673279,
    "learning_rate": 6.33249791144528e-06,
    "epoch": 1.100250626566416,
    "step": 4390
  },
  {
    "loss": 0.0508,
    "grad_norm": 0.34549760818481445,
    "learning_rate": 6.324143692564746e-06,
    "epoch": 1.1027568922305764,
    "step": 4400
  },
  {
    "loss": 0.0468,
    "grad_norm": 0.5830257534980774,
    "learning_rate": 6.31578947368421e-06,
    "epoch": 1.1052631578947367,
    "step": 4410
  },
  {
    "loss": 0.0455,
    "grad_norm": 0.49075934290885925,
    "learning_rate": 6.307435254803677e-06,
    "epoch": 1.1077694235588973,
    "step": 4420
  },
  {
    "loss": 0.0441,
    "grad_norm": 0.4059816002845764,
    "learning_rate": 6.299081035923142e-06,
    "epoch": 1.1102756892230576,
    "step": 4430
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.27880731225013733,
    "learning_rate": 6.290726817042607e-06,
    "epoch": 1.112781954887218,
    "step": 4440
  },
  {
    "loss": 0.0518,
    "grad_norm": 1.0637881755828857,
    "learning_rate": 6.282372598162072e-06,
    "epoch": 1.1152882205513786,
    "step": 4450
  },
  {
    "loss": 0.0424,
    "grad_norm": 0.3857598304748535,
    "learning_rate": 6.274018379281538e-06,
    "epoch": 1.117794486215539,
    "step": 4460
  },
  {
    "loss": 0.0342,
    "grad_norm": 0.4849005937576294,
    "learning_rate": 6.265664160401003e-06,
    "epoch": 1.1203007518796992,
    "step": 4470
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.24885569512844086,
    "learning_rate": 6.2573099415204685e-06,
    "epoch": 1.1228070175438596,
    "step": 4480
  },
  {
    "loss": 0.0294,
    "grad_norm": 0.2720469534397125,
    "learning_rate": 6.248955722639933e-06,
    "epoch": 1.12531328320802,
    "step": 4490
  },
  {
    "loss": 0.0331,
    "grad_norm": 0.4908117651939392,
    "learning_rate": 6.240601503759399e-06,
    "epoch": 1.1278195488721805,
    "step": 4500
  },
  {
    "eval_loss": 0.04378658905625343,
    "eval_roc_auc_macro": 0.983834454444433,
    "eval_runtime": 40.0311,
    "eval_samples_per_second": 797.255,
    "eval_steps_per_second": 24.931,
    "epoch": 1.1278195488721805,
    "step": 4500
  },
  {
    "train_loss": 0.0381205752491951,
    "train_roc_auc_macro": 0.9870463842551899,
    "train_runtime": 160.149,
    "train_samples_per_second": 797.108,
    "train_steps_per_second": 24.914,
    "epoch": 1.1278195488721805,
    "step": 4500
  },
  {
    "loss": 0.0416,
    "grad_norm": 0.975957989692688,
    "learning_rate": 6.232247284878864e-06,
    "epoch": 1.1303258145363408,
    "step": 4510
  },
  {
    "loss": 0.0327,
    "grad_norm": 0.3181970417499542,
    "learning_rate": 6.2238930659983295e-06,
    "epoch": 1.1328320802005012,
    "step": 4520
  },
  {
    "loss": 0.0382,
    "grad_norm": 0.48425590991973877,
    "learning_rate": 6.215538847117794e-06,
    "epoch": 1.1353383458646618,
    "step": 4530
  },
  {
    "loss": 0.031,
    "grad_norm": 0.4373329281806946,
    "learning_rate": 6.207184628237261e-06,
    "epoch": 1.137844611528822,
    "step": 4540
  },
  {
    "loss": 0.0348,
    "grad_norm": 0.4815737009048462,
    "learning_rate": 6.198830409356725e-06,
    "epoch": 1.1403508771929824,
    "step": 4550
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.5263585448265076,
    "learning_rate": 6.1904761904761914e-06,
    "epoch": 1.1428571428571428,
    "step": 4560
  },
  {
    "loss": 0.0429,
    "grad_norm": 0.7249641418457031,
    "learning_rate": 6.182121971595656e-06,
    "epoch": 1.1453634085213031,
    "step": 4570
  },
  {
    "loss": 0.0329,
    "grad_norm": 0.05619930848479271,
    "learning_rate": 6.173767752715122e-06,
    "epoch": 1.1478696741854637,
    "step": 4580
  },
  {
    "loss": 0.048,
    "grad_norm": 0.5431390404701233,
    "learning_rate": 6.165413533834587e-06,
    "epoch": 1.150375939849624,
    "step": 4590
  },
  {
    "loss": 0.0519,
    "grad_norm": 0.5628699660301208,
    "learning_rate": 6.1570593149540525e-06,
    "epoch": 1.1528822055137844,
    "step": 4600
  },
  {
    "loss": 0.0317,
    "grad_norm": 0.126090407371521,
    "learning_rate": 6.148705096073517e-06,
    "epoch": 1.155388471177945,
    "step": 4610
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.5262156128883362,
    "learning_rate": 6.140350877192983e-06,
    "epoch": 1.1578947368421053,
    "step": 4620
  },
  {
    "loss": 0.0333,
    "grad_norm": 0.010185261256992817,
    "learning_rate": 6.131996658312448e-06,
    "epoch": 1.1604010025062657,
    "step": 4630
  },
  {
    "loss": 0.0356,
    "grad_norm": 0.3544754981994629,
    "learning_rate": 6.1236424394319135e-06,
    "epoch": 1.162907268170426,
    "step": 4640
  },
  {
    "loss": 0.0574,
    "grad_norm": 0.5727601051330566,
    "learning_rate": 6.115288220551378e-06,
    "epoch": 1.1654135338345863,
    "step": 4650
  },
  {
    "loss": 0.039,
    "grad_norm": 0.287481427192688,
    "learning_rate": 6.106934001670844e-06,
    "epoch": 1.167919799498747,
    "step": 4660
  },
  {
    "loss": 0.0287,
    "grad_norm": 0.32994741201400757,
    "learning_rate": 6.098579782790309e-06,
    "epoch": 1.1704260651629073,
    "step": 4670
  },
  {
    "loss": 0.0404,
    "grad_norm": 0.8284792304039001,
    "learning_rate": 6.0902255639097755e-06,
    "epoch": 1.1729323308270676,
    "step": 4680
  },
  {
    "loss": 0.034,
    "grad_norm": 0.5398133397102356,
    "learning_rate": 6.08187134502924e-06,
    "epoch": 1.1754385964912282,
    "step": 4690
  },
  {
    "loss": 0.038,
    "grad_norm": 0.6179161667823792,
    "learning_rate": 6.073517126148706e-06,
    "epoch": 1.1779448621553885,
    "step": 4700
  },
  {
    "loss": 0.0463,
    "grad_norm": 0.46442216634750366,
    "learning_rate": 6.065162907268171e-06,
    "epoch": 1.1804511278195489,
    "step": 4710
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.18412207067012787,
    "learning_rate": 6.0568086883876365e-06,
    "epoch": 1.1829573934837092,
    "step": 4720
  },
  {
    "loss": 0.0458,
    "grad_norm": 0.7151626348495483,
    "learning_rate": 6.048454469507101e-06,
    "epoch": 1.1854636591478696,
    "step": 4730
  },
  {
    "loss": 0.0483,
    "grad_norm": 0.7000407576560974,
    "learning_rate": 6.040100250626567e-06,
    "epoch": 1.1879699248120301,
    "step": 4740
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.33564257621765137,
    "learning_rate": 6.031746031746032e-06,
    "epoch": 1.1904761904761905,
    "step": 4750
  },
  {
    "eval_loss": 0.0423511378467083,
    "eval_roc_auc_macro": 0.9852606704870697,
    "eval_runtime": 40.0817,
    "eval_samples_per_second": 796.248,
    "eval_steps_per_second": 24.899,
    "epoch": 1.1904761904761905,
    "step": 4750
  },
  {
    "train_loss": 0.03712745010852814,
    "train_roc_auc_macro": 0.9878082144838193,
    "train_runtime": 160.0319,
    "train_samples_per_second": 797.691,
    "train_steps_per_second": 24.933,
    "epoch": 1.1904761904761905,
    "step": 4750
  },
  {
    "loss": 0.0379,
    "grad_norm": 0.6941669583320618,
    "learning_rate": 6.023391812865498e-06,
    "epoch": 1.1929824561403508,
    "step": 4760
  },
  {
    "loss": 0.0294,
    "grad_norm": 0.4326702356338501,
    "learning_rate": 6.015037593984962e-06,
    "epoch": 1.1954887218045114,
    "step": 4770
  },
  {
    "loss": 0.0401,
    "grad_norm": 0.4265258312225342,
    "learning_rate": 6.006683375104428e-06,
    "epoch": 1.1979949874686717,
    "step": 4780
  },
  {
    "loss": 0.0305,
    "grad_norm": 0.27312591671943665,
    "learning_rate": 5.998329156223893e-06,
    "epoch": 1.200501253132832,
    "step": 4790
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.3788611590862274,
    "learning_rate": 5.9899749373433595e-06,
    "epoch": 1.2030075187969924,
    "step": 4800
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.7349147200584412,
    "learning_rate": 5.9816207184628235e-06,
    "epoch": 1.2055137844611528,
    "step": 4810
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.20814965665340424,
    "learning_rate": 5.97326649958229e-06,
    "epoch": 1.2080200501253133,
    "step": 4820
  },
  {
    "loss": 0.0436,
    "grad_norm": 0.3237966299057007,
    "learning_rate": 5.964912280701755e-06,
    "epoch": 1.2105263157894737,
    "step": 4830
  },
  {
    "loss": 0.0467,
    "grad_norm": 0.2955785095691681,
    "learning_rate": 5.9565580618212205e-06,
    "epoch": 1.213032581453634,
    "step": 4840
  },
  {
    "loss": 0.0338,
    "grad_norm": 0.26365864276885986,
    "learning_rate": 5.948203842940685e-06,
    "epoch": 1.2155388471177946,
    "step": 4850
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.19212710857391357,
    "learning_rate": 5.939849624060151e-06,
    "epoch": 1.218045112781955,
    "step": 4860
  },
  {
    "loss": 0.038,
    "grad_norm": 0.3016059994697571,
    "learning_rate": 5.931495405179616e-06,
    "epoch": 1.2205513784461153,
    "step": 4870
  },
  {
    "loss": 0.0419,
    "grad_norm": 0.19515369832515717,
    "learning_rate": 5.923141186299082e-06,
    "epoch": 1.2230576441102756,
    "step": 4880
  },
  {
    "loss": 0.0275,
    "grad_norm": 0.26592332124710083,
    "learning_rate": 5.9147869674185465e-06,
    "epoch": 1.225563909774436,
    "step": 4890
  },
  {
    "loss": 0.0319,
    "grad_norm": 0.6086524724960327,
    "learning_rate": 5.906432748538012e-06,
    "epoch": 1.2280701754385965,
    "step": 4900
  },
  {
    "loss": 0.0404,
    "grad_norm": 0.34025517106056213,
    "learning_rate": 5.898078529657477e-06,
    "epoch": 1.2305764411027569,
    "step": 4910
  },
  {
    "loss": 0.0309,
    "grad_norm": 0.2694992125034332,
    "learning_rate": 5.889724310776943e-06,
    "epoch": 1.2330827067669172,
    "step": 4920
  },
  {
    "loss": 0.042,
    "grad_norm": 0.690390408039093,
    "learning_rate": 5.8813700918964075e-06,
    "epoch": 1.2355889724310778,
    "step": 4930
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.34681710600852966,
    "learning_rate": 5.873015873015874e-06,
    "epoch": 1.2380952380952381,
    "step": 4940
  },
  {
    "loss": 0.0396,
    "grad_norm": 1.1608861684799194,
    "learning_rate": 5.864661654135339e-06,
    "epoch": 1.2406015037593985,
    "step": 4950
  },
  {
    "loss": 0.0405,
    "grad_norm": 0.41334763169288635,
    "learning_rate": 5.856307435254805e-06,
    "epoch": 1.2431077694235588,
    "step": 4960
  },
  {
    "loss": 0.0299,
    "grad_norm": 0.3570535480976105,
    "learning_rate": 5.847953216374269e-06,
    "epoch": 1.2456140350877192,
    "step": 4970
  },
  {
    "loss": 0.0326,
    "grad_norm": 0.610243558883667,
    "learning_rate": 5.839598997493735e-06,
    "epoch": 1.2481203007518797,
    "step": 4980
  },
  {
    "loss": 0.0355,
    "grad_norm": 0.34713491797447205,
    "learning_rate": 5.8312447786132e-06,
    "epoch": 1.25062656641604,
    "step": 4990
  },
  {
    "loss": 0.0433,
    "grad_norm": 0.49045079946517944,
    "learning_rate": 5.822890559732666e-06,
    "epoch": 1.2531328320802004,
    "step": 5000
  },
  {
    "eval_loss": 0.042975764721632004,
    "eval_roc_auc_macro": 0.9850302584017872,
    "eval_runtime": 40.0684,
    "eval_samples_per_second": 796.513,
    "eval_steps_per_second": 24.907,
    "epoch": 1.2531328320802004,
    "step": 5000
  },
  {
    "train_loss": 0.036232590675354004,
    "train_roc_auc_macro": 0.9874768570894128,
    "train_runtime": 160.0354,
    "train_samples_per_second": 797.674,
    "train_steps_per_second": 24.932,
    "epoch": 1.2531328320802004,
    "step": 5000
  },
  {
    "loss": 0.0294,
    "grad_norm": 0.5213409662246704,
    "learning_rate": 5.8145363408521305e-06,
    "epoch": 1.255639097744361,
    "step": 5010
  },
  {
    "loss": 0.0303,
    "grad_norm": 0.8073368072509766,
    "learning_rate": 5.806182121971596e-06,
    "epoch": 1.2581453634085213,
    "step": 5020
  },
  {
    "loss": 0.0309,
    "grad_norm": 0.5798935890197754,
    "learning_rate": 5.797827903091061e-06,
    "epoch": 1.2606516290726817,
    "step": 5030
  },
  {
    "loss": 0.0262,
    "grad_norm": 0.17765460908412933,
    "learning_rate": 5.789473684210527e-06,
    "epoch": 1.263157894736842,
    "step": 5040
  },
  {
    "loss": 0.0396,
    "grad_norm": 1.1368190050125122,
    "learning_rate": 5.7811194653299915e-06,
    "epoch": 1.2656641604010024,
    "step": 5050
  },
  {
    "loss": 0.0433,
    "grad_norm": 0.6098414659500122,
    "learning_rate": 5.772765246449458e-06,
    "epoch": 1.268170426065163,
    "step": 5060
  },
  {
    "loss": 0.03,
    "grad_norm": 0.3217276632785797,
    "learning_rate": 5.764411027568922e-06,
    "epoch": 1.2706766917293233,
    "step": 5070
  },
  {
    "loss": 0.0438,
    "grad_norm": 0.3812418580055237,
    "learning_rate": 5.756056808688389e-06,
    "epoch": 1.2731829573934836,
    "step": 5080
  },
  {
    "loss": 0.0397,
    "grad_norm": 0.8968520164489746,
    "learning_rate": 5.7477025898078535e-06,
    "epoch": 1.2756892230576442,
    "step": 5090
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.5664238929748535,
    "learning_rate": 5.739348370927319e-06,
    "epoch": 1.2781954887218046,
    "step": 5100
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.31212642788887024,
    "learning_rate": 5.730994152046784e-06,
    "epoch": 1.280701754385965,
    "step": 5110
  },
  {
    "loss": 0.0285,
    "grad_norm": 0.1605653017759323,
    "learning_rate": 5.72263993316625e-06,
    "epoch": 1.2832080200501252,
    "step": 5120
  },
  {
    "loss": 0.0327,
    "grad_norm": 0.35141971707344055,
    "learning_rate": 5.7142857142857145e-06,
    "epoch": 1.2857142857142856,
    "step": 5130
  },
  {
    "loss": 0.0563,
    "grad_norm": 0.8419257998466492,
    "learning_rate": 5.70593149540518e-06,
    "epoch": 1.2882205513784462,
    "step": 5140
  },
  {
    "loss": 0.0353,
    "grad_norm": 0.10742269456386566,
    "learning_rate": 5.697577276524645e-06,
    "epoch": 1.2907268170426065,
    "step": 5150
  },
  {
    "loss": 0.0424,
    "grad_norm": 0.1413206160068512,
    "learning_rate": 5.689223057644111e-06,
    "epoch": 1.2932330827067668,
    "step": 5160
  },
  {
    "loss": 0.0432,
    "grad_norm": 0.3031069040298462,
    "learning_rate": 5.6808688387635756e-06,
    "epoch": 1.2957393483709274,
    "step": 5170
  },
  {
    "loss": 0.0352,
    "grad_norm": 0.21399666368961334,
    "learning_rate": 5.672514619883041e-06,
    "epoch": 1.2982456140350878,
    "step": 5180
  },
  {
    "loss": 0.036,
    "grad_norm": 0.35575899481773376,
    "learning_rate": 5.664160401002506e-06,
    "epoch": 1.300751879699248,
    "step": 5190
  },
  {
    "loss": 0.0418,
    "grad_norm": 0.3140037953853607,
    "learning_rate": 5.655806182121973e-06,
    "epoch": 1.3032581453634084,
    "step": 5200
  },
  {
    "loss": 0.0347,
    "grad_norm": 0.7451584935188293,
    "learning_rate": 5.6474519632414375e-06,
    "epoch": 1.3057644110275688,
    "step": 5210
  },
  {
    "loss": 0.0471,
    "grad_norm": 0.4790022373199463,
    "learning_rate": 5.639097744360903e-06,
    "epoch": 1.3082706766917294,
    "step": 5220
  },
  {
    "loss": 0.0411,
    "grad_norm": 0.24041041731834412,
    "learning_rate": 5.630743525480368e-06,
    "epoch": 1.3107769423558897,
    "step": 5230
  },
  {
    "loss": 0.0295,
    "grad_norm": 0.41915175318717957,
    "learning_rate": 5.622389306599834e-06,
    "epoch": 1.31328320802005,
    "step": 5240
  },
  {
    "loss": 0.0426,
    "grad_norm": 0.3322940170764923,
    "learning_rate": 5.6140350877192985e-06,
    "epoch": 1.3157894736842106,
    "step": 5250
  },
  {
    "eval_loss": 0.04285445064306259,
    "eval_roc_auc_macro": 0.9863894120732382,
    "eval_runtime": 39.9992,
    "eval_samples_per_second": 797.892,
    "eval_steps_per_second": 24.951,
    "epoch": 1.3157894736842106,
    "step": 5250
  },
  {
    "train_loss": 0.036791857331991196,
    "train_roc_auc_macro": 0.9885529177582127,
    "train_runtime": 159.9911,
    "train_samples_per_second": 797.894,
    "train_steps_per_second": 24.939,
    "epoch": 1.3157894736842106,
    "step": 5250
  },
  {
    "loss": 0.0367,
    "grad_norm": 0.351863831281662,
    "learning_rate": 5.605680868838764e-06,
    "epoch": 1.318295739348371,
    "step": 5260
  },
  {
    "loss": 0.0319,
    "grad_norm": 0.13619083166122437,
    "learning_rate": 5.597326649958229e-06,
    "epoch": 1.3208020050125313,
    "step": 5270
  },
  {
    "loss": 0.0257,
    "grad_norm": 0.3755817413330078,
    "learning_rate": 5.588972431077695e-06,
    "epoch": 1.3233082706766917,
    "step": 5280
  },
  {
    "loss": 0.0317,
    "grad_norm": 0.4120734632015228,
    "learning_rate": 5.58061821219716e-06,
    "epoch": 1.325814536340852,
    "step": 5290
  },
  {
    "loss": 0.0536,
    "grad_norm": 0.6780737638473511,
    "learning_rate": 5.572263993316625e-06,
    "epoch": 1.3283208020050126,
    "step": 5300
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.7731581330299377,
    "learning_rate": 5.56390977443609e-06,
    "epoch": 1.330827067669173,
    "step": 5310
  },
  {
    "loss": 0.0467,
    "grad_norm": 0.9400215148925781,
    "learning_rate": 5.555555555555557e-06,
    "epoch": 1.3333333333333333,
    "step": 5320
  },
  {
    "loss": 0.0512,
    "grad_norm": 0.5370454788208008,
    "learning_rate": 5.547201336675021e-06,
    "epoch": 1.3358395989974938,
    "step": 5330
  },
  {
    "loss": 0.0399,
    "grad_norm": 0.5509061813354492,
    "learning_rate": 5.538847117794487e-06,
    "epoch": 1.3383458646616542,
    "step": 5340
  },
  {
    "loss": 0.0519,
    "grad_norm": 0.6148005723953247,
    "learning_rate": 5.530492898913952e-06,
    "epoch": 1.3408521303258145,
    "step": 5350
  },
  {
    "loss": 0.0336,
    "grad_norm": 0.6321110129356384,
    "learning_rate": 5.522138680033418e-06,
    "epoch": 1.3433583959899749,
    "step": 5360
  },
  {
    "loss": 0.0457,
    "grad_norm": 0.2051113098859787,
    "learning_rate": 5.5137844611528826e-06,
    "epoch": 1.3458646616541352,
    "step": 5370
  },
  {
    "loss": 0.046,
    "grad_norm": 0.4623883068561554,
    "learning_rate": 5.505430242272348e-06,
    "epoch": 1.3483709273182958,
    "step": 5380
  },
  {
    "loss": 0.0428,
    "grad_norm": 0.4035273492336273,
    "learning_rate": 5.497076023391813e-06,
    "epoch": 1.3508771929824561,
    "step": 5390
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.09445185959339142,
    "learning_rate": 5.488721804511279e-06,
    "epoch": 1.3533834586466165,
    "step": 5400
  },
  {
    "loss": 0.0356,
    "grad_norm": 0.38554149866104126,
    "learning_rate": 5.480367585630744e-06,
    "epoch": 1.355889724310777,
    "step": 5410
  },
  {
    "loss": 0.0405,
    "grad_norm": 0.29354122281074524,
    "learning_rate": 5.472013366750209e-06,
    "epoch": 1.3583959899749374,
    "step": 5420
  },
  {
    "loss": 0.0551,
    "grad_norm": 0.39145416021347046,
    "learning_rate": 5.463659147869674e-06,
    "epoch": 1.3609022556390977,
    "step": 5430
  },
  {
    "loss": 0.0359,
    "grad_norm": 0.5181493759155273,
    "learning_rate": 5.45530492898914e-06,
    "epoch": 1.363408521303258,
    "step": 5440
  },
  {
    "loss": 0.0427,
    "grad_norm": 0.6624869108200073,
    "learning_rate": 5.446950710108605e-06,
    "epoch": 1.3659147869674184,
    "step": 5450
  },
  {
    "loss": 0.042,
    "grad_norm": 0.6257243752479553,
    "learning_rate": 5.438596491228071e-06,
    "epoch": 1.368421052631579,
    "step": 5460
  },
  {
    "loss": 0.0357,
    "grad_norm": 0.4664570093154907,
    "learning_rate": 5.430242272347536e-06,
    "epoch": 1.3709273182957393,
    "step": 5470
  },
  {
    "loss": 0.0356,
    "grad_norm": 0.28538399934768677,
    "learning_rate": 5.421888053467002e-06,
    "epoch": 1.3734335839598997,
    "step": 5480
  },
  {
    "loss": 0.0282,
    "grad_norm": 0.615220844745636,
    "learning_rate": 5.413533834586467e-06,
    "epoch": 1.3759398496240602,
    "step": 5490
  },
  {
    "loss": 0.0253,
    "grad_norm": 0.06178580969572067,
    "learning_rate": 5.405179615705932e-06,
    "epoch": 1.3784461152882206,
    "step": 5500
  },
  {
    "eval_loss": 0.04120750352740288,
    "eval_roc_auc_macro": 0.9860856719612826,
    "eval_runtime": 40.029,
    "eval_samples_per_second": 797.296,
    "eval_steps_per_second": 24.932,
    "epoch": 1.3784461152882206,
    "step": 5500
  },
  {
    "train_loss": 0.03498440608382225,
    "train_roc_auc_macro": 0.988939298707184,
    "train_runtime": 159.9624,
    "train_samples_per_second": 798.037,
    "train_steps_per_second": 24.943,
    "epoch": 1.3784461152882206,
    "step": 5500
  },
  {
    "loss": 0.036,
    "grad_norm": 0.3067939877510071,
    "learning_rate": 5.396825396825397e-06,
    "epoch": 1.380952380952381,
    "step": 5510
  },
  {
    "loss": 0.0385,
    "grad_norm": 0.6444392800331116,
    "learning_rate": 5.388471177944863e-06,
    "epoch": 1.3834586466165413,
    "step": 5520
  },
  {
    "loss": 0.0333,
    "grad_norm": 0.5253767967224121,
    "learning_rate": 5.380116959064328e-06,
    "epoch": 1.3859649122807016,
    "step": 5530
  },
  {
    "loss": 0.0343,
    "grad_norm": 0.35796043276786804,
    "learning_rate": 5.371762740183793e-06,
    "epoch": 1.3884711779448622,
    "step": 5540
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.3732394874095917,
    "learning_rate": 5.363408521303258e-06,
    "epoch": 1.3909774436090225,
    "step": 5550
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.5622828006744385,
    "learning_rate": 5.355054302422724e-06,
    "epoch": 1.3934837092731829,
    "step": 5560
  },
  {
    "loss": 0.0361,
    "grad_norm": 0.5967395305633545,
    "learning_rate": 5.346700083542189e-06,
    "epoch": 1.3959899749373434,
    "step": 5570
  },
  {
    "loss": 0.03,
    "grad_norm": 0.1709698587656021,
    "learning_rate": 5.338345864661654e-06,
    "epoch": 1.3984962406015038,
    "step": 5580
  },
  {
    "loss": 0.0389,
    "grad_norm": 0.7764810919761658,
    "learning_rate": 5.329991645781119e-06,
    "epoch": 1.4010025062656641,
    "step": 5590
  },
  {
    "loss": 0.0385,
    "grad_norm": 0.5374071598052979,
    "learning_rate": 5.321637426900586e-06,
    "epoch": 1.4035087719298245,
    "step": 5600
  },
  {
    "loss": 0.027,
    "grad_norm": 0.5112891793251038,
    "learning_rate": 5.313283208020051e-06,
    "epoch": 1.4060150375939848,
    "step": 5610
  },
  {
    "loss": 0.0254,
    "grad_norm": 0.1193893626332283,
    "learning_rate": 5.304928989139516e-06,
    "epoch": 1.4085213032581454,
    "step": 5620
  },
  {
    "loss": 0.0474,
    "grad_norm": 0.6816580891609192,
    "learning_rate": 5.296574770258981e-06,
    "epoch": 1.4110275689223057,
    "step": 5630
  },
  {
    "loss": 0.037,
    "grad_norm": 0.3135402798652649,
    "learning_rate": 5.288220551378447e-06,
    "epoch": 1.413533834586466,
    "step": 5640
  },
  {
    "loss": 0.0376,
    "grad_norm": 0.46437913179397583,
    "learning_rate": 5.279866332497912e-06,
    "epoch": 1.4160401002506267,
    "step": 5650
  },
  {
    "loss": 0.0448,
    "grad_norm": 1.0422279834747314,
    "learning_rate": 5.271512113617377e-06,
    "epoch": 1.418546365914787,
    "step": 5660
  },
  {
    "loss": 0.0343,
    "grad_norm": 0.6119031310081482,
    "learning_rate": 5.263157894736842e-06,
    "epoch": 1.4210526315789473,
    "step": 5670
  },
  {
    "loss": 0.0337,
    "grad_norm": 0.433521032333374,
    "learning_rate": 5.254803675856308e-06,
    "epoch": 1.4235588972431077,
    "step": 5680
  },
  {
    "loss": 0.0387,
    "grad_norm": 0.3966446816921234,
    "learning_rate": 5.246449456975773e-06,
    "epoch": 1.426065162907268,
    "step": 5690
  },
  {
    "loss": 0.0367,
    "grad_norm": 0.8921454548835754,
    "learning_rate": 5.2380952380952384e-06,
    "epoch": 1.4285714285714286,
    "step": 5700
  },
  {
    "loss": 0.0429,
    "grad_norm": 0.5772244930267334,
    "learning_rate": 5.229741019214703e-06,
    "epoch": 1.431077694235589,
    "step": 5710
  },
  {
    "loss": 0.0334,
    "grad_norm": 0.4224029779434204,
    "learning_rate": 5.22138680033417e-06,
    "epoch": 1.4335839598997493,
    "step": 5720
  },
  {
    "loss": 0.0438,
    "grad_norm": 0.22093774378299713,
    "learning_rate": 5.213032581453634e-06,
    "epoch": 1.4360902255639099,
    "step": 5730
  },
  {
    "loss": 0.0363,
    "grad_norm": 0.6503860950469971,
    "learning_rate": 5.2046783625731e-06,
    "epoch": 1.4385964912280702,
    "step": 5740
  },
  {
    "loss": 0.0404,
    "grad_norm": 0.5086298584938049,
    "learning_rate": 5.196324143692565e-06,
    "epoch": 1.4411027568922306,
    "step": 5750
  },
  {
    "eval_loss": 0.04037359356880188,
    "eval_roc_auc_macro": 0.9867828456758964,
    "eval_runtime": 40.0598,
    "eval_samples_per_second": 796.685,
    "eval_steps_per_second": 24.913,
    "epoch": 1.4411027568922306,
    "step": 5750
  },
  {
    "train_loss": 0.03524629399180412,
    "train_roc_auc_macro": 0.989371833107248,
    "train_runtime": 159.9485,
    "train_samples_per_second": 798.107,
    "train_steps_per_second": 24.946,
    "epoch": 1.4411027568922306,
    "step": 5750
  },
  {
    "loss": 0.0479,
    "grad_norm": 0.47918087244033813,
    "learning_rate": 5.187969924812031e-06,
    "epoch": 1.443609022556391,
    "step": 5760
  },
  {
    "loss": 0.0406,
    "grad_norm": 0.5079498291015625,
    "learning_rate": 5.179615705931496e-06,
    "epoch": 1.4461152882205512,
    "step": 5770
  },
  {
    "loss": 0.031,
    "grad_norm": 0.43536579608917236,
    "learning_rate": 5.171261487050961e-06,
    "epoch": 1.4486215538847118,
    "step": 5780
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.7256597876548767,
    "learning_rate": 5.162907268170426e-06,
    "epoch": 1.4511278195488722,
    "step": 5790
  },
  {
    "loss": 0.046,
    "grad_norm": 0.1755124032497406,
    "learning_rate": 5.154553049289892e-06,
    "epoch": 1.4536340852130325,
    "step": 5800
  },
  {
    "loss": 0.0351,
    "grad_norm": 0.4723098874092102,
    "learning_rate": 5.146198830409357e-06,
    "epoch": 1.456140350877193,
    "step": 5810
  },
  {
    "loss": 0.0369,
    "grad_norm": 0.20161888003349304,
    "learning_rate": 5.1378446115288225e-06,
    "epoch": 1.4586466165413534,
    "step": 5820
  },
  {
    "loss": 0.0242,
    "grad_norm": 0.26079651713371277,
    "learning_rate": 5.129490392648287e-06,
    "epoch": 1.4611528822055138,
    "step": 5830
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.6445503830909729,
    "learning_rate": 5.121136173767753e-06,
    "epoch": 1.463659147869674,
    "step": 5840
  },
  {
    "loss": 0.0279,
    "grad_norm": 0.5971944332122803,
    "learning_rate": 5.112781954887218e-06,
    "epoch": 1.4661654135338344,
    "step": 5850
  },
  {
    "loss": 0.0236,
    "grad_norm": 0.2735300660133362,
    "learning_rate": 5.104427736006684e-06,
    "epoch": 1.468671679197995,
    "step": 5860
  },
  {
    "loss": 0.0405,
    "grad_norm": 0.6447358727455139,
    "learning_rate": 5.096073517126149e-06,
    "epoch": 1.4711779448621554,
    "step": 5870
  },
  {
    "loss": 0.0334,
    "grad_norm": 0.060509491711854935,
    "learning_rate": 5.087719298245615e-06,
    "epoch": 1.4736842105263157,
    "step": 5880
  },
  {
    "loss": 0.0305,
    "grad_norm": 0.4136050045490265,
    "learning_rate": 5.07936507936508e-06,
    "epoch": 1.4761904761904763,
    "step": 5890
  },
  {
    "loss": 0.0304,
    "grad_norm": 0.23479120433330536,
    "learning_rate": 5.0710108604845454e-06,
    "epoch": 1.4786967418546366,
    "step": 5900
  },
  {
    "loss": 0.0311,
    "grad_norm": 0.30736392736434937,
    "learning_rate": 5.06265664160401e-06,
    "epoch": 1.481203007518797,
    "step": 5910
  },
  {
    "loss": 0.0412,
    "grad_norm": 0.32005053758621216,
    "learning_rate": 5.054302422723476e-06,
    "epoch": 1.4837092731829573,
    "step": 5920
  },
  {
    "loss": 0.0345,
    "grad_norm": 0.3121037781238556,
    "learning_rate": 5.045948203842941e-06,
    "epoch": 1.4862155388471177,
    "step": 5930
  },
  {
    "loss": 0.0294,
    "grad_norm": 0.4713146686553955,
    "learning_rate": 5.0375939849624065e-06,
    "epoch": 1.4887218045112782,
    "step": 5940
  },
  {
    "loss": 0.0313,
    "grad_norm": 0.33784881234169006,
    "learning_rate": 5.029239766081871e-06,
    "epoch": 1.4912280701754386,
    "step": 5950
  },
  {
    "loss": 0.0285,
    "grad_norm": 0.38131412863731384,
    "learning_rate": 5.020885547201337e-06,
    "epoch": 1.493734335839599,
    "step": 5960
  },
  {
    "loss": 0.0381,
    "grad_norm": 0.41345056891441345,
    "learning_rate": 5.012531328320802e-06,
    "epoch": 1.4962406015037595,
    "step": 5970
  },
  {
    "loss": 0.0343,
    "grad_norm": 0.2140233814716339,
    "learning_rate": 5.004177109440268e-06,
    "epoch": 1.4987468671679198,
    "step": 5980
  },
  {
    "loss": 0.0279,
    "grad_norm": 0.4027130603790283,
    "learning_rate": 4.995822890559732e-06,
    "epoch": 1.5012531328320802,
    "step": 5990
  },
  {
    "loss": 0.0364,
    "grad_norm": 0.26868343353271484,
    "learning_rate": 4.987468671679198e-06,
    "epoch": 1.5037593984962405,
    "step": 6000
  },
  {
    "eval_loss": 0.041449446231126785,
    "eval_roc_auc_macro": 0.9864801479305174,
    "eval_runtime": 40.0423,
    "eval_samples_per_second": 797.033,
    "eval_steps_per_second": 24.924,
    "epoch": 1.5037593984962405,
    "step": 6000
  },
  {
    "train_loss": 0.035134848207235336,
    "train_roc_auc_macro": 0.9894390361855611,
    "train_runtime": 160.2575,
    "train_samples_per_second": 796.568,
    "train_steps_per_second": 24.897,
    "epoch": 1.5037593984962405,
    "step": 6000
  },
  {
    "loss": 0.037,
    "grad_norm": 0.8194125294685364,
    "learning_rate": 4.979114452798664e-06,
    "epoch": 1.5062656641604009,
    "step": 6010
  },
  {
    "loss": 0.0342,
    "grad_norm": 0.42055758833885193,
    "learning_rate": 4.970760233918129e-06,
    "epoch": 1.5087719298245614,
    "step": 6020
  },
  {
    "loss": 0.0479,
    "grad_norm": 0.6429078578948975,
    "learning_rate": 4.962406015037594e-06,
    "epoch": 1.5112781954887218,
    "step": 6030
  },
  {
    "loss": 0.0306,
    "grad_norm": 0.76606285572052,
    "learning_rate": 4.954051796157059e-06,
    "epoch": 1.5137844611528823,
    "step": 6040
  },
  {
    "loss": 0.0394,
    "grad_norm": 0.862926721572876,
    "learning_rate": 4.945697577276525e-06,
    "epoch": 1.5162907268170427,
    "step": 6050
  },
  {
    "loss": 0.0344,
    "grad_norm": 0.3074311316013336,
    "learning_rate": 4.93734335839599e-06,
    "epoch": 1.518796992481203,
    "step": 6060
  },
  {
    "loss": 0.0363,
    "grad_norm": 0.5904564261436462,
    "learning_rate": 4.928989139515455e-06,
    "epoch": 1.5213032581453634,
    "step": 6070
  },
  {
    "loss": 0.0269,
    "grad_norm": 0.14649364352226257,
    "learning_rate": 4.920634920634921e-06,
    "epoch": 1.5238095238095237,
    "step": 6080
  },
  {
    "loss": 0.0384,
    "grad_norm": 0.32221677899360657,
    "learning_rate": 4.912280701754386e-06,
    "epoch": 1.526315789473684,
    "step": 6090
  },
  {
    "loss": 0.043,
    "grad_norm": 0.2321767807006836,
    "learning_rate": 4.903926482873852e-06,
    "epoch": 1.5288220551378446,
    "step": 6100
  },
  {
    "loss": 0.0429,
    "grad_norm": 0.19541466236114502,
    "learning_rate": 4.8955722639933164e-06,
    "epoch": 1.531328320802005,
    "step": 6110
  },
  {
    "loss": 0.0408,
    "grad_norm": 0.745727002620697,
    "learning_rate": 4.887218045112782e-06,
    "epoch": 1.5338345864661656,
    "step": 6120
  },
  {
    "loss": 0.0299,
    "grad_norm": 0.27837249636650085,
    "learning_rate": 4.878863826232248e-06,
    "epoch": 1.536340852130326,
    "step": 6130
  },
  {
    "loss": 0.0421,
    "grad_norm": 0.47419822216033936,
    "learning_rate": 4.870509607351713e-06,
    "epoch": 1.5388471177944862,
    "step": 6140
  },
  {
    "loss": 0.0404,
    "grad_norm": 1.2793740034103394,
    "learning_rate": 4.862155388471178e-06,
    "epoch": 1.5413533834586466,
    "step": 6150
  },
  {
    "loss": 0.0481,
    "grad_norm": 1.2893410921096802,
    "learning_rate": 4.853801169590643e-06,
    "epoch": 1.543859649122807,
    "step": 6160
  },
  {
    "loss": 0.0416,
    "grad_norm": 0.6523971557617188,
    "learning_rate": 4.845446950710109e-06,
    "epoch": 1.5463659147869673,
    "step": 6170
  },
  {
    "loss": 0.0306,
    "grad_norm": 0.6217572093009949,
    "learning_rate": 4.837092731829574e-06,
    "epoch": 1.5488721804511278,
    "step": 6180
  },
  {
    "loss": 0.0269,
    "grad_norm": 0.41453155875205994,
    "learning_rate": 4.828738512949039e-06,
    "epoch": 1.5513784461152882,
    "step": 6190
  },
  {
    "loss": 0.0513,
    "grad_norm": 0.32647469639778137,
    "learning_rate": 4.820384294068505e-06,
    "epoch": 1.5538847117794488,
    "step": 6200
  },
  {
    "loss": 0.0377,
    "grad_norm": 0.3760787844657898,
    "learning_rate": 4.81203007518797e-06,
    "epoch": 1.556390977443609,
    "step": 6210
  },
  {
    "loss": 0.0334,
    "grad_norm": 0.48511913418769836,
    "learning_rate": 4.803675856307436e-06,
    "epoch": 1.5588972431077694,
    "step": 6220
  },
  {
    "loss": 0.0321,
    "grad_norm": 0.289206326007843,
    "learning_rate": 4.7953216374269005e-06,
    "epoch": 1.5614035087719298,
    "step": 6230
  },
  {
    "loss": 0.0513,
    "grad_norm": 0.43455469608306885,
    "learning_rate": 4.786967418546366e-06,
    "epoch": 1.5639097744360901,
    "step": 6240
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.16977690160274506,
    "learning_rate": 4.778613199665831e-06,
    "epoch": 1.5664160401002505,
    "step": 6250
  },
  {
    "eval_loss": 0.04298388585448265,
    "eval_roc_auc_macro": 0.986174467148308,
    "eval_runtime": 40.069,
    "eval_samples_per_second": 796.5,
    "eval_steps_per_second": 24.907,
    "epoch": 1.5664160401002505,
    "step": 6250
  },
  {
    "train_loss": 0.036655884236097336,
    "train_roc_auc_macro": 0.9894364552562912,
    "train_runtime": 160.0804,
    "train_samples_per_second": 797.449,
    "train_steps_per_second": 24.925,
    "epoch": 1.5664160401002505,
    "step": 6250
  },
  {
    "loss": 0.0291,
    "grad_norm": 0.34160116314888,
    "learning_rate": 4.770258980785297e-06,
    "epoch": 1.568922305764411,
    "step": 6260
  },
  {
    "loss": 0.0276,
    "grad_norm": 0.8523963093757629,
    "learning_rate": 4.761904761904762e-06,
    "epoch": 1.5714285714285714,
    "step": 6270
  },
  {
    "loss": 0.0589,
    "grad_norm": 0.5708876848220825,
    "learning_rate": 4.753550543024227e-06,
    "epoch": 1.573934837092732,
    "step": 6280
  },
  {
    "loss": 0.0401,
    "grad_norm": 0.27775734663009644,
    "learning_rate": 4.745196324143693e-06,
    "epoch": 1.5764411027568923,
    "step": 6290
  },
  {
    "loss": 0.0244,
    "grad_norm": 0.6827231645584106,
    "learning_rate": 4.736842105263158e-06,
    "epoch": 1.5789473684210527,
    "step": 6300
  },
  {
    "loss": 0.0414,
    "grad_norm": 0.5600234866142273,
    "learning_rate": 4.7284878863826234e-06,
    "epoch": 1.581453634085213,
    "step": 6310
  },
  {
    "loss": 0.0453,
    "grad_norm": 0.6963033676147461,
    "learning_rate": 4.720133667502088e-06,
    "epoch": 1.5839598997493733,
    "step": 6320
  },
  {
    "loss": 0.033,
    "grad_norm": 0.4955906271934509,
    "learning_rate": 4.711779448621554e-06,
    "epoch": 1.5864661654135337,
    "step": 6330
  },
  {
    "loss": 0.0398,
    "grad_norm": 0.1835090070962906,
    "learning_rate": 4.70342522974102e-06,
    "epoch": 1.5889724310776943,
    "step": 6340
  },
  {
    "loss": 0.0462,
    "grad_norm": 0.5786104202270508,
    "learning_rate": 4.6950710108604845e-06,
    "epoch": 1.5914786967418546,
    "step": 6350
  },
  {
    "loss": 0.0443,
    "grad_norm": 0.3000316321849823,
    "learning_rate": 4.68671679197995e-06,
    "epoch": 1.5939849624060152,
    "step": 6360
  },
  {
    "loss": 0.0339,
    "grad_norm": 0.2065388411283493,
    "learning_rate": 4.678362573099415e-06,
    "epoch": 1.5964912280701755,
    "step": 6370
  },
  {
    "loss": 0.0292,
    "grad_norm": 0.6421399116516113,
    "learning_rate": 4.670008354218881e-06,
    "epoch": 1.5989974937343359,
    "step": 6380
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.477430522441864,
    "learning_rate": 4.661654135338346e-06,
    "epoch": 1.6015037593984962,
    "step": 6390
  },
  {
    "loss": 0.0337,
    "grad_norm": 0.4962281882762909,
    "learning_rate": 4.653299916457811e-06,
    "epoch": 1.6040100250626566,
    "step": 6400
  },
  {
    "loss": 0.0295,
    "grad_norm": 0.5672966241836548,
    "learning_rate": 4.644945697577277e-06,
    "epoch": 1.606516290726817,
    "step": 6410
  },
  {
    "loss": 0.0286,
    "grad_norm": 0.381777286529541,
    "learning_rate": 4.636591478696742e-06,
    "epoch": 1.6090225563909775,
    "step": 6420
  },
  {
    "loss": 0.0492,
    "grad_norm": 0.6543538570404053,
    "learning_rate": 4.6282372598162075e-06,
    "epoch": 1.6115288220551378,
    "step": 6430
  },
  {
    "loss": 0.0416,
    "grad_norm": 0.4553641378879547,
    "learning_rate": 4.619883040935672e-06,
    "epoch": 1.6140350877192984,
    "step": 6440
  },
  {
    "loss": 0.0279,
    "grad_norm": 0.5127755999565125,
    "learning_rate": 4.611528822055138e-06,
    "epoch": 1.6165413533834587,
    "step": 6450
  },
  {
    "loss": 0.0242,
    "grad_norm": 0.7175858020782471,
    "learning_rate": 4.603174603174604e-06,
    "epoch": 1.619047619047619,
    "step": 6460
  },
  {
    "loss": 0.0417,
    "grad_norm": 0.6695749163627625,
    "learning_rate": 4.5948203842940685e-06,
    "epoch": 1.6215538847117794,
    "step": 6470
  },
  {
    "loss": 0.0465,
    "grad_norm": 0.39170676469802856,
    "learning_rate": 4.586466165413534e-06,
    "epoch": 1.6240601503759398,
    "step": 6480
  },
  {
    "loss": 0.0359,
    "grad_norm": 0.3691265881061554,
    "learning_rate": 4.578111946532999e-06,
    "epoch": 1.6265664160401,
    "step": 6490
  },
  {
    "loss": 0.039,
    "grad_norm": 0.30917805433273315,
    "learning_rate": 4.569757727652465e-06,
    "epoch": 1.6290726817042607,
    "step": 6500
  },
  {
    "eval_loss": 0.04049357399344444,
    "eval_roc_auc_macro": 0.9865520966163599,
    "eval_runtime": 40.0307,
    "eval_samples_per_second": 797.263,
    "eval_steps_per_second": 24.931,
    "epoch": 1.6290726817042607,
    "step": 6500
  },
  {
    "train_loss": 0.034559398889541626,
    "train_roc_auc_macro": 0.9898042559806527,
    "train_runtime": 160.0272,
    "train_samples_per_second": 797.715,
    "train_steps_per_second": 24.933,
    "epoch": 1.6290726817042607,
    "step": 6500
  },
  {
    "loss": 0.0314,
    "grad_norm": 0.6012861132621765,
    "learning_rate": 4.56140350877193e-06,
    "epoch": 1.631578947368421,
    "step": 6510
  },
  {
    "loss": 0.0403,
    "grad_norm": 0.5487945675849915,
    "learning_rate": 4.553049289891395e-06,
    "epoch": 1.6340852130325816,
    "step": 6520
  },
  {
    "loss": 0.0451,
    "grad_norm": 0.48721322417259216,
    "learning_rate": 4.544695071010861e-06,
    "epoch": 1.636591478696742,
    "step": 6530
  },
  {
    "loss": 0.0387,
    "grad_norm": 0.11829924583435059,
    "learning_rate": 4.536340852130326e-06,
    "epoch": 1.6390977443609023,
    "step": 6540
  },
  {
    "loss": 0.0293,
    "grad_norm": 0.28611990809440613,
    "learning_rate": 4.5279866332497915e-06,
    "epoch": 1.6416040100250626,
    "step": 6550
  },
  {
    "loss": 0.0342,
    "grad_norm": 0.6713125109672546,
    "learning_rate": 4.519632414369256e-06,
    "epoch": 1.644110275689223,
    "step": 6560
  },
  {
    "loss": 0.0483,
    "grad_norm": 0.2381177395582199,
    "learning_rate": 4.511278195488722e-06,
    "epoch": 1.6466165413533833,
    "step": 6570
  },
  {
    "loss": 0.0375,
    "grad_norm": 0.5260119438171387,
    "learning_rate": 4.502923976608187e-06,
    "epoch": 1.6491228070175439,
    "step": 6580
  },
  {
    "loss": 0.0247,
    "grad_norm": 0.33172276616096497,
    "learning_rate": 4.4945697577276526e-06,
    "epoch": 1.6516290726817042,
    "step": 6590
  },
  {
    "loss": 0.034,
    "grad_norm": 0.22462892532348633,
    "learning_rate": 4.486215538847118e-06,
    "epoch": 1.6541353383458648,
    "step": 6600
  },
  {
    "loss": 0.0444,
    "grad_norm": 0.27533912658691406,
    "learning_rate": 4.477861319966583e-06,
    "epoch": 1.6566416040100251,
    "step": 6610
  },
  {
    "loss": 0.0324,
    "grad_norm": 0.6540682315826416,
    "learning_rate": 4.469507101086049e-06,
    "epoch": 1.6591478696741855,
    "step": 6620
  },
  {
    "loss": 0.0448,
    "grad_norm": 0.4551929831504822,
    "learning_rate": 4.461152882205514e-06,
    "epoch": 1.6616541353383458,
    "step": 6630
  },
  {
    "loss": 0.0316,
    "grad_norm": 0.40741392970085144,
    "learning_rate": 4.452798663324979e-06,
    "epoch": 1.6641604010025062,
    "step": 6640
  },
  {
    "loss": 0.0186,
    "grad_norm": 0.17324747145175934,
    "learning_rate": 4.444444444444444e-06,
    "epoch": 1.6666666666666665,
    "step": 6650
  },
  {
    "loss": 0.0438,
    "grad_norm": 0.5527657270431519,
    "learning_rate": 4.43609022556391e-06,
    "epoch": 1.669172932330827,
    "step": 6660
  },
  {
    "loss": 0.0426,
    "grad_norm": 0.5970724821090698,
    "learning_rate": 4.4277360066833755e-06,
    "epoch": 1.6716791979949874,
    "step": 6670
  },
  {
    "loss": 0.0301,
    "grad_norm": 0.32665160298347473,
    "learning_rate": 4.41938178780284e-06,
    "epoch": 1.674185463659148,
    "step": 6680
  },
  {
    "loss": 0.0413,
    "grad_norm": 0.37805095314979553,
    "learning_rate": 4.411027568922306e-06,
    "epoch": 1.6766917293233083,
    "step": 6690
  },
  {
    "loss": 0.0243,
    "grad_norm": 0.5349996089935303,
    "learning_rate": 4.402673350041771e-06,
    "epoch": 1.6791979949874687,
    "step": 6700
  },
  {
    "loss": 0.0294,
    "grad_norm": 0.5246626734733582,
    "learning_rate": 4.394319131161237e-06,
    "epoch": 1.681704260651629,
    "step": 6710
  },
  {
    "loss": 0.047,
    "grad_norm": 0.3228677213191986,
    "learning_rate": 4.385964912280702e-06,
    "epoch": 1.6842105263157894,
    "step": 6720
  },
  {
    "loss": 0.0284,
    "grad_norm": 0.3660467267036438,
    "learning_rate": 4.377610693400167e-06,
    "epoch": 1.6867167919799497,
    "step": 6730
  },
  {
    "loss": 0.032,
    "grad_norm": 0.46420150995254517,
    "learning_rate": 4.369256474519633e-06,
    "epoch": 1.6892230576441103,
    "step": 6740
  },
  {
    "loss": 0.0397,
    "grad_norm": 0.46147868037223816,
    "learning_rate": 4.360902255639098e-06,
    "epoch": 1.6917293233082706,
    "step": 6750
  },
  {
    "eval_loss": 0.04230367764830589,
    "eval_roc_auc_macro": 0.9861619247662032,
    "eval_runtime": 40.1038,
    "eval_samples_per_second": 795.811,
    "eval_steps_per_second": 24.885,
    "epoch": 1.6917293233082706,
    "step": 6750
  },
  {
    "train_loss": 0.03596251830458641,
    "train_roc_auc_macro": 0.9895204618195038,
    "train_runtime": 159.9106,
    "train_samples_per_second": 798.296,
    "train_steps_per_second": 24.951,
    "epoch": 1.6917293233082706,
    "step": 6750
  },
  {
    "train_runtime": 6427.9911,
    "train_samples_per_second": 59.578,
    "train_steps_per_second": 1.862,
    "total_flos": 2.841436662711091e+16,
    "train_loss": 0.04696749197995221,
    "epoch": 1.6917293233082706,
    "step": 6750
  }
]