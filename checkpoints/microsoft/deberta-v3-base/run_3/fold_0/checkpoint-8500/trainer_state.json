{
  "best_metric": 0.988334434064107,
  "best_model_checkpoint": "/home/azureuser/ruben/toxicity_classificator_internal/checkpoints/microsoft/deberta-v3-base/run_3/fold_0/checkpoint-8500",
  "epoch": 2.1303258145363406,
  "eval_steps": 250,
  "global_step": 8500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002506265664160401,
      "grad_norm": 1.4408477544784546,
      "learning_rate": 9.991645781119465e-06,
      "loss": 0.6765,
      "step": 10
    },
    {
      "epoch": 0.005012531328320802,
      "grad_norm": 1.6730225086212158,
      "learning_rate": 9.983291562238932e-06,
      "loss": 0.6209,
      "step": 20
    },
    {
      "epoch": 0.007518796992481203,
      "grad_norm": 1.7877625226974487,
      "learning_rate": 9.974937343358396e-06,
      "loss": 0.5311,
      "step": 30
    },
    {
      "epoch": 0.010025062656641603,
      "grad_norm": 2.1101157665252686,
      "learning_rate": 9.966583124477862e-06,
      "loss": 0.4128,
      "step": 40
    },
    {
      "epoch": 0.012531328320802004,
      "grad_norm": 1.5441410541534424,
      "learning_rate": 9.958228905597328e-06,
      "loss": 0.3119,
      "step": 50
    },
    {
      "epoch": 0.015037593984962405,
      "grad_norm": 1.5221312046051025,
      "learning_rate": 9.949874686716793e-06,
      "loss": 0.2547,
      "step": 60
    },
    {
      "epoch": 0.017543859649122806,
      "grad_norm": 0.9331484436988831,
      "learning_rate": 9.941520467836257e-06,
      "loss": 0.2112,
      "step": 70
    },
    {
      "epoch": 0.020050125313283207,
      "grad_norm": 1.1612122058868408,
      "learning_rate": 9.933166248955723e-06,
      "loss": 0.1666,
      "step": 80
    },
    {
      "epoch": 0.022556390977443608,
      "grad_norm": 0.8236584067344666,
      "learning_rate": 9.924812030075189e-06,
      "loss": 0.1391,
      "step": 90
    },
    {
      "epoch": 0.02506265664160401,
      "grad_norm": 0.8422651886940002,
      "learning_rate": 9.916457811194654e-06,
      "loss": 0.1306,
      "step": 100
    },
    {
      "epoch": 0.02756892230576441,
      "grad_norm": 1.1541403532028198,
      "learning_rate": 9.908103592314118e-06,
      "loss": 0.154,
      "step": 110
    },
    {
      "epoch": 0.03007518796992481,
      "grad_norm": 0.6919097900390625,
      "learning_rate": 9.899749373433584e-06,
      "loss": 0.1082,
      "step": 120
    },
    {
      "epoch": 0.03258145363408521,
      "grad_norm": 0.7719461917877197,
      "learning_rate": 9.89139515455305e-06,
      "loss": 0.0949,
      "step": 130
    },
    {
      "epoch": 0.03508771929824561,
      "grad_norm": 0.7547005414962769,
      "learning_rate": 9.883040935672515e-06,
      "loss": 0.0973,
      "step": 140
    },
    {
      "epoch": 0.03759398496240601,
      "grad_norm": 1.2274123430252075,
      "learning_rate": 9.87468671679198e-06,
      "loss": 0.128,
      "step": 150
    },
    {
      "epoch": 0.040100250626566414,
      "grad_norm": 0.6684793829917908,
      "learning_rate": 9.866332497911447e-06,
      "loss": 0.0851,
      "step": 160
    },
    {
      "epoch": 0.042606516290726815,
      "grad_norm": 0.5955708622932434,
      "learning_rate": 9.85797827903091e-06,
      "loss": 0.0872,
      "step": 170
    },
    {
      "epoch": 0.045112781954887216,
      "grad_norm": 0.4783340096473694,
      "learning_rate": 9.849624060150376e-06,
      "loss": 0.0913,
      "step": 180
    },
    {
      "epoch": 0.047619047619047616,
      "grad_norm": 0.4344499111175537,
      "learning_rate": 9.841269841269842e-06,
      "loss": 0.0746,
      "step": 190
    },
    {
      "epoch": 0.05012531328320802,
      "grad_norm": 0.6639338135719299,
      "learning_rate": 9.832915622389308e-06,
      "loss": 0.0784,
      "step": 200
    },
    {
      "epoch": 0.05263157894736842,
      "grad_norm": 0.6906208992004395,
      "learning_rate": 9.824561403508772e-06,
      "loss": 0.0857,
      "step": 210
    },
    {
      "epoch": 0.05513784461152882,
      "grad_norm": 0.350981205701828,
      "learning_rate": 9.816207184628238e-06,
      "loss": 0.0565,
      "step": 220
    },
    {
      "epoch": 0.05764411027568922,
      "grad_norm": 0.42513224482536316,
      "learning_rate": 9.807852965747703e-06,
      "loss": 0.0568,
      "step": 230
    },
    {
      "epoch": 0.06015037593984962,
      "grad_norm": 1.3628160953521729,
      "learning_rate": 9.799498746867169e-06,
      "loss": 0.0574,
      "step": 240
    },
    {
      "epoch": 0.06265664160401002,
      "grad_norm": 1.024634599685669,
      "learning_rate": 9.791144527986633e-06,
      "loss": 0.0732,
      "step": 250
    },
    {
      "epoch": 0.06265664160401002,
      "eval_loss": 0.05983755737543106,
      "eval_roc_auc_macro": 0.9400867406841655,
      "eval_runtime": 40.019,
      "eval_samples_per_second": 797.496,
      "eval_steps_per_second": 24.938,
      "step": 250
    },
    {
      "epoch": 0.06265664160401002,
      "step": 250,
      "train_loss": 0.06019674986600876,
      "train_roc_auc_macro": 0.9423451937434396,
      "train_runtime": 160.358,
      "train_samples_per_second": 796.069,
      "train_steps_per_second": 24.882
    },
    {
      "epoch": 0.06516290726817042,
      "grad_norm": 0.22991779446601868,
      "learning_rate": 9.782790309106099e-06,
      "loss": 0.0505,
      "step": 260
    },
    {
      "epoch": 0.06766917293233082,
      "grad_norm": 0.475492000579834,
      "learning_rate": 9.774436090225564e-06,
      "loss": 0.058,
      "step": 270
    },
    {
      "epoch": 0.07017543859649122,
      "grad_norm": 0.21481375396251678,
      "learning_rate": 9.76608187134503e-06,
      "loss": 0.0605,
      "step": 280
    },
    {
      "epoch": 0.07268170426065163,
      "grad_norm": 0.5271284580230713,
      "learning_rate": 9.757727652464496e-06,
      "loss": 0.0724,
      "step": 290
    },
    {
      "epoch": 0.07518796992481203,
      "grad_norm": 0.40126702189445496,
      "learning_rate": 9.749373433583961e-06,
      "loss": 0.0625,
      "step": 300
    },
    {
      "epoch": 0.07769423558897243,
      "grad_norm": 0.8164220452308655,
      "learning_rate": 9.741019214703425e-06,
      "loss": 0.0669,
      "step": 310
    },
    {
      "epoch": 0.08020050125313283,
      "grad_norm": 0.18396039307117462,
      "learning_rate": 9.732664995822891e-06,
      "loss": 0.0538,
      "step": 320
    },
    {
      "epoch": 0.08270676691729323,
      "grad_norm": 0.28133052587509155,
      "learning_rate": 9.724310776942357e-06,
      "loss": 0.041,
      "step": 330
    },
    {
      "epoch": 0.08521303258145363,
      "grad_norm": 0.5192440748214722,
      "learning_rate": 9.715956558061822e-06,
      "loss": 0.0573,
      "step": 340
    },
    {
      "epoch": 0.08771929824561403,
      "grad_norm": 0.2954210638999939,
      "learning_rate": 9.707602339181286e-06,
      "loss": 0.0574,
      "step": 350
    },
    {
      "epoch": 0.09022556390977443,
      "grad_norm": 0.7618799805641174,
      "learning_rate": 9.699248120300752e-06,
      "loss": 0.0539,
      "step": 360
    },
    {
      "epoch": 0.09273182957393483,
      "grad_norm": 1.063485026359558,
      "learning_rate": 9.690893901420218e-06,
      "loss": 0.0601,
      "step": 370
    },
    {
      "epoch": 0.09523809523809523,
      "grad_norm": 0.3019580543041229,
      "learning_rate": 9.682539682539683e-06,
      "loss": 0.0507,
      "step": 380
    },
    {
      "epoch": 0.09774436090225563,
      "grad_norm": 1.099424123764038,
      "learning_rate": 9.674185463659147e-06,
      "loss": 0.0712,
      "step": 390
    },
    {
      "epoch": 0.10025062656641603,
      "grad_norm": 0.417179137468338,
      "learning_rate": 9.665831244778615e-06,
      "loss": 0.0513,
      "step": 400
    },
    {
      "epoch": 0.10275689223057644,
      "grad_norm": 0.4834933280944824,
      "learning_rate": 9.657477025898079e-06,
      "loss": 0.06,
      "step": 410
    },
    {
      "epoch": 0.10526315789473684,
      "grad_norm": 0.4411593973636627,
      "learning_rate": 9.649122807017545e-06,
      "loss": 0.0447,
      "step": 420
    },
    {
      "epoch": 0.10776942355889724,
      "grad_norm": 0.7319832444190979,
      "learning_rate": 9.64076858813701e-06,
      "loss": 0.0572,
      "step": 430
    },
    {
      "epoch": 0.11027568922305764,
      "grad_norm": 0.41691118478775024,
      "learning_rate": 9.632414369256476e-06,
      "loss": 0.0712,
      "step": 440
    },
    {
      "epoch": 0.11278195488721804,
      "grad_norm": 0.26865169405937195,
      "learning_rate": 9.62406015037594e-06,
      "loss": 0.0466,
      "step": 450
    },
    {
      "epoch": 0.11528822055137844,
      "grad_norm": 0.7867982983589172,
      "learning_rate": 9.615705931495406e-06,
      "loss": 0.0479,
      "step": 460
    },
    {
      "epoch": 0.11779448621553884,
      "grad_norm": 1.3521400690078735,
      "learning_rate": 9.607351712614871e-06,
      "loss": 0.0687,
      "step": 470
    },
    {
      "epoch": 0.12030075187969924,
      "grad_norm": 0.46725034713745117,
      "learning_rate": 9.598997493734337e-06,
      "loss": 0.0539,
      "step": 480
    },
    {
      "epoch": 0.12280701754385964,
      "grad_norm": 1.194468379020691,
      "learning_rate": 9.590643274853801e-06,
      "loss": 0.0567,
      "step": 490
    },
    {
      "epoch": 0.12531328320802004,
      "grad_norm": 1.2412118911743164,
      "learning_rate": 9.582289055973267e-06,
      "loss": 0.0652,
      "step": 500
    },
    {
      "epoch": 0.12531328320802004,
      "eval_loss": 0.05480056256055832,
      "eval_roc_auc_macro": 0.9504454553319284,
      "eval_runtime": 40.188,
      "eval_samples_per_second": 794.144,
      "eval_steps_per_second": 24.833,
      "step": 500
    },
    {
      "epoch": 0.12531328320802004,
      "step": 500,
      "train_loss": 0.05483245849609375,
      "train_roc_auc_macro": 0.9502595091394294,
      "train_runtime": 159.8601,
      "train_samples_per_second": 798.548,
      "train_steps_per_second": 24.959
    },
    {
      "epoch": 0.12781954887218044,
      "grad_norm": 0.6684610247612,
      "learning_rate": 9.573934837092732e-06,
      "loss": 0.0502,
      "step": 510
    },
    {
      "epoch": 0.13032581453634084,
      "grad_norm": 1.291597604751587,
      "learning_rate": 9.565580618212198e-06,
      "loss": 0.0448,
      "step": 520
    },
    {
      "epoch": 0.13283208020050125,
      "grad_norm": 0.7662550806999207,
      "learning_rate": 9.557226399331662e-06,
      "loss": 0.0591,
      "step": 530
    },
    {
      "epoch": 0.13533834586466165,
      "grad_norm": 0.36886876821517944,
      "learning_rate": 9.54887218045113e-06,
      "loss": 0.0407,
      "step": 540
    },
    {
      "epoch": 0.13784461152882205,
      "grad_norm": 0.682466983795166,
      "learning_rate": 9.540517961570593e-06,
      "loss": 0.0545,
      "step": 550
    },
    {
      "epoch": 0.14035087719298245,
      "grad_norm": 0.7388448715209961,
      "learning_rate": 9.532163742690059e-06,
      "loss": 0.0615,
      "step": 560
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.3511280417442322,
      "learning_rate": 9.523809523809525e-06,
      "loss": 0.0494,
      "step": 570
    },
    {
      "epoch": 0.14536340852130325,
      "grad_norm": 0.8246035575866699,
      "learning_rate": 9.51545530492899e-06,
      "loss": 0.0656,
      "step": 580
    },
    {
      "epoch": 0.14786967418546365,
      "grad_norm": 0.9270527958869934,
      "learning_rate": 9.507101086048454e-06,
      "loss": 0.0504,
      "step": 590
    },
    {
      "epoch": 0.15037593984962405,
      "grad_norm": 0.46469786763191223,
      "learning_rate": 9.49874686716792e-06,
      "loss": 0.0392,
      "step": 600
    },
    {
      "epoch": 0.15288220551378445,
      "grad_norm": 0.4902782440185547,
      "learning_rate": 9.490392648287386e-06,
      "loss": 0.0466,
      "step": 610
    },
    {
      "epoch": 0.15538847117794485,
      "grad_norm": 0.42051973938941956,
      "learning_rate": 9.482038429406851e-06,
      "loss": 0.0487,
      "step": 620
    },
    {
      "epoch": 0.15789473684210525,
      "grad_norm": 0.28798818588256836,
      "learning_rate": 9.473684210526315e-06,
      "loss": 0.0415,
      "step": 630
    },
    {
      "epoch": 0.16040100250626566,
      "grad_norm": 1.017924189567566,
      "learning_rate": 9.465329991645781e-06,
      "loss": 0.0468,
      "step": 640
    },
    {
      "epoch": 0.16290726817042606,
      "grad_norm": 0.7977983951568604,
      "learning_rate": 9.456975772765247e-06,
      "loss": 0.0428,
      "step": 650
    },
    {
      "epoch": 0.16541353383458646,
      "grad_norm": 0.34931766986846924,
      "learning_rate": 9.448621553884713e-06,
      "loss": 0.0512,
      "step": 660
    },
    {
      "epoch": 0.16791979949874686,
      "grad_norm": 0.726164698600769,
      "learning_rate": 9.440267335004177e-06,
      "loss": 0.0714,
      "step": 670
    },
    {
      "epoch": 0.17042606516290726,
      "grad_norm": 0.44096025824546814,
      "learning_rate": 9.431913116123644e-06,
      "loss": 0.0698,
      "step": 680
    },
    {
      "epoch": 0.17293233082706766,
      "grad_norm": 0.4475220739841461,
      "learning_rate": 9.423558897243108e-06,
      "loss": 0.0426,
      "step": 690
    },
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 0.4990343749523163,
      "learning_rate": 9.415204678362574e-06,
      "loss": 0.0545,
      "step": 700
    },
    {
      "epoch": 0.17794486215538846,
      "grad_norm": 0.6149981617927551,
      "learning_rate": 9.40685045948204e-06,
      "loss": 0.0505,
      "step": 710
    },
    {
      "epoch": 0.18045112781954886,
      "grad_norm": 0.756777822971344,
      "learning_rate": 9.398496240601505e-06,
      "loss": 0.0459,
      "step": 720
    },
    {
      "epoch": 0.18295739348370926,
      "grad_norm": 0.4779841899871826,
      "learning_rate": 9.390142021720969e-06,
      "loss": 0.0481,
      "step": 730
    },
    {
      "epoch": 0.18546365914786966,
      "grad_norm": 0.4704706072807312,
      "learning_rate": 9.381787802840435e-06,
      "loss": 0.0431,
      "step": 740
    },
    {
      "epoch": 0.18796992481203006,
      "grad_norm": 1.072485089302063,
      "learning_rate": 9.3734335839599e-06,
      "loss": 0.0489,
      "step": 750
    },
    {
      "epoch": 0.18796992481203006,
      "eval_loss": 0.0482805110514164,
      "eval_roc_auc_macro": 0.9761191071239401,
      "eval_runtime": 40.141,
      "eval_samples_per_second": 795.072,
      "eval_steps_per_second": 24.862,
      "step": 750
    },
    {
      "epoch": 0.18796992481203006,
      "step": 750,
      "train_loss": 0.04795032739639282,
      "train_roc_auc_macro": 0.9767375199960444,
      "train_runtime": 160.1844,
      "train_samples_per_second": 796.931,
      "train_steps_per_second": 24.909
    },
    {
      "epoch": 0.19047619047619047,
      "grad_norm": 0.4279235005378723,
      "learning_rate": 9.365079365079366e-06,
      "loss": 0.044,
      "step": 760
    },
    {
      "epoch": 0.19298245614035087,
      "grad_norm": 0.3175554573535919,
      "learning_rate": 9.35672514619883e-06,
      "loss": 0.0616,
      "step": 770
    },
    {
      "epoch": 0.19548872180451127,
      "grad_norm": 0.4382724463939667,
      "learning_rate": 9.348370927318296e-06,
      "loss": 0.0527,
      "step": 780
    },
    {
      "epoch": 0.19799498746867167,
      "grad_norm": 0.9067234396934509,
      "learning_rate": 9.340016708437761e-06,
      "loss": 0.0531,
      "step": 790
    },
    {
      "epoch": 0.20050125313283207,
      "grad_norm": 0.4953837990760803,
      "learning_rate": 9.331662489557227e-06,
      "loss": 0.0475,
      "step": 800
    },
    {
      "epoch": 0.20300751879699247,
      "grad_norm": 0.31862232089042664,
      "learning_rate": 9.323308270676693e-06,
      "loss": 0.0382,
      "step": 810
    },
    {
      "epoch": 0.20551378446115287,
      "grad_norm": 0.5429617762565613,
      "learning_rate": 9.314954051796158e-06,
      "loss": 0.0443,
      "step": 820
    },
    {
      "epoch": 0.20802005012531327,
      "grad_norm": 0.39321091771125793,
      "learning_rate": 9.306599832915622e-06,
      "loss": 0.0443,
      "step": 830
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 0.9917818307876587,
      "learning_rate": 9.298245614035088e-06,
      "loss": 0.0661,
      "step": 840
    },
    {
      "epoch": 0.21303258145363407,
      "grad_norm": 0.42479372024536133,
      "learning_rate": 9.289891395154554e-06,
      "loss": 0.0519,
      "step": 850
    },
    {
      "epoch": 0.21553884711779447,
      "grad_norm": 0.5923789739608765,
      "learning_rate": 9.28153717627402e-06,
      "loss": 0.0547,
      "step": 860
    },
    {
      "epoch": 0.21804511278195488,
      "grad_norm": 0.3640490770339966,
      "learning_rate": 9.273182957393484e-06,
      "loss": 0.0427,
      "step": 870
    },
    {
      "epoch": 0.22055137844611528,
      "grad_norm": 0.5948413610458374,
      "learning_rate": 9.26482873851295e-06,
      "loss": 0.0331,
      "step": 880
    },
    {
      "epoch": 0.22305764411027568,
      "grad_norm": 0.3513549268245697,
      "learning_rate": 9.256474519632415e-06,
      "loss": 0.0551,
      "step": 890
    },
    {
      "epoch": 0.22556390977443608,
      "grad_norm": 0.25647038221359253,
      "learning_rate": 9.24812030075188e-06,
      "loss": 0.0554,
      "step": 900
    },
    {
      "epoch": 0.22807017543859648,
      "grad_norm": 0.5384249687194824,
      "learning_rate": 9.239766081871345e-06,
      "loss": 0.0452,
      "step": 910
    },
    {
      "epoch": 0.23057644110275688,
      "grad_norm": 0.2580678462982178,
      "learning_rate": 9.231411862990812e-06,
      "loss": 0.05,
      "step": 920
    },
    {
      "epoch": 0.23308270676691728,
      "grad_norm": 0.4967542588710785,
      "learning_rate": 9.223057644110276e-06,
      "loss": 0.0527,
      "step": 930
    },
    {
      "epoch": 0.23558897243107768,
      "grad_norm": 0.16077525913715363,
      "learning_rate": 9.214703425229742e-06,
      "loss": 0.0377,
      "step": 940
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 0.6475339531898499,
      "learning_rate": 9.206349206349207e-06,
      "loss": 0.0416,
      "step": 950
    },
    {
      "epoch": 0.24060150375939848,
      "grad_norm": 0.5804770588874817,
      "learning_rate": 9.197994987468673e-06,
      "loss": 0.056,
      "step": 960
    },
    {
      "epoch": 0.24310776942355888,
      "grad_norm": 0.5444996356964111,
      "learning_rate": 9.189640768588137e-06,
      "loss": 0.047,
      "step": 970
    },
    {
      "epoch": 0.24561403508771928,
      "grad_norm": 0.6083528995513916,
      "learning_rate": 9.181286549707603e-06,
      "loss": 0.0416,
      "step": 980
    },
    {
      "epoch": 0.24812030075187969,
      "grad_norm": 0.5601528882980347,
      "learning_rate": 9.172932330827068e-06,
      "loss": 0.0635,
      "step": 990
    },
    {
      "epoch": 0.2506265664160401,
      "grad_norm": 1.0909243822097778,
      "learning_rate": 9.164578111946534e-06,
      "loss": 0.0489,
      "step": 1000
    },
    {
      "epoch": 0.2506265664160401,
      "eval_loss": 0.046178948134183884,
      "eval_roc_auc_macro": 0.9776625068676631,
      "eval_runtime": 40.164,
      "eval_samples_per_second": 794.618,
      "eval_steps_per_second": 24.848,
      "step": 1000
    },
    {
      "epoch": 0.2506265664160401,
      "step": 1000,
      "train_loss": 0.04599626734852791,
      "train_roc_auc_macro": 0.9784912599489609,
      "train_runtime": 160.0599,
      "train_samples_per_second": 797.551,
      "train_steps_per_second": 24.928
    },
    {
      "epoch": 0.2531328320802005,
      "grad_norm": 0.46866801381111145,
      "learning_rate": 9.156223893065998e-06,
      "loss": 0.059,
      "step": 1010
    },
    {
      "epoch": 0.2556390977443609,
      "grad_norm": 0.7971266508102417,
      "learning_rate": 9.147869674185464e-06,
      "loss": 0.0484,
      "step": 1020
    },
    {
      "epoch": 0.2581453634085213,
      "grad_norm": 0.06490778177976608,
      "learning_rate": 9.13951545530493e-06,
      "loss": 0.0299,
      "step": 1030
    },
    {
      "epoch": 0.2606516290726817,
      "grad_norm": 0.6884651184082031,
      "learning_rate": 9.131161236424395e-06,
      "loss": 0.0696,
      "step": 1040
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 1.1250797510147095,
      "learning_rate": 9.12280701754386e-06,
      "loss": 0.0535,
      "step": 1050
    },
    {
      "epoch": 0.2656641604010025,
      "grad_norm": 0.8167755007743835,
      "learning_rate": 9.114452798663327e-06,
      "loss": 0.0612,
      "step": 1060
    },
    {
      "epoch": 0.2681704260651629,
      "grad_norm": 0.40547409653663635,
      "learning_rate": 9.10609857978279e-06,
      "loss": 0.0514,
      "step": 1070
    },
    {
      "epoch": 0.2706766917293233,
      "grad_norm": 0.26287347078323364,
      "learning_rate": 9.097744360902256e-06,
      "loss": 0.0372,
      "step": 1080
    },
    {
      "epoch": 0.2731829573934837,
      "grad_norm": 0.6525184512138367,
      "learning_rate": 9.089390142021722e-06,
      "loss": 0.0532,
      "step": 1090
    },
    {
      "epoch": 0.2756892230576441,
      "grad_norm": 0.26179075241088867,
      "learning_rate": 9.081035923141188e-06,
      "loss": 0.053,
      "step": 1100
    },
    {
      "epoch": 0.2781954887218045,
      "grad_norm": 0.7149436473846436,
      "learning_rate": 9.072681704260652e-06,
      "loss": 0.0358,
      "step": 1110
    },
    {
      "epoch": 0.2807017543859649,
      "grad_norm": 0.4274386167526245,
      "learning_rate": 9.064327485380117e-06,
      "loss": 0.0466,
      "step": 1120
    },
    {
      "epoch": 0.2832080200501253,
      "grad_norm": 0.8530676960945129,
      "learning_rate": 9.055973266499583e-06,
      "loss": 0.036,
      "step": 1130
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.40656402707099915,
      "learning_rate": 9.047619047619049e-06,
      "loss": 0.0415,
      "step": 1140
    },
    {
      "epoch": 0.2882205513784461,
      "grad_norm": 0.5395305752754211,
      "learning_rate": 9.039264828738513e-06,
      "loss": 0.0548,
      "step": 1150
    },
    {
      "epoch": 0.2907268170426065,
      "grad_norm": 1.5970454216003418,
      "learning_rate": 9.030910609857978e-06,
      "loss": 0.0534,
      "step": 1160
    },
    {
      "epoch": 0.2932330827067669,
      "grad_norm": 0.4180588126182556,
      "learning_rate": 9.022556390977444e-06,
      "loss": 0.0461,
      "step": 1170
    },
    {
      "epoch": 0.2957393483709273,
      "grad_norm": 0.40951836109161377,
      "learning_rate": 9.01420217209691e-06,
      "loss": 0.0366,
      "step": 1180
    },
    {
      "epoch": 0.2982456140350877,
      "grad_norm": 0.7291640043258667,
      "learning_rate": 9.005847953216374e-06,
      "loss": 0.0457,
      "step": 1190
    },
    {
      "epoch": 0.3007518796992481,
      "grad_norm": 0.613789439201355,
      "learning_rate": 8.997493734335841e-06,
      "loss": 0.0488,
      "step": 1200
    },
    {
      "epoch": 0.3032581453634085,
      "grad_norm": 0.2604009807109833,
      "learning_rate": 8.989139515455305e-06,
      "loss": 0.0383,
      "step": 1210
    },
    {
      "epoch": 0.3057644110275689,
      "grad_norm": 0.24613989889621735,
      "learning_rate": 8.98078529657477e-06,
      "loss": 0.0418,
      "step": 1220
    },
    {
      "epoch": 0.3082706766917293,
      "grad_norm": 0.5190037488937378,
      "learning_rate": 8.972431077694236e-06,
      "loss": 0.0396,
      "step": 1230
    },
    {
      "epoch": 0.3107769423558897,
      "grad_norm": 0.5563756227493286,
      "learning_rate": 8.964076858813702e-06,
      "loss": 0.0486,
      "step": 1240
    },
    {
      "epoch": 0.3132832080200501,
      "grad_norm": 0.4659547507762909,
      "learning_rate": 8.955722639933166e-06,
      "loss": 0.0415,
      "step": 1250
    },
    {
      "epoch": 0.3132832080200501,
      "eval_loss": 0.044028956443071365,
      "eval_roc_auc_macro": 0.9776437152463316,
      "eval_runtime": 40.1218,
      "eval_samples_per_second": 795.452,
      "eval_steps_per_second": 24.874,
      "step": 1250
    },
    {
      "epoch": 0.3132832080200501,
      "step": 1250,
      "train_loss": 0.04353025555610657,
      "train_roc_auc_macro": 0.978752789134151,
      "train_runtime": 160.2651,
      "train_samples_per_second": 796.53,
      "train_steps_per_second": 24.896
    },
    {
      "epoch": 0.3157894736842105,
      "grad_norm": 1.0362204313278198,
      "learning_rate": 8.947368421052632e-06,
      "loss": 0.0588,
      "step": 1260
    },
    {
      "epoch": 0.3182957393483709,
      "grad_norm": 0.3890063166618347,
      "learning_rate": 8.939014202172098e-06,
      "loss": 0.0578,
      "step": 1270
    },
    {
      "epoch": 0.3208020050125313,
      "grad_norm": 0.3854334056377411,
      "learning_rate": 8.930659983291563e-06,
      "loss": 0.0395,
      "step": 1280
    },
    {
      "epoch": 0.3233082706766917,
      "grad_norm": 0.1379595547914505,
      "learning_rate": 8.922305764411027e-06,
      "loss": 0.0309,
      "step": 1290
    },
    {
      "epoch": 0.3258145363408521,
      "grad_norm": 0.7800858020782471,
      "learning_rate": 8.913951545530493e-06,
      "loss": 0.0477,
      "step": 1300
    },
    {
      "epoch": 0.3283208020050125,
      "grad_norm": 0.2724402844905853,
      "learning_rate": 8.905597326649959e-06,
      "loss": 0.0448,
      "step": 1310
    },
    {
      "epoch": 0.3308270676691729,
      "grad_norm": 0.622992753982544,
      "learning_rate": 8.897243107769424e-06,
      "loss": 0.0459,
      "step": 1320
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.4153427183628082,
      "learning_rate": 8.888888888888888e-06,
      "loss": 0.0398,
      "step": 1330
    },
    {
      "epoch": 0.3358395989974937,
      "grad_norm": 0.7987594604492188,
      "learning_rate": 8.880534670008356e-06,
      "loss": 0.0593,
      "step": 1340
    },
    {
      "epoch": 0.3383458646616541,
      "grad_norm": 0.6227214336395264,
      "learning_rate": 8.87218045112782e-06,
      "loss": 0.0508,
      "step": 1350
    },
    {
      "epoch": 0.3408521303258145,
      "grad_norm": 0.6205913424491882,
      "learning_rate": 8.863826232247285e-06,
      "loss": 0.0433,
      "step": 1360
    },
    {
      "epoch": 0.3433583959899749,
      "grad_norm": 1.321230411529541,
      "learning_rate": 8.855472013366751e-06,
      "loss": 0.0503,
      "step": 1370
    },
    {
      "epoch": 0.3458646616541353,
      "grad_norm": 0.7801042795181274,
      "learning_rate": 8.847117794486217e-06,
      "loss": 0.0286,
      "step": 1380
    },
    {
      "epoch": 0.3483709273182957,
      "grad_norm": 0.7479844093322754,
      "learning_rate": 8.83876357560568e-06,
      "loss": 0.0352,
      "step": 1390
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.5204843878746033,
      "learning_rate": 8.830409356725146e-06,
      "loss": 0.0359,
      "step": 1400
    },
    {
      "epoch": 0.3533834586466165,
      "grad_norm": 0.4982084035873413,
      "learning_rate": 8.822055137844612e-06,
      "loss": 0.0396,
      "step": 1410
    },
    {
      "epoch": 0.3558897243107769,
      "grad_norm": 1.1902806758880615,
      "learning_rate": 8.813700918964078e-06,
      "loss": 0.0525,
      "step": 1420
    },
    {
      "epoch": 0.3583959899749373,
      "grad_norm": 0.5185311436653137,
      "learning_rate": 8.805346700083542e-06,
      "loss": 0.0341,
      "step": 1430
    },
    {
      "epoch": 0.3609022556390977,
      "grad_norm": 0.46087467670440674,
      "learning_rate": 8.796992481203007e-06,
      "loss": 0.0441,
      "step": 1440
    },
    {
      "epoch": 0.3634085213032581,
      "grad_norm": 0.4275951683521271,
      "learning_rate": 8.788638262322473e-06,
      "loss": 0.0401,
      "step": 1450
    },
    {
      "epoch": 0.3659147869674185,
      "grad_norm": 1.1329147815704346,
      "learning_rate": 8.780284043441939e-06,
      "loss": 0.0541,
      "step": 1460
    },
    {
      "epoch": 0.3684210526315789,
      "grad_norm": 0.38843241333961487,
      "learning_rate": 8.771929824561405e-06,
      "loss": 0.0332,
      "step": 1470
    },
    {
      "epoch": 0.37092731829573933,
      "grad_norm": 1.2091282606124878,
      "learning_rate": 8.76357560568087e-06,
      "loss": 0.0441,
      "step": 1480
    },
    {
      "epoch": 0.37343358395989973,
      "grad_norm": 0.40390950441360474,
      "learning_rate": 8.755221386800334e-06,
      "loss": 0.0492,
      "step": 1490
    },
    {
      "epoch": 0.37593984962406013,
      "grad_norm": 0.36913198232650757,
      "learning_rate": 8.7468671679198e-06,
      "loss": 0.0382,
      "step": 1500
    },
    {
      "epoch": 0.37593984962406013,
      "eval_loss": 0.04538508504629135,
      "eval_roc_auc_macro": 0.9779154918813674,
      "eval_runtime": 40.2036,
      "eval_samples_per_second": 793.834,
      "eval_steps_per_second": 24.824,
      "step": 1500
    },
    {
      "epoch": 0.37593984962406013,
      "step": 1500,
      "train_loss": 0.044416144490242004,
      "train_roc_auc_macro": 0.9790247187992348,
      "train_runtime": 160.115,
      "train_samples_per_second": 797.277,
      "train_steps_per_second": 24.92
    },
    {
      "epoch": 0.37844611528822053,
      "grad_norm": 0.5642015933990479,
      "learning_rate": 8.738512949039266e-06,
      "loss": 0.055,
      "step": 1510
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 0.471573144197464,
      "learning_rate": 8.730158730158731e-06,
      "loss": 0.0553,
      "step": 1520
    },
    {
      "epoch": 0.38345864661654133,
      "grad_norm": 0.4613744020462036,
      "learning_rate": 8.721804511278195e-06,
      "loss": 0.049,
      "step": 1530
    },
    {
      "epoch": 0.38596491228070173,
      "grad_norm": 0.6760826110839844,
      "learning_rate": 8.713450292397661e-06,
      "loss": 0.0362,
      "step": 1540
    },
    {
      "epoch": 0.38847117794486213,
      "grad_norm": 0.7579594254493713,
      "learning_rate": 8.705096073517127e-06,
      "loss": 0.0468,
      "step": 1550
    },
    {
      "epoch": 0.39097744360902253,
      "grad_norm": 0.35823166370391846,
      "learning_rate": 8.696741854636592e-06,
      "loss": 0.0622,
      "step": 1560
    },
    {
      "epoch": 0.39348370927318294,
      "grad_norm": 0.3639257550239563,
      "learning_rate": 8.688387635756056e-06,
      "loss": 0.0359,
      "step": 1570
    },
    {
      "epoch": 0.39598997493734334,
      "grad_norm": 0.46362432837486267,
      "learning_rate": 8.680033416875524e-06,
      "loss": 0.0498,
      "step": 1580
    },
    {
      "epoch": 0.39849624060150374,
      "grad_norm": 0.5837037563323975,
      "learning_rate": 8.671679197994988e-06,
      "loss": 0.052,
      "step": 1590
    },
    {
      "epoch": 0.40100250626566414,
      "grad_norm": 0.15971457958221436,
      "learning_rate": 8.663324979114453e-06,
      "loss": 0.0403,
      "step": 1600
    },
    {
      "epoch": 0.40350877192982454,
      "grad_norm": 0.4578914940357208,
      "learning_rate": 8.654970760233919e-06,
      "loss": 0.0552,
      "step": 1610
    },
    {
      "epoch": 0.40601503759398494,
      "grad_norm": 0.3594070076942444,
      "learning_rate": 8.646616541353385e-06,
      "loss": 0.0437,
      "step": 1620
    },
    {
      "epoch": 0.40852130325814534,
      "grad_norm": 0.5247479677200317,
      "learning_rate": 8.638262322472849e-06,
      "loss": 0.0477,
      "step": 1630
    },
    {
      "epoch": 0.41102756892230574,
      "grad_norm": 0.27982136607170105,
      "learning_rate": 8.629908103592314e-06,
      "loss": 0.0372,
      "step": 1640
    },
    {
      "epoch": 0.41353383458646614,
      "grad_norm": 0.2830865681171417,
      "learning_rate": 8.62155388471178e-06,
      "loss": 0.0436,
      "step": 1650
    },
    {
      "epoch": 0.41604010025062654,
      "grad_norm": 0.761627197265625,
      "learning_rate": 8.613199665831246e-06,
      "loss": 0.0576,
      "step": 1660
    },
    {
      "epoch": 0.41854636591478694,
      "grad_norm": 0.6222057342529297,
      "learning_rate": 8.60484544695071e-06,
      "loss": 0.0446,
      "step": 1670
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 0.7640460133552551,
      "learning_rate": 8.596491228070176e-06,
      "loss": 0.0535,
      "step": 1680
    },
    {
      "epoch": 0.42355889724310775,
      "grad_norm": 0.34586775302886963,
      "learning_rate": 8.588137009189641e-06,
      "loss": 0.0398,
      "step": 1690
    },
    {
      "epoch": 0.42606516290726815,
      "grad_norm": 0.32787013053894043,
      "learning_rate": 8.579782790309107e-06,
      "loss": 0.0429,
      "step": 1700
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 0.34200409054756165,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.0305,
      "step": 1710
    },
    {
      "epoch": 0.43107769423558895,
      "grad_norm": 0.45649290084838867,
      "learning_rate": 8.563074352548038e-06,
      "loss": 0.0352,
      "step": 1720
    },
    {
      "epoch": 0.43358395989974935,
      "grad_norm": 0.6221197247505188,
      "learning_rate": 8.554720133667502e-06,
      "loss": 0.0453,
      "step": 1730
    },
    {
      "epoch": 0.43609022556390975,
      "grad_norm": 0.39651966094970703,
      "learning_rate": 8.546365914786968e-06,
      "loss": 0.0603,
      "step": 1740
    },
    {
      "epoch": 0.43859649122807015,
      "grad_norm": 0.24653573334217072,
      "learning_rate": 8.538011695906434e-06,
      "loss": 0.0392,
      "step": 1750
    },
    {
      "epoch": 0.43859649122807015,
      "eval_loss": 0.04435262084007263,
      "eval_roc_auc_macro": 0.9797106727217865,
      "eval_runtime": 40.1779,
      "eval_samples_per_second": 794.342,
      "eval_steps_per_second": 24.84,
      "step": 1750
    },
    {
      "epoch": 0.43859649122807015,
      "step": 1750,
      "train_loss": 0.04364630579948425,
      "train_roc_auc_macro": 0.9808566534377854,
      "train_runtime": 160.088,
      "train_samples_per_second": 797.411,
      "train_steps_per_second": 24.924
    },
    {
      "epoch": 0.44110275689223055,
      "grad_norm": 0.2677309513092041,
      "learning_rate": 8.5296574770259e-06,
      "loss": 0.0439,
      "step": 1760
    },
    {
      "epoch": 0.44360902255639095,
      "grad_norm": 0.3605603873729706,
      "learning_rate": 8.521303258145363e-06,
      "loss": 0.0405,
      "step": 1770
    },
    {
      "epoch": 0.44611528822055135,
      "grad_norm": 0.3845527470111847,
      "learning_rate": 8.512949039264829e-06,
      "loss": 0.0503,
      "step": 1780
    },
    {
      "epoch": 0.44862155388471175,
      "grad_norm": 0.9330785274505615,
      "learning_rate": 8.504594820384295e-06,
      "loss": 0.0389,
      "step": 1790
    },
    {
      "epoch": 0.45112781954887216,
      "grad_norm": 0.2612278461456299,
      "learning_rate": 8.49624060150376e-06,
      "loss": 0.043,
      "step": 1800
    },
    {
      "epoch": 0.45363408521303256,
      "grad_norm": 0.17237769067287445,
      "learning_rate": 8.487886382623224e-06,
      "loss": 0.0502,
      "step": 1810
    },
    {
      "epoch": 0.45614035087719296,
      "grad_norm": 0.7634428143501282,
      "learning_rate": 8.47953216374269e-06,
      "loss": 0.0413,
      "step": 1820
    },
    {
      "epoch": 0.45864661654135336,
      "grad_norm": 0.7590186595916748,
      "learning_rate": 8.471177944862156e-06,
      "loss": 0.0436,
      "step": 1830
    },
    {
      "epoch": 0.46115288220551376,
      "grad_norm": 0.5104067921638489,
      "learning_rate": 8.462823725981621e-06,
      "loss": 0.0405,
      "step": 1840
    },
    {
      "epoch": 0.46365914786967416,
      "grad_norm": 0.5332840085029602,
      "learning_rate": 8.454469507101085e-06,
      "loss": 0.0504,
      "step": 1850
    },
    {
      "epoch": 0.46616541353383456,
      "grad_norm": 0.421382874250412,
      "learning_rate": 8.446115288220553e-06,
      "loss": 0.0395,
      "step": 1860
    },
    {
      "epoch": 0.46867167919799496,
      "grad_norm": 0.6324112415313721,
      "learning_rate": 8.437761069340017e-06,
      "loss": 0.0611,
      "step": 1870
    },
    {
      "epoch": 0.47117794486215536,
      "grad_norm": 0.584549069404602,
      "learning_rate": 8.429406850459483e-06,
      "loss": 0.0433,
      "step": 1880
    },
    {
      "epoch": 0.47368421052631576,
      "grad_norm": 1.033017873764038,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.0563,
      "step": 1890
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 0.6071874499320984,
      "learning_rate": 8.412698412698414e-06,
      "loss": 0.0586,
      "step": 1900
    },
    {
      "epoch": 0.47869674185463656,
      "grad_norm": 0.23946914076805115,
      "learning_rate": 8.404344193817878e-06,
      "loss": 0.0475,
      "step": 1910
    },
    {
      "epoch": 0.48120300751879697,
      "grad_norm": 0.6018146872520447,
      "learning_rate": 8.395989974937344e-06,
      "loss": 0.0352,
      "step": 1920
    },
    {
      "epoch": 0.48370927318295737,
      "grad_norm": 0.6665701866149902,
      "learning_rate": 8.38763575605681e-06,
      "loss": 0.0705,
      "step": 1930
    },
    {
      "epoch": 0.48621553884711777,
      "grad_norm": 0.4050275385379791,
      "learning_rate": 8.379281537176275e-06,
      "loss": 0.0556,
      "step": 1940
    },
    {
      "epoch": 0.48872180451127817,
      "grad_norm": 0.19337581098079681,
      "learning_rate": 8.370927318295739e-06,
      "loss": 0.0372,
      "step": 1950
    },
    {
      "epoch": 0.49122807017543857,
      "grad_norm": 0.29966074228286743,
      "learning_rate": 8.362573099415205e-06,
      "loss": 0.0417,
      "step": 1960
    },
    {
      "epoch": 0.49373433583959897,
      "grad_norm": 0.14322353899478912,
      "learning_rate": 8.35421888053467e-06,
      "loss": 0.0416,
      "step": 1970
    },
    {
      "epoch": 0.49624060150375937,
      "grad_norm": 0.2168140858411789,
      "learning_rate": 8.345864661654136e-06,
      "loss": 0.0589,
      "step": 1980
    },
    {
      "epoch": 0.49874686716791977,
      "grad_norm": 0.27628079056739807,
      "learning_rate": 8.3375104427736e-06,
      "loss": 0.035,
      "step": 1990
    },
    {
      "epoch": 0.5012531328320802,
      "grad_norm": 0.797219455242157,
      "learning_rate": 8.329156223893067e-06,
      "loss": 0.0431,
      "step": 2000
    },
    {
      "epoch": 0.5012531328320802,
      "eval_loss": 0.04204361513257027,
      "eval_roc_auc_macro": 0.9796120091059924,
      "eval_runtime": 40.21,
      "eval_samples_per_second": 793.708,
      "eval_steps_per_second": 24.82,
      "step": 2000
    },
    {
      "epoch": 0.5012531328320802,
      "step": 2000,
      "train_loss": 0.04092445969581604,
      "train_roc_auc_macro": 0.9808415848293236,
      "train_runtime": 159.9108,
      "train_samples_per_second": 798.295,
      "train_steps_per_second": 24.951
    },
    {
      "epoch": 0.5037593984962406,
      "grad_norm": 0.35267603397369385,
      "learning_rate": 8.320802005012531e-06,
      "loss": 0.0338,
      "step": 2010
    },
    {
      "epoch": 0.506265664160401,
      "grad_norm": 0.4782724976539612,
      "learning_rate": 8.312447786131997e-06,
      "loss": 0.0568,
      "step": 2020
    },
    {
      "epoch": 0.5087719298245614,
      "grad_norm": 0.16177569329738617,
      "learning_rate": 8.304093567251463e-06,
      "loss": 0.04,
      "step": 2030
    },
    {
      "epoch": 0.5112781954887218,
      "grad_norm": 0.7489504814147949,
      "learning_rate": 8.295739348370928e-06,
      "loss": 0.0426,
      "step": 2040
    },
    {
      "epoch": 0.5137844611528822,
      "grad_norm": 0.49404376745224,
      "learning_rate": 8.287385129490392e-06,
      "loss": 0.0293,
      "step": 2050
    },
    {
      "epoch": 0.5162907268170426,
      "grad_norm": 0.7741215825080872,
      "learning_rate": 8.279030910609858e-06,
      "loss": 0.0484,
      "step": 2060
    },
    {
      "epoch": 0.518796992481203,
      "grad_norm": 0.20316584408283234,
      "learning_rate": 8.270676691729324e-06,
      "loss": 0.0286,
      "step": 2070
    },
    {
      "epoch": 0.5213032581453634,
      "grad_norm": 0.6676768660545349,
      "learning_rate": 8.26232247284879e-06,
      "loss": 0.0478,
      "step": 2080
    },
    {
      "epoch": 0.5238095238095238,
      "grad_norm": 0.28707364201545715,
      "learning_rate": 8.253968253968254e-06,
      "loss": 0.0464,
      "step": 2090
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 0.9474145770072937,
      "learning_rate": 8.24561403508772e-06,
      "loss": 0.0429,
      "step": 2100
    },
    {
      "epoch": 0.5288220551378446,
      "grad_norm": 0.35904011130332947,
      "learning_rate": 8.237259816207185e-06,
      "loss": 0.0429,
      "step": 2110
    },
    {
      "epoch": 0.531328320802005,
      "grad_norm": 0.4296281635761261,
      "learning_rate": 8.22890559732665e-06,
      "loss": 0.0429,
      "step": 2120
    },
    {
      "epoch": 0.5338345864661654,
      "grad_norm": 0.9051135182380676,
      "learning_rate": 8.220551378446116e-06,
      "loss": 0.0545,
      "step": 2130
    },
    {
      "epoch": 0.5363408521303258,
      "grad_norm": 0.6026296019554138,
      "learning_rate": 8.212197159565582e-06,
      "loss": 0.0663,
      "step": 2140
    },
    {
      "epoch": 0.5388471177944862,
      "grad_norm": 0.2895073890686035,
      "learning_rate": 8.203842940685046e-06,
      "loss": 0.0504,
      "step": 2150
    },
    {
      "epoch": 0.5413533834586466,
      "grad_norm": 0.4194778800010681,
      "learning_rate": 8.195488721804512e-06,
      "loss": 0.0452,
      "step": 2160
    },
    {
      "epoch": 0.543859649122807,
      "grad_norm": 0.46451491117477417,
      "learning_rate": 8.187134502923977e-06,
      "loss": 0.0437,
      "step": 2170
    },
    {
      "epoch": 0.5463659147869674,
      "grad_norm": 1.0731219053268433,
      "learning_rate": 8.178780284043443e-06,
      "loss": 0.0518,
      "step": 2180
    },
    {
      "epoch": 0.5488721804511278,
      "grad_norm": 0.27461594343185425,
      "learning_rate": 8.170426065162907e-06,
      "loss": 0.0625,
      "step": 2190
    },
    {
      "epoch": 0.5513784461152882,
      "grad_norm": 0.27587905526161194,
      "learning_rate": 8.162071846282373e-06,
      "loss": 0.0431,
      "step": 2200
    },
    {
      "epoch": 0.5538847117794486,
      "grad_norm": 0.43781593441963196,
      "learning_rate": 8.153717627401838e-06,
      "loss": 0.0349,
      "step": 2210
    },
    {
      "epoch": 0.556390977443609,
      "grad_norm": 0.3835380971431732,
      "learning_rate": 8.145363408521304e-06,
      "loss": 0.0462,
      "step": 2220
    },
    {
      "epoch": 0.5588972431077694,
      "grad_norm": 0.245835542678833,
      "learning_rate": 8.137009189640768e-06,
      "loss": 0.0335,
      "step": 2230
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 0.3579965829849243,
      "learning_rate": 8.128654970760235e-06,
      "loss": 0.0395,
      "step": 2240
    },
    {
      "epoch": 0.5639097744360902,
      "grad_norm": 0.9020552635192871,
      "learning_rate": 8.1203007518797e-06,
      "loss": 0.0469,
      "step": 2250
    },
    {
      "epoch": 0.5639097744360902,
      "eval_loss": 0.04356660693883896,
      "eval_roc_auc_macro": 0.979829698944346,
      "eval_runtime": 40.1139,
      "eval_samples_per_second": 795.609,
      "eval_steps_per_second": 24.879,
      "step": 2250
    },
    {
      "epoch": 0.5639097744360902,
      "step": 2250,
      "train_loss": 0.0421292670071125,
      "train_roc_auc_macro": 0.9814092989308434,
      "train_runtime": 160.1345,
      "train_samples_per_second": 797.18,
      "train_steps_per_second": 24.917
    },
    {
      "epoch": 0.5664160401002506,
      "grad_norm": 0.357499361038208,
      "learning_rate": 8.111946532999165e-06,
      "loss": 0.0486,
      "step": 2260
    },
    {
      "epoch": 0.568922305764411,
      "grad_norm": 0.7083078026771545,
      "learning_rate": 8.103592314118631e-06,
      "loss": 0.0422,
      "step": 2270
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.1296345293521881,
      "learning_rate": 8.095238095238097e-06,
      "loss": 0.0428,
      "step": 2280
    },
    {
      "epoch": 0.5739348370927319,
      "grad_norm": 0.3122028708457947,
      "learning_rate": 8.08688387635756e-06,
      "loss": 0.0426,
      "step": 2290
    },
    {
      "epoch": 0.5764411027568922,
      "grad_norm": 0.7225139737129211,
      "learning_rate": 8.078529657477026e-06,
      "loss": 0.0326,
      "step": 2300
    },
    {
      "epoch": 0.5789473684210527,
      "grad_norm": 1.4210373163223267,
      "learning_rate": 8.070175438596492e-06,
      "loss": 0.0488,
      "step": 2310
    },
    {
      "epoch": 0.581453634085213,
      "grad_norm": 0.4432374835014343,
      "learning_rate": 8.061821219715958e-06,
      "loss": 0.0351,
      "step": 2320
    },
    {
      "epoch": 0.5839598997493735,
      "grad_norm": 0.2566751539707184,
      "learning_rate": 8.053467000835422e-06,
      "loss": 0.034,
      "step": 2330
    },
    {
      "epoch": 0.5864661654135338,
      "grad_norm": 0.4036833345890045,
      "learning_rate": 8.045112781954887e-06,
      "loss": 0.0411,
      "step": 2340
    },
    {
      "epoch": 0.5889724310776943,
      "grad_norm": 0.3019193112850189,
      "learning_rate": 8.036758563074353e-06,
      "loss": 0.0359,
      "step": 2350
    },
    {
      "epoch": 0.5914786967418546,
      "grad_norm": 0.5575416684150696,
      "learning_rate": 8.028404344193819e-06,
      "loss": 0.0427,
      "step": 2360
    },
    {
      "epoch": 0.5939849624060151,
      "grad_norm": 0.6689484119415283,
      "learning_rate": 8.020050125313283e-06,
      "loss": 0.0413,
      "step": 2370
    },
    {
      "epoch": 0.5964912280701754,
      "grad_norm": 0.17705793678760529,
      "learning_rate": 8.01169590643275e-06,
      "loss": 0.038,
      "step": 2380
    },
    {
      "epoch": 0.5989974937343359,
      "grad_norm": 0.34430524706840515,
      "learning_rate": 8.003341687552214e-06,
      "loss": 0.0363,
      "step": 2390
    },
    {
      "epoch": 0.6015037593984962,
      "grad_norm": 0.5890575051307678,
      "learning_rate": 7.99498746867168e-06,
      "loss": 0.0405,
      "step": 2400
    },
    {
      "epoch": 0.6040100250626567,
      "grad_norm": 0.3029840290546417,
      "learning_rate": 7.986633249791145e-06,
      "loss": 0.0248,
      "step": 2410
    },
    {
      "epoch": 0.606516290726817,
      "grad_norm": 0.1161850318312645,
      "learning_rate": 7.978279030910611e-06,
      "loss": 0.0499,
      "step": 2420
    },
    {
      "epoch": 0.6090225563909775,
      "grad_norm": 0.5781925916671753,
      "learning_rate": 7.969924812030075e-06,
      "loss": 0.0426,
      "step": 2430
    },
    {
      "epoch": 0.6115288220551378,
      "grad_norm": 0.6846217513084412,
      "learning_rate": 7.96157059314954e-06,
      "loss": 0.0457,
      "step": 2440
    },
    {
      "epoch": 0.6140350877192983,
      "grad_norm": 0.30787649750709534,
      "learning_rate": 7.953216374269006e-06,
      "loss": 0.0522,
      "step": 2450
    },
    {
      "epoch": 0.6165413533834586,
      "grad_norm": 0.24454160034656525,
      "learning_rate": 7.944862155388472e-06,
      "loss": 0.0452,
      "step": 2460
    },
    {
      "epoch": 0.6190476190476191,
      "grad_norm": 0.8994396328926086,
      "learning_rate": 7.936507936507936e-06,
      "loss": 0.0572,
      "step": 2470
    },
    {
      "epoch": 0.6215538847117794,
      "grad_norm": 0.5733615159988403,
      "learning_rate": 7.928153717627402e-06,
      "loss": 0.0373,
      "step": 2480
    },
    {
      "epoch": 0.6240601503759399,
      "grad_norm": 0.46692565083503723,
      "learning_rate": 7.919799498746868e-06,
      "loss": 0.0478,
      "step": 2490
    },
    {
      "epoch": 0.6265664160401002,
      "grad_norm": 0.8457190990447998,
      "learning_rate": 7.911445279866333e-06,
      "loss": 0.0638,
      "step": 2500
    },
    {
      "epoch": 0.6265664160401002,
      "eval_loss": 0.053397826850414276,
      "eval_roc_auc_macro": 0.9819049284194591,
      "eval_runtime": 40.192,
      "eval_samples_per_second": 794.064,
      "eval_steps_per_second": 24.831,
      "step": 2500
    },
    {
      "epoch": 0.6265664160401002,
      "step": 2500,
      "train_loss": 0.051611337810754776,
      "train_roc_auc_macro": 0.9833525990702906,
      "train_runtime": 159.9476,
      "train_samples_per_second": 798.111,
      "train_steps_per_second": 24.946
    },
    {
      "epoch": 0.6290726817042607,
      "grad_norm": 0.5415027737617493,
      "learning_rate": 7.903091060985797e-06,
      "loss": 0.0561,
      "step": 2510
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.4704972505569458,
      "learning_rate": 7.894736842105265e-06,
      "loss": 0.0511,
      "step": 2520
    },
    {
      "epoch": 0.6340852130325815,
      "grad_norm": 0.2087634652853012,
      "learning_rate": 7.886382623224729e-06,
      "loss": 0.0461,
      "step": 2530
    },
    {
      "epoch": 0.6365914786967418,
      "grad_norm": 0.45964252948760986,
      "learning_rate": 7.878028404344194e-06,
      "loss": 0.0369,
      "step": 2540
    },
    {
      "epoch": 0.6390977443609023,
      "grad_norm": 0.4960629343986511,
      "learning_rate": 7.86967418546366e-06,
      "loss": 0.0435,
      "step": 2550
    },
    {
      "epoch": 0.6416040100250626,
      "grad_norm": 0.5791741013526917,
      "learning_rate": 7.861319966583126e-06,
      "loss": 0.0325,
      "step": 2560
    },
    {
      "epoch": 0.6441102756892231,
      "grad_norm": 0.5503925085067749,
      "learning_rate": 7.85296574770259e-06,
      "loss": 0.0315,
      "step": 2570
    },
    {
      "epoch": 0.6466165413533834,
      "grad_norm": 0.9607227444648743,
      "learning_rate": 7.844611528822055e-06,
      "loss": 0.0512,
      "step": 2580
    },
    {
      "epoch": 0.6491228070175439,
      "grad_norm": 0.21270069479942322,
      "learning_rate": 7.836257309941521e-06,
      "loss": 0.0472,
      "step": 2590
    },
    {
      "epoch": 0.6516290726817042,
      "grad_norm": 0.6391130685806274,
      "learning_rate": 7.827903091060987e-06,
      "loss": 0.04,
      "step": 2600
    },
    {
      "epoch": 0.6541353383458647,
      "grad_norm": 0.4660216271877289,
      "learning_rate": 7.81954887218045e-06,
      "loss": 0.049,
      "step": 2610
    },
    {
      "epoch": 0.656641604010025,
      "grad_norm": 0.44749706983566284,
      "learning_rate": 7.811194653299916e-06,
      "loss": 0.0438,
      "step": 2620
    },
    {
      "epoch": 0.6591478696741855,
      "grad_norm": 0.9602824449539185,
      "learning_rate": 7.802840434419382e-06,
      "loss": 0.047,
      "step": 2630
    },
    {
      "epoch": 0.6616541353383458,
      "grad_norm": 0.42889150977134705,
      "learning_rate": 7.794486215538848e-06,
      "loss": 0.0494,
      "step": 2640
    },
    {
      "epoch": 0.6641604010025063,
      "grad_norm": 0.8028417825698853,
      "learning_rate": 7.786131996658313e-06,
      "loss": 0.0407,
      "step": 2650
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.5636252164840698,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.041,
      "step": 2660
    },
    {
      "epoch": 0.6691729323308271,
      "grad_norm": 0.8244350552558899,
      "learning_rate": 7.769423558897243e-06,
      "loss": 0.0724,
      "step": 2670
    },
    {
      "epoch": 0.6716791979949874,
      "grad_norm": 0.31228306889533997,
      "learning_rate": 7.761069340016709e-06,
      "loss": 0.0396,
      "step": 2680
    },
    {
      "epoch": 0.6741854636591479,
      "grad_norm": 0.4428434371948242,
      "learning_rate": 7.752715121136175e-06,
      "loss": 0.0444,
      "step": 2690
    },
    {
      "epoch": 0.6766917293233082,
      "grad_norm": 0.47241300344467163,
      "learning_rate": 7.74436090225564e-06,
      "loss": 0.0449,
      "step": 2700
    },
    {
      "epoch": 0.6791979949874687,
      "grad_norm": 0.5099948644638062,
      "learning_rate": 7.736006683375104e-06,
      "loss": 0.046,
      "step": 2710
    },
    {
      "epoch": 0.681704260651629,
      "grad_norm": 0.5048907995223999,
      "learning_rate": 7.72765246449457e-06,
      "loss": 0.0401,
      "step": 2720
    },
    {
      "epoch": 0.6842105263157895,
      "grad_norm": 0.5372223258018494,
      "learning_rate": 7.719298245614036e-06,
      "loss": 0.0464,
      "step": 2730
    },
    {
      "epoch": 0.6867167919799498,
      "grad_norm": 0.1896323561668396,
      "learning_rate": 7.710944026733501e-06,
      "loss": 0.0274,
      "step": 2740
    },
    {
      "epoch": 0.6892230576441103,
      "grad_norm": 0.27228087186813354,
      "learning_rate": 7.702589807852965e-06,
      "loss": 0.0381,
      "step": 2750
    },
    {
      "epoch": 0.6892230576441103,
      "eval_loss": 0.0431830994784832,
      "eval_roc_auc_macro": 0.9811633747229295,
      "eval_runtime": 40.1611,
      "eval_samples_per_second": 794.675,
      "eval_steps_per_second": 24.85,
      "step": 2750
    },
    {
      "epoch": 0.6892230576441103,
      "step": 2750,
      "train_loss": 0.041194066405296326,
      "train_roc_auc_macro": 0.9835261665686476,
      "train_runtime": 160.1991,
      "train_samples_per_second": 796.858,
      "train_steps_per_second": 24.907
    },
    {
      "epoch": 0.6917293233082706,
      "grad_norm": 0.7533156871795654,
      "learning_rate": 7.694235588972433e-06,
      "loss": 0.0485,
      "step": 2760
    },
    {
      "epoch": 0.6942355889724311,
      "grad_norm": 0.2779483497142792,
      "learning_rate": 7.685881370091897e-06,
      "loss": 0.0434,
      "step": 2770
    },
    {
      "epoch": 0.6967418546365914,
      "grad_norm": 0.2285560816526413,
      "learning_rate": 7.677527151211362e-06,
      "loss": 0.0382,
      "step": 2780
    },
    {
      "epoch": 0.6992481203007519,
      "grad_norm": 0.6269541382789612,
      "learning_rate": 7.669172932330828e-06,
      "loss": 0.0334,
      "step": 2790
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.49803832173347473,
      "learning_rate": 7.660818713450294e-06,
      "loss": 0.0315,
      "step": 2800
    },
    {
      "epoch": 0.7042606516290727,
      "grad_norm": 1.0870757102966309,
      "learning_rate": 7.652464494569758e-06,
      "loss": 0.0392,
      "step": 2810
    },
    {
      "epoch": 0.706766917293233,
      "grad_norm": 0.6606059670448303,
      "learning_rate": 7.644110275689223e-06,
      "loss": 0.0434,
      "step": 2820
    },
    {
      "epoch": 0.7092731829573935,
      "grad_norm": 0.7329869866371155,
      "learning_rate": 7.635756056808689e-06,
      "loss": 0.0373,
      "step": 2830
    },
    {
      "epoch": 0.7117794486215538,
      "grad_norm": 0.3831316828727722,
      "learning_rate": 7.627401837928155e-06,
      "loss": 0.0426,
      "step": 2840
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.4045303463935852,
      "learning_rate": 7.61904761904762e-06,
      "loss": 0.0391,
      "step": 2850
    },
    {
      "epoch": 0.7167919799498746,
      "grad_norm": 0.6689099073410034,
      "learning_rate": 7.610693400167085e-06,
      "loss": 0.0431,
      "step": 2860
    },
    {
      "epoch": 0.7192982456140351,
      "grad_norm": 0.5189253687858582,
      "learning_rate": 7.60233918128655e-06,
      "loss": 0.0437,
      "step": 2870
    },
    {
      "epoch": 0.7218045112781954,
      "grad_norm": 0.28976693749427795,
      "learning_rate": 7.593984962406016e-06,
      "loss": 0.0366,
      "step": 2880
    },
    {
      "epoch": 0.7243107769423559,
      "grad_norm": 0.34005817770957947,
      "learning_rate": 7.585630743525481e-06,
      "loss": 0.0477,
      "step": 2890
    },
    {
      "epoch": 0.7268170426065163,
      "grad_norm": 0.8267617225646973,
      "learning_rate": 7.577276524644946e-06,
      "loss": 0.052,
      "step": 2900
    },
    {
      "epoch": 0.7293233082706767,
      "grad_norm": 0.5384452939033508,
      "learning_rate": 7.568922305764411e-06,
      "loss": 0.0563,
      "step": 2910
    },
    {
      "epoch": 0.731829573934837,
      "grad_norm": 0.07964614778757095,
      "learning_rate": 7.560568086883877e-06,
      "loss": 0.0383,
      "step": 2920
    },
    {
      "epoch": 0.7343358395989975,
      "grad_norm": 0.2411738634109497,
      "learning_rate": 7.552213868003342e-06,
      "loss": 0.0289,
      "step": 2930
    },
    {
      "epoch": 0.7368421052631579,
      "grad_norm": 0.35897326469421387,
      "learning_rate": 7.5438596491228074e-06,
      "loss": 0.0334,
      "step": 2940
    },
    {
      "epoch": 0.7393483709273183,
      "grad_norm": 0.21722064912319183,
      "learning_rate": 7.535505430242272e-06,
      "loss": 0.0389,
      "step": 2950
    },
    {
      "epoch": 0.7418546365914787,
      "grad_norm": 0.4464230239391327,
      "learning_rate": 7.527151211361739e-06,
      "loss": 0.0658,
      "step": 2960
    },
    {
      "epoch": 0.7443609022556391,
      "grad_norm": 0.6759232878684998,
      "learning_rate": 7.518796992481203e-06,
      "loss": 0.0407,
      "step": 2970
    },
    {
      "epoch": 0.7468671679197995,
      "grad_norm": 0.5167270302772522,
      "learning_rate": 7.510442773600669e-06,
      "loss": 0.0559,
      "step": 2980
    },
    {
      "epoch": 0.7493734335839599,
      "grad_norm": 0.2946869134902954,
      "learning_rate": 7.502088554720134e-06,
      "loss": 0.038,
      "step": 2990
    },
    {
      "epoch": 0.7518796992481203,
      "grad_norm": 0.9136060476303101,
      "learning_rate": 7.4937343358396e-06,
      "loss": 0.0469,
      "step": 3000
    },
    {
      "epoch": 0.7518796992481203,
      "eval_loss": 0.04243472218513489,
      "eval_roc_auc_macro": 0.9830720854227382,
      "eval_runtime": 40.2106,
      "eval_samples_per_second": 793.697,
      "eval_steps_per_second": 24.819,
      "step": 3000
    },
    {
      "epoch": 0.7518796992481203,
      "step": 3000,
      "train_loss": 0.04039120674133301,
      "train_roc_auc_macro": 0.9854837912501115,
      "train_runtime": 160.2319,
      "train_samples_per_second": 796.695,
      "train_steps_per_second": 24.901
    },
    {
      "epoch": 0.7543859649122807,
      "grad_norm": 0.402290403842926,
      "learning_rate": 7.485380116959065e-06,
      "loss": 0.0324,
      "step": 3010
    },
    {
      "epoch": 0.7568922305764411,
      "grad_norm": 1.223938226699829,
      "learning_rate": 7.47702589807853e-06,
      "loss": 0.0365,
      "step": 3020
    },
    {
      "epoch": 0.7593984962406015,
      "grad_norm": 1.4168792963027954,
      "learning_rate": 7.468671679197995e-06,
      "loss": 0.0429,
      "step": 3030
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 0.7579914927482605,
      "learning_rate": 7.460317460317461e-06,
      "loss": 0.0501,
      "step": 3040
    },
    {
      "epoch": 0.7644110275689223,
      "grad_norm": 0.496858686208725,
      "learning_rate": 7.451963241436926e-06,
      "loss": 0.0547,
      "step": 3050
    },
    {
      "epoch": 0.7669172932330827,
      "grad_norm": 0.21267935633659363,
      "learning_rate": 7.4436090225563915e-06,
      "loss": 0.0402,
      "step": 3060
    },
    {
      "epoch": 0.7694235588972431,
      "grad_norm": 0.3777441680431366,
      "learning_rate": 7.435254803675856e-06,
      "loss": 0.0436,
      "step": 3070
    },
    {
      "epoch": 0.7719298245614035,
      "grad_norm": 1.1241486072540283,
      "learning_rate": 7.426900584795322e-06,
      "loss": 0.0443,
      "step": 3080
    },
    {
      "epoch": 0.7744360902255639,
      "grad_norm": 0.16072261333465576,
      "learning_rate": 7.418546365914787e-06,
      "loss": 0.0623,
      "step": 3090
    },
    {
      "epoch": 0.7769423558897243,
      "grad_norm": 0.704451322555542,
      "learning_rate": 7.410192147034253e-06,
      "loss": 0.0411,
      "step": 3100
    },
    {
      "epoch": 0.7794486215538847,
      "grad_norm": 0.4831007719039917,
      "learning_rate": 7.401837928153718e-06,
      "loss": 0.0478,
      "step": 3110
    },
    {
      "epoch": 0.7819548872180451,
      "grad_norm": 0.5147837400436401,
      "learning_rate": 7.393483709273184e-06,
      "loss": 0.0447,
      "step": 3120
    },
    {
      "epoch": 0.7844611528822055,
      "grad_norm": 0.3434632122516632,
      "learning_rate": 7.385129490392649e-06,
      "loss": 0.0608,
      "step": 3130
    },
    {
      "epoch": 0.7869674185463659,
      "grad_norm": 0.514335036277771,
      "learning_rate": 7.3767752715121144e-06,
      "loss": 0.0427,
      "step": 3140
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.4517228603363037,
      "learning_rate": 7.368421052631579e-06,
      "loss": 0.0485,
      "step": 3150
    },
    {
      "epoch": 0.7919799498746867,
      "grad_norm": 0.878666341304779,
      "learning_rate": 7.360066833751045e-06,
      "loss": 0.0382,
      "step": 3160
    },
    {
      "epoch": 0.7944862155388471,
      "grad_norm": 0.18248842656612396,
      "learning_rate": 7.35171261487051e-06,
      "loss": 0.0362,
      "step": 3170
    },
    {
      "epoch": 0.7969924812030075,
      "grad_norm": 0.8331691026687622,
      "learning_rate": 7.3433583959899755e-06,
      "loss": 0.0439,
      "step": 3180
    },
    {
      "epoch": 0.7994987468671679,
      "grad_norm": 1.5881096124649048,
      "learning_rate": 7.33500417710944e-06,
      "loss": 0.0496,
      "step": 3190
    },
    {
      "epoch": 0.8020050125313283,
      "grad_norm": 0.3412207067012787,
      "learning_rate": 7.326649958228906e-06,
      "loss": 0.0441,
      "step": 3200
    },
    {
      "epoch": 0.8045112781954887,
      "grad_norm": 0.35050487518310547,
      "learning_rate": 7.318295739348371e-06,
      "loss": 0.0302,
      "step": 3210
    },
    {
      "epoch": 0.8070175438596491,
      "grad_norm": 0.249750018119812,
      "learning_rate": 7.309941520467837e-06,
      "loss": 0.0371,
      "step": 3220
    },
    {
      "epoch": 0.8095238095238095,
      "grad_norm": 0.14520816504955292,
      "learning_rate": 7.301587301587301e-06,
      "loss": 0.0336,
      "step": 3230
    },
    {
      "epoch": 0.8120300751879699,
      "grad_norm": 0.351215124130249,
      "learning_rate": 7.293233082706768e-06,
      "loss": 0.0668,
      "step": 3240
    },
    {
      "epoch": 0.8145363408521303,
      "grad_norm": 0.7257996201515198,
      "learning_rate": 7.284878863826233e-06,
      "loss": 0.044,
      "step": 3250
    },
    {
      "epoch": 0.8145363408521303,
      "eval_loss": 0.044755954295396805,
      "eval_roc_auc_macro": 0.9834688639331657,
      "eval_runtime": 40.2444,
      "eval_samples_per_second": 793.029,
      "eval_steps_per_second": 24.798,
      "step": 3250
    },
    {
      "epoch": 0.8145363408521303,
      "step": 3250,
      "train_loss": 0.042619023472070694,
      "train_roc_auc_macro": 0.9862114012748355,
      "train_runtime": 160.2502,
      "train_samples_per_second": 796.605,
      "train_steps_per_second": 24.899
    },
    {
      "epoch": 0.8170426065162907,
      "grad_norm": 0.3546600639820099,
      "learning_rate": 7.2765246449456985e-06,
      "loss": 0.0364,
      "step": 3260
    },
    {
      "epoch": 0.8195488721804511,
      "grad_norm": 0.38446244597435,
      "learning_rate": 7.268170426065163e-06,
      "loss": 0.0438,
      "step": 3270
    },
    {
      "epoch": 0.8220551378446115,
      "grad_norm": 0.8546282649040222,
      "learning_rate": 7.259816207184629e-06,
      "loss": 0.0495,
      "step": 3280
    },
    {
      "epoch": 0.8245614035087719,
      "grad_norm": 0.4560432732105255,
      "learning_rate": 7.251461988304094e-06,
      "loss": 0.0416,
      "step": 3290
    },
    {
      "epoch": 0.8270676691729323,
      "grad_norm": 0.5769849419593811,
      "learning_rate": 7.2431077694235595e-06,
      "loss": 0.0501,
      "step": 3300
    },
    {
      "epoch": 0.8295739348370927,
      "grad_norm": 0.444046288728714,
      "learning_rate": 7.234753550543024e-06,
      "loss": 0.041,
      "step": 3310
    },
    {
      "epoch": 0.8320802005012531,
      "grad_norm": 0.4624394476413727,
      "learning_rate": 7.22639933166249e-06,
      "loss": 0.0451,
      "step": 3320
    },
    {
      "epoch": 0.8345864661654135,
      "grad_norm": 0.34395632147789,
      "learning_rate": 7.218045112781955e-06,
      "loss": 0.0408,
      "step": 3330
    },
    {
      "epoch": 0.8370927318295739,
      "grad_norm": 0.016663437709212303,
      "learning_rate": 7.209690893901421e-06,
      "loss": 0.0247,
      "step": 3340
    },
    {
      "epoch": 0.8395989974937343,
      "grad_norm": 0.833902895450592,
      "learning_rate": 7.2013366750208854e-06,
      "loss": 0.0472,
      "step": 3350
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.5240737199783325,
      "learning_rate": 7.192982456140352e-06,
      "loss": 0.0393,
      "step": 3360
    },
    {
      "epoch": 0.8446115288220551,
      "grad_norm": 0.8097997903823853,
      "learning_rate": 7.184628237259817e-06,
      "loss": 0.0345,
      "step": 3370
    },
    {
      "epoch": 0.8471177944862155,
      "grad_norm": 0.3454185426235199,
      "learning_rate": 7.1762740183792825e-06,
      "loss": 0.0461,
      "step": 3380
    },
    {
      "epoch": 0.849624060150376,
      "grad_norm": 0.1711002141237259,
      "learning_rate": 7.167919799498747e-06,
      "loss": 0.0364,
      "step": 3390
    },
    {
      "epoch": 0.8521303258145363,
      "grad_norm": 0.5074334144592285,
      "learning_rate": 7.159565580618213e-06,
      "loss": 0.0538,
      "step": 3400
    },
    {
      "epoch": 0.8546365914786967,
      "grad_norm": 0.2239346206188202,
      "learning_rate": 7.151211361737678e-06,
      "loss": 0.0418,
      "step": 3410
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.5865164399147034,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 0.0529,
      "step": 3420
    },
    {
      "epoch": 0.8596491228070176,
      "grad_norm": 0.21216480433940887,
      "learning_rate": 7.134502923976608e-06,
      "loss": 0.0392,
      "step": 3430
    },
    {
      "epoch": 0.8621553884711779,
      "grad_norm": 0.4637210965156555,
      "learning_rate": 7.126148705096074e-06,
      "loss": 0.0397,
      "step": 3440
    },
    {
      "epoch": 0.8646616541353384,
      "grad_norm": 0.26414379477500916,
      "learning_rate": 7.117794486215539e-06,
      "loss": 0.0554,
      "step": 3450
    },
    {
      "epoch": 0.8671679197994987,
      "grad_norm": 0.6069537401199341,
      "learning_rate": 7.109440267335005e-06,
      "loss": 0.0516,
      "step": 3460
    },
    {
      "epoch": 0.8696741854636592,
      "grad_norm": 0.609828770160675,
      "learning_rate": 7.1010860484544695e-06,
      "loss": 0.0338,
      "step": 3470
    },
    {
      "epoch": 0.8721804511278195,
      "grad_norm": 0.6801688075065613,
      "learning_rate": 7.092731829573936e-06,
      "loss": 0.0309,
      "step": 3480
    },
    {
      "epoch": 0.87468671679198,
      "grad_norm": 0.9877630472183228,
      "learning_rate": 7.0843776106934e-06,
      "loss": 0.0499,
      "step": 3490
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 0.7329442501068115,
      "learning_rate": 7.0760233918128665e-06,
      "loss": 0.0335,
      "step": 3500
    },
    {
      "epoch": 0.8771929824561403,
      "eval_loss": 0.04124552384018898,
      "eval_roc_auc_macro": 0.9824324909048544,
      "eval_runtime": 40.2244,
      "eval_samples_per_second": 793.424,
      "eval_steps_per_second": 24.811,
      "step": 3500
    },
    {
      "epoch": 0.8771929824561403,
      "step": 3500,
      "train_loss": 0.03881501778960228,
      "train_roc_auc_macro": 0.985622393061251,
      "train_runtime": 160.0309,
      "train_samples_per_second": 797.696,
      "train_steps_per_second": 24.933
    },
    {
      "epoch": 0.8796992481203008,
      "grad_norm": 0.36224526166915894,
      "learning_rate": 7.067669172932331e-06,
      "loss": 0.0428,
      "step": 3510
    },
    {
      "epoch": 0.8822055137844611,
      "grad_norm": 0.2520832121372223,
      "learning_rate": 7.059314954051797e-06,
      "loss": 0.0382,
      "step": 3520
    },
    {
      "epoch": 0.8847117794486216,
      "grad_norm": 0.7564098834991455,
      "learning_rate": 7.050960735171262e-06,
      "loss": 0.0496,
      "step": 3530
    },
    {
      "epoch": 0.8872180451127819,
      "grad_norm": 0.40669286251068115,
      "learning_rate": 7.042606516290728e-06,
      "loss": 0.0436,
      "step": 3540
    },
    {
      "epoch": 0.8897243107769424,
      "grad_norm": 0.5031375288963318,
      "learning_rate": 7.0342522974101924e-06,
      "loss": 0.043,
      "step": 3550
    },
    {
      "epoch": 0.8922305764411027,
      "grad_norm": 0.4948709011077881,
      "learning_rate": 7.025898078529658e-06,
      "loss": 0.0359,
      "step": 3560
    },
    {
      "epoch": 0.8947368421052632,
      "grad_norm": 0.6863162517547607,
      "learning_rate": 7.017543859649123e-06,
      "loss": 0.0324,
      "step": 3570
    },
    {
      "epoch": 0.8972431077694235,
      "grad_norm": 0.3842679560184479,
      "learning_rate": 7.009189640768589e-06,
      "loss": 0.0467,
      "step": 3580
    },
    {
      "epoch": 0.899749373433584,
      "grad_norm": 0.31943240761756897,
      "learning_rate": 7.0008354218880535e-06,
      "loss": 0.0498,
      "step": 3590
    },
    {
      "epoch": 0.9022556390977443,
      "grad_norm": 0.7861886024475098,
      "learning_rate": 6.992481203007519e-06,
      "loss": 0.0416,
      "step": 3600
    },
    {
      "epoch": 0.9047619047619048,
      "grad_norm": 0.5935928821563721,
      "learning_rate": 6.984126984126984e-06,
      "loss": 0.048,
      "step": 3610
    },
    {
      "epoch": 0.9072681704260651,
      "grad_norm": 0.21373607218265533,
      "learning_rate": 6.9757727652464506e-06,
      "loss": 0.0423,
      "step": 3620
    },
    {
      "epoch": 0.9097744360902256,
      "grad_norm": 1.3939608335494995,
      "learning_rate": 6.9674185463659146e-06,
      "loss": 0.0493,
      "step": 3630
    },
    {
      "epoch": 0.9122807017543859,
      "grad_norm": 0.5063135027885437,
      "learning_rate": 6.959064327485381e-06,
      "loss": 0.0333,
      "step": 3640
    },
    {
      "epoch": 0.9147869674185464,
      "grad_norm": 0.4036746621131897,
      "learning_rate": 6.950710108604846e-06,
      "loss": 0.0356,
      "step": 3650
    },
    {
      "epoch": 0.9172932330827067,
      "grad_norm": 0.8082371354103088,
      "learning_rate": 6.942355889724312e-06,
      "loss": 0.0502,
      "step": 3660
    },
    {
      "epoch": 0.9197994987468672,
      "grad_norm": 0.36194857954978943,
      "learning_rate": 6.9340016708437765e-06,
      "loss": 0.0365,
      "step": 3670
    },
    {
      "epoch": 0.9223057644110275,
      "grad_norm": 0.3080035150051117,
      "learning_rate": 6.925647451963242e-06,
      "loss": 0.0415,
      "step": 3680
    },
    {
      "epoch": 0.924812030075188,
      "grad_norm": 0.5197771787643433,
      "learning_rate": 6.917293233082707e-06,
      "loss": 0.0464,
      "step": 3690
    },
    {
      "epoch": 0.9273182957393483,
      "grad_norm": 0.6710476875305176,
      "learning_rate": 6.908939014202173e-06,
      "loss": 0.0407,
      "step": 3700
    },
    {
      "epoch": 0.9298245614035088,
      "grad_norm": 0.7213407158851624,
      "learning_rate": 6.9005847953216375e-06,
      "loss": 0.0471,
      "step": 3710
    },
    {
      "epoch": 0.9323308270676691,
      "grad_norm": 0.588036298751831,
      "learning_rate": 6.892230576441103e-06,
      "loss": 0.0716,
      "step": 3720
    },
    {
      "epoch": 0.9348370927318296,
      "grad_norm": 0.43976977467536926,
      "learning_rate": 6.883876357560568e-06,
      "loss": 0.0509,
      "step": 3730
    },
    {
      "epoch": 0.9373433583959899,
      "grad_norm": 0.5134975910186768,
      "learning_rate": 6.875522138680034e-06,
      "loss": 0.0456,
      "step": 3740
    },
    {
      "epoch": 0.9398496240601504,
      "grad_norm": 0.1979387104511261,
      "learning_rate": 6.867167919799499e-06,
      "loss": 0.04,
      "step": 3750
    },
    {
      "epoch": 0.9398496240601504,
      "eval_loss": 0.03985537588596344,
      "eval_roc_auc_macro": 0.984979736243924,
      "eval_runtime": 40.2136,
      "eval_samples_per_second": 793.638,
      "eval_steps_per_second": 24.818,
      "step": 3750
    },
    {
      "epoch": 0.9398496240601504,
      "step": 3750,
      "train_loss": 0.037387073040008545,
      "train_roc_auc_macro": 0.9876621950814721,
      "train_runtime": 160.2132,
      "train_samples_per_second": 796.788,
      "train_steps_per_second": 24.904
    },
    {
      "epoch": 0.9423558897243107,
      "grad_norm": 0.5716590285301208,
      "learning_rate": 6.858813700918965e-06,
      "loss": 0.0366,
      "step": 3760
    },
    {
      "epoch": 0.9448621553884712,
      "grad_norm": 0.3027721643447876,
      "learning_rate": 6.85045948203843e-06,
      "loss": 0.0371,
      "step": 3770
    },
    {
      "epoch": 0.9473684210526315,
      "grad_norm": 1.7562482357025146,
      "learning_rate": 6.842105263157896e-06,
      "loss": 0.0686,
      "step": 3780
    },
    {
      "epoch": 0.949874686716792,
      "grad_norm": 0.1362065225839615,
      "learning_rate": 6.8337510442773605e-06,
      "loss": 0.0303,
      "step": 3790
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.2002398818731308,
      "learning_rate": 6.825396825396826e-06,
      "loss": 0.0312,
      "step": 3800
    },
    {
      "epoch": 0.9548872180451128,
      "grad_norm": 0.22775691747665405,
      "learning_rate": 6.817042606516291e-06,
      "loss": 0.0286,
      "step": 3810
    },
    {
      "epoch": 0.9573934837092731,
      "grad_norm": 0.39093631505966187,
      "learning_rate": 6.808688387635757e-06,
      "loss": 0.05,
      "step": 3820
    },
    {
      "epoch": 0.9598997493734336,
      "grad_norm": 0.8268927931785583,
      "learning_rate": 6.8003341687552216e-06,
      "loss": 0.0358,
      "step": 3830
    },
    {
      "epoch": 0.9624060150375939,
      "grad_norm": 0.23877404630184174,
      "learning_rate": 6.791979949874687e-06,
      "loss": 0.0388,
      "step": 3840
    },
    {
      "epoch": 0.9649122807017544,
      "grad_norm": 0.6266796588897705,
      "learning_rate": 6.783625730994152e-06,
      "loss": 0.0302,
      "step": 3850
    },
    {
      "epoch": 0.9674185463659147,
      "grad_norm": 0.3295767605304718,
      "learning_rate": 6.775271512113618e-06,
      "loss": 0.0427,
      "step": 3860
    },
    {
      "epoch": 0.9699248120300752,
      "grad_norm": 0.24588534235954285,
      "learning_rate": 6.766917293233083e-06,
      "loss": 0.0473,
      "step": 3870
    },
    {
      "epoch": 0.9724310776942355,
      "grad_norm": 0.3437758684158325,
      "learning_rate": 6.758563074352549e-06,
      "loss": 0.0339,
      "step": 3880
    },
    {
      "epoch": 0.974937343358396,
      "grad_norm": 0.6232357621192932,
      "learning_rate": 6.750208855472013e-06,
      "loss": 0.0422,
      "step": 3890
    },
    {
      "epoch": 0.9774436090225563,
      "grad_norm": 0.30568814277648926,
      "learning_rate": 6.74185463659148e-06,
      "loss": 0.0373,
      "step": 3900
    },
    {
      "epoch": 0.9799498746867168,
      "grad_norm": 0.7163788080215454,
      "learning_rate": 6.7335004177109445e-06,
      "loss": 0.0444,
      "step": 3910
    },
    {
      "epoch": 0.9824561403508771,
      "grad_norm": 0.3349212110042572,
      "learning_rate": 6.72514619883041e-06,
      "loss": 0.0525,
      "step": 3920
    },
    {
      "epoch": 0.9849624060150376,
      "grad_norm": 0.44280126690864563,
      "learning_rate": 6.716791979949875e-06,
      "loss": 0.0359,
      "step": 3930
    },
    {
      "epoch": 0.9874686716791979,
      "grad_norm": 0.21476492285728455,
      "learning_rate": 6.708437761069341e-06,
      "loss": 0.0302,
      "step": 3940
    },
    {
      "epoch": 0.9899749373433584,
      "grad_norm": 0.23392868041992188,
      "learning_rate": 6.700083542188806e-06,
      "loss": 0.041,
      "step": 3950
    },
    {
      "epoch": 0.9924812030075187,
      "grad_norm": 0.9477850198745728,
      "learning_rate": 6.691729323308271e-06,
      "loss": 0.0278,
      "step": 3960
    },
    {
      "epoch": 0.9949874686716792,
      "grad_norm": 0.5088475346565247,
      "learning_rate": 6.683375104427736e-06,
      "loss": 0.0297,
      "step": 3970
    },
    {
      "epoch": 0.9974937343358395,
      "grad_norm": 0.25741907954216003,
      "learning_rate": 6.675020885547202e-06,
      "loss": 0.0471,
      "step": 3980
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.924382209777832,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0441,
      "step": 3990
    },
    {
      "epoch": 1.0025062656641603,
      "grad_norm": 1.60616135597229,
      "learning_rate": 6.658312447786132e-06,
      "loss": 0.0437,
      "step": 4000
    },
    {
      "epoch": 1.0025062656641603,
      "eval_loss": 0.04115594923496246,
      "eval_roc_auc_macro": 0.9831501831395227,
      "eval_runtime": 40.2197,
      "eval_samples_per_second": 793.517,
      "eval_steps_per_second": 24.814,
      "step": 4000
    },
    {
      "epoch": 1.0025062656641603,
      "step": 4000,
      "train_loss": 0.03811728581786156,
      "train_roc_auc_macro": 0.987177288915332,
      "train_runtime": 160.1734,
      "train_samples_per_second": 796.986,
      "train_steps_per_second": 24.911
    },
    {
      "epoch": 1.0050125313283207,
      "grad_norm": 0.10593032091856003,
      "learning_rate": 6.649958228905597e-06,
      "loss": 0.0347,
      "step": 4010
    },
    {
      "epoch": 1.0075187969924813,
      "grad_norm": 0.5359533429145813,
      "learning_rate": 6.641604010025064e-06,
      "loss": 0.0358,
      "step": 4020
    },
    {
      "epoch": 1.0100250626566416,
      "grad_norm": 0.1605738401412964,
      "learning_rate": 6.6332497911445286e-06,
      "loss": 0.0371,
      "step": 4030
    },
    {
      "epoch": 1.012531328320802,
      "grad_norm": 0.6040553450584412,
      "learning_rate": 6.624895572263994e-06,
      "loss": 0.0379,
      "step": 4040
    },
    {
      "epoch": 1.0150375939849625,
      "grad_norm": 0.27667659521102905,
      "learning_rate": 6.616541353383459e-06,
      "loss": 0.0345,
      "step": 4050
    },
    {
      "epoch": 1.0175438596491229,
      "grad_norm": 0.23997490108013153,
      "learning_rate": 6.608187134502925e-06,
      "loss": 0.0361,
      "step": 4060
    },
    {
      "epoch": 1.0200501253132832,
      "grad_norm": 0.4629116654396057,
      "learning_rate": 6.59983291562239e-06,
      "loss": 0.0313,
      "step": 4070
    },
    {
      "epoch": 1.0225563909774436,
      "grad_norm": 0.444297730922699,
      "learning_rate": 6.591478696741855e-06,
      "loss": 0.04,
      "step": 4080
    },
    {
      "epoch": 1.025062656641604,
      "grad_norm": 0.6503068804740906,
      "learning_rate": 6.58312447786132e-06,
      "loss": 0.0413,
      "step": 4090
    },
    {
      "epoch": 1.0275689223057645,
      "grad_norm": 0.550023078918457,
      "learning_rate": 6.574770258980786e-06,
      "loss": 0.047,
      "step": 4100
    },
    {
      "epoch": 1.0300751879699248,
      "grad_norm": 0.38836848735809326,
      "learning_rate": 6.566416040100251e-06,
      "loss": 0.0387,
      "step": 4110
    },
    {
      "epoch": 1.0325814536340852,
      "grad_norm": 0.45282837748527527,
      "learning_rate": 6.558061821219716e-06,
      "loss": 0.0299,
      "step": 4120
    },
    {
      "epoch": 1.0350877192982457,
      "grad_norm": 0.5061465501785278,
      "learning_rate": 6.549707602339181e-06,
      "loss": 0.0524,
      "step": 4130
    },
    {
      "epoch": 1.037593984962406,
      "grad_norm": 0.37313079833984375,
      "learning_rate": 6.541353383458648e-06,
      "loss": 0.0368,
      "step": 4140
    },
    {
      "epoch": 1.0401002506265664,
      "grad_norm": 2.068237066268921,
      "learning_rate": 6.532999164578112e-06,
      "loss": 0.0471,
      "step": 4150
    },
    {
      "epoch": 1.0426065162907268,
      "grad_norm": 0.822014570236206,
      "learning_rate": 6.524644945697578e-06,
      "loss": 0.0508,
      "step": 4160
    },
    {
      "epoch": 1.045112781954887,
      "grad_norm": 0.4443384110927582,
      "learning_rate": 6.516290726817043e-06,
      "loss": 0.0392,
      "step": 4170
    },
    {
      "epoch": 1.0476190476190477,
      "grad_norm": 0.11673208326101303,
      "learning_rate": 6.507936507936509e-06,
      "loss": 0.0352,
      "step": 4180
    },
    {
      "epoch": 1.050125313283208,
      "grad_norm": 0.9144834280014038,
      "learning_rate": 6.499582289055974e-06,
      "loss": 0.039,
      "step": 4190
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 1.0214922428131104,
      "learning_rate": 6.491228070175439e-06,
      "loss": 0.0441,
      "step": 4200
    },
    {
      "epoch": 1.055137844611529,
      "grad_norm": 0.26567569375038147,
      "learning_rate": 6.482873851294904e-06,
      "loss": 0.0306,
      "step": 4210
    },
    {
      "epoch": 1.0576441102756893,
      "grad_norm": 0.34778502583503723,
      "learning_rate": 6.47451963241437e-06,
      "loss": 0.0402,
      "step": 4220
    },
    {
      "epoch": 1.0601503759398496,
      "grad_norm": 0.49123266339302063,
      "learning_rate": 6.466165413533835e-06,
      "loss": 0.0316,
      "step": 4230
    },
    {
      "epoch": 1.06265664160401,
      "grad_norm": 0.610453724861145,
      "learning_rate": 6.4578111946533e-06,
      "loss": 0.0596,
      "step": 4240
    },
    {
      "epoch": 1.0651629072681703,
      "grad_norm": 0.41509491205215454,
      "learning_rate": 6.449456975772765e-06,
      "loss": 0.039,
      "step": 4250
    },
    {
      "epoch": 1.0651629072681703,
      "eval_loss": 0.04089737683534622,
      "eval_roc_auc_macro": 0.9847721164043134,
      "eval_runtime": 40.0693,
      "eval_samples_per_second": 796.495,
      "eval_steps_per_second": 24.907,
      "step": 4250
    },
    {
      "epoch": 1.0651629072681703,
      "step": 4250,
      "train_loss": 0.037609443068504333,
      "train_roc_auc_macro": 0.9881841729708004,
      "train_runtime": 160.3264,
      "train_samples_per_second": 796.226,
      "train_steps_per_second": 24.887
    },
    {
      "epoch": 1.0676691729323309,
      "grad_norm": 0.44911694526672363,
      "learning_rate": 6.441102756892231e-06,
      "loss": 0.0436,
      "step": 4260
    },
    {
      "epoch": 1.0701754385964912,
      "grad_norm": 0.6540994048118591,
      "learning_rate": 6.432748538011696e-06,
      "loss": 0.0411,
      "step": 4270
    },
    {
      "epoch": 1.0726817042606516,
      "grad_norm": 0.35898876190185547,
      "learning_rate": 6.424394319131162e-06,
      "loss": 0.0385,
      "step": 4280
    },
    {
      "epoch": 1.0751879699248121,
      "grad_norm": 0.5673819780349731,
      "learning_rate": 6.416040100250627e-06,
      "loss": 0.0519,
      "step": 4290
    },
    {
      "epoch": 1.0776942355889725,
      "grad_norm": 0.08079078793525696,
      "learning_rate": 6.407685881370093e-06,
      "loss": 0.0288,
      "step": 4300
    },
    {
      "epoch": 1.0802005012531328,
      "grad_norm": 0.2324022799730301,
      "learning_rate": 6.399331662489558e-06,
      "loss": 0.0315,
      "step": 4310
    },
    {
      "epoch": 1.0827067669172932,
      "grad_norm": 0.7725433111190796,
      "learning_rate": 6.390977443609023e-06,
      "loss": 0.0345,
      "step": 4320
    },
    {
      "epoch": 1.0852130325814535,
      "grad_norm": 0.6687294244766235,
      "learning_rate": 6.382623224728488e-06,
      "loss": 0.0309,
      "step": 4330
    },
    {
      "epoch": 1.087719298245614,
      "grad_norm": 0.27638688683509827,
      "learning_rate": 6.374269005847954e-06,
      "loss": 0.0272,
      "step": 4340
    },
    {
      "epoch": 1.0902255639097744,
      "grad_norm": 0.873312771320343,
      "learning_rate": 6.365914786967419e-06,
      "loss": 0.0429,
      "step": 4350
    },
    {
      "epoch": 1.0927318295739348,
      "grad_norm": 0.5383234620094299,
      "learning_rate": 6.3575605680868844e-06,
      "loss": 0.0414,
      "step": 4360
    },
    {
      "epoch": 1.0952380952380953,
      "grad_norm": 0.16404461860656738,
      "learning_rate": 6.349206349206349e-06,
      "loss": 0.0392,
      "step": 4370
    },
    {
      "epoch": 1.0977443609022557,
      "grad_norm": 0.5910026431083679,
      "learning_rate": 6.340852130325815e-06,
      "loss": 0.0302,
      "step": 4380
    },
    {
      "epoch": 1.100250626566416,
      "grad_norm": 0.4509510099887848,
      "learning_rate": 6.33249791144528e-06,
      "loss": 0.0386,
      "step": 4390
    },
    {
      "epoch": 1.1027568922305764,
      "grad_norm": 0.6699321269989014,
      "learning_rate": 6.324143692564746e-06,
      "loss": 0.04,
      "step": 4400
    },
    {
      "epoch": 1.1052631578947367,
      "grad_norm": 0.7105019092559814,
      "learning_rate": 6.31578947368421e-06,
      "loss": 0.0348,
      "step": 4410
    },
    {
      "epoch": 1.1077694235588973,
      "grad_norm": 0.353118896484375,
      "learning_rate": 6.307435254803677e-06,
      "loss": 0.0446,
      "step": 4420
    },
    {
      "epoch": 1.1102756892230576,
      "grad_norm": 0.4812457263469696,
      "learning_rate": 6.299081035923142e-06,
      "loss": 0.0385,
      "step": 4430
    },
    {
      "epoch": 1.112781954887218,
      "grad_norm": 0.7750608325004578,
      "learning_rate": 6.290726817042607e-06,
      "loss": 0.0333,
      "step": 4440
    },
    {
      "epoch": 1.1152882205513786,
      "grad_norm": 0.21832586824893951,
      "learning_rate": 6.282372598162072e-06,
      "loss": 0.0267,
      "step": 4450
    },
    {
      "epoch": 1.117794486215539,
      "grad_norm": 0.42593687772750854,
      "learning_rate": 6.274018379281538e-06,
      "loss": 0.0505,
      "step": 4460
    },
    {
      "epoch": 1.1203007518796992,
      "grad_norm": 0.3650740087032318,
      "learning_rate": 6.265664160401003e-06,
      "loss": 0.0422,
      "step": 4470
    },
    {
      "epoch": 1.1228070175438596,
      "grad_norm": 0.2873338758945465,
      "learning_rate": 6.2573099415204685e-06,
      "loss": 0.0361,
      "step": 4480
    },
    {
      "epoch": 1.12531328320802,
      "grad_norm": 0.2623548209667206,
      "learning_rate": 6.248955722639933e-06,
      "loss": 0.0361,
      "step": 4490
    },
    {
      "epoch": 1.1278195488721805,
      "grad_norm": 0.7105318307876587,
      "learning_rate": 6.240601503759399e-06,
      "loss": 0.0466,
      "step": 4500
    },
    {
      "epoch": 1.1278195488721805,
      "eval_loss": 0.03995538502931595,
      "eval_roc_auc_macro": 0.9859805614116516,
      "eval_runtime": 40.1725,
      "eval_samples_per_second": 794.449,
      "eval_steps_per_second": 24.843,
      "step": 4500
    },
    {
      "epoch": 1.1278195488721805,
      "step": 4500,
      "train_loss": 0.03692593425512314,
      "train_roc_auc_macro": 0.9888083159963689,
      "train_runtime": 160.0999,
      "train_samples_per_second": 797.352,
      "train_steps_per_second": 24.922
    },
    {
      "epoch": 1.1303258145363408,
      "grad_norm": 0.9351005554199219,
      "learning_rate": 6.232247284878864e-06,
      "loss": 0.049,
      "step": 4510
    },
    {
      "epoch": 1.1328320802005012,
      "grad_norm": 0.443974107503891,
      "learning_rate": 6.2238930659983295e-06,
      "loss": 0.0335,
      "step": 4520
    },
    {
      "epoch": 1.1353383458646618,
      "grad_norm": 0.35339781641960144,
      "learning_rate": 6.215538847117794e-06,
      "loss": 0.0399,
      "step": 4530
    },
    {
      "epoch": 1.137844611528822,
      "grad_norm": 0.345162034034729,
      "learning_rate": 6.207184628237261e-06,
      "loss": 0.0459,
      "step": 4540
    },
    {
      "epoch": 1.1403508771929824,
      "grad_norm": 0.7051923274993896,
      "learning_rate": 6.198830409356725e-06,
      "loss": 0.0435,
      "step": 4550
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.3358924984931946,
      "learning_rate": 6.1904761904761914e-06,
      "loss": 0.0432,
      "step": 4560
    },
    {
      "epoch": 1.1453634085213031,
      "grad_norm": 0.8656628727912903,
      "learning_rate": 6.182121971595656e-06,
      "loss": 0.0341,
      "step": 4570
    },
    {
      "epoch": 1.1478696741854637,
      "grad_norm": 0.5494139194488525,
      "learning_rate": 6.173767752715122e-06,
      "loss": 0.0349,
      "step": 4580
    },
    {
      "epoch": 1.150375939849624,
      "grad_norm": 0.2667691111564636,
      "learning_rate": 6.165413533834587e-06,
      "loss": 0.0428,
      "step": 4590
    },
    {
      "epoch": 1.1528822055137844,
      "grad_norm": 0.6590185165405273,
      "learning_rate": 6.1570593149540525e-06,
      "loss": 0.0345,
      "step": 4600
    },
    {
      "epoch": 1.155388471177945,
      "grad_norm": 0.1371915191411972,
      "learning_rate": 6.148705096073517e-06,
      "loss": 0.0205,
      "step": 4610
    },
    {
      "epoch": 1.1578947368421053,
      "grad_norm": 0.28042858839035034,
      "learning_rate": 6.140350877192983e-06,
      "loss": 0.0466,
      "step": 4620
    },
    {
      "epoch": 1.1604010025062657,
      "grad_norm": 0.5586515069007874,
      "learning_rate": 6.131996658312448e-06,
      "loss": 0.0543,
      "step": 4630
    },
    {
      "epoch": 1.162907268170426,
      "grad_norm": 0.5110713243484497,
      "learning_rate": 6.1236424394319135e-06,
      "loss": 0.043,
      "step": 4640
    },
    {
      "epoch": 1.1654135338345863,
      "grad_norm": 0.949370801448822,
      "learning_rate": 6.115288220551378e-06,
      "loss": 0.0294,
      "step": 4650
    },
    {
      "epoch": 1.167919799498747,
      "grad_norm": 0.47652971744537354,
      "learning_rate": 6.106934001670844e-06,
      "loss": 0.0458,
      "step": 4660
    },
    {
      "epoch": 1.1704260651629073,
      "grad_norm": 0.2177223563194275,
      "learning_rate": 6.098579782790309e-06,
      "loss": 0.0361,
      "step": 4670
    },
    {
      "epoch": 1.1729323308270676,
      "grad_norm": 0.3461247980594635,
      "learning_rate": 6.0902255639097755e-06,
      "loss": 0.0306,
      "step": 4680
    },
    {
      "epoch": 1.1754385964912282,
      "grad_norm": 0.41509613394737244,
      "learning_rate": 6.08187134502924e-06,
      "loss": 0.031,
      "step": 4690
    },
    {
      "epoch": 1.1779448621553885,
      "grad_norm": 0.37679725885391235,
      "learning_rate": 6.073517126148706e-06,
      "loss": 0.0422,
      "step": 4700
    },
    {
      "epoch": 1.1804511278195489,
      "grad_norm": 0.7310770750045776,
      "learning_rate": 6.065162907268171e-06,
      "loss": 0.0472,
      "step": 4710
    },
    {
      "epoch": 1.1829573934837092,
      "grad_norm": 0.5293043255805969,
      "learning_rate": 6.0568086883876365e-06,
      "loss": 0.0411,
      "step": 4720
    },
    {
      "epoch": 1.1854636591478696,
      "grad_norm": 0.41634058952331543,
      "learning_rate": 6.048454469507101e-06,
      "loss": 0.0503,
      "step": 4730
    },
    {
      "epoch": 1.1879699248120301,
      "grad_norm": 0.35650917887687683,
      "learning_rate": 6.040100250626567e-06,
      "loss": 0.0416,
      "step": 4740
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.2546582818031311,
      "learning_rate": 6.031746031746032e-06,
      "loss": 0.0414,
      "step": 4750
    },
    {
      "epoch": 1.1904761904761905,
      "eval_loss": 0.038807809352874756,
      "eval_roc_auc_macro": 0.9854801842763239,
      "eval_runtime": 40.1557,
      "eval_samples_per_second": 794.782,
      "eval_steps_per_second": 24.853,
      "step": 4750
    },
    {
      "epoch": 1.1904761904761905,
      "step": 4750,
      "train_loss": 0.03544020280241966,
      "train_roc_auc_macro": 0.9883942581987765,
      "train_runtime": 160.271,
      "train_samples_per_second": 796.501,
      "train_steps_per_second": 24.895
    },
    {
      "epoch": 1.1929824561403508,
      "grad_norm": 1.1034667491912842,
      "learning_rate": 6.023391812865498e-06,
      "loss": 0.0278,
      "step": 4760
    },
    {
      "epoch": 1.1954887218045114,
      "grad_norm": 0.2874937653541565,
      "learning_rate": 6.015037593984962e-06,
      "loss": 0.0475,
      "step": 4770
    },
    {
      "epoch": 1.1979949874686717,
      "grad_norm": 0.5901988744735718,
      "learning_rate": 6.006683375104428e-06,
      "loss": 0.0376,
      "step": 4780
    },
    {
      "epoch": 1.200501253132832,
      "grad_norm": 0.40174123644828796,
      "learning_rate": 5.998329156223893e-06,
      "loss": 0.0318,
      "step": 4790
    },
    {
      "epoch": 1.2030075187969924,
      "grad_norm": 0.29789888858795166,
      "learning_rate": 5.9899749373433595e-06,
      "loss": 0.0526,
      "step": 4800
    },
    {
      "epoch": 1.2055137844611528,
      "grad_norm": 0.7703436613082886,
      "learning_rate": 5.9816207184628235e-06,
      "loss": 0.0302,
      "step": 4810
    },
    {
      "epoch": 1.2080200501253133,
      "grad_norm": 0.9085685014724731,
      "learning_rate": 5.97326649958229e-06,
      "loss": 0.0313,
      "step": 4820
    },
    {
      "epoch": 1.2105263157894737,
      "grad_norm": 0.5443141460418701,
      "learning_rate": 5.964912280701755e-06,
      "loss": 0.0611,
      "step": 4830
    },
    {
      "epoch": 1.213032581453634,
      "grad_norm": 0.22715608775615692,
      "learning_rate": 5.9565580618212205e-06,
      "loss": 0.0357,
      "step": 4840
    },
    {
      "epoch": 1.2155388471177946,
      "grad_norm": 0.38736721873283386,
      "learning_rate": 5.948203842940685e-06,
      "loss": 0.0288,
      "step": 4850
    },
    {
      "epoch": 1.218045112781955,
      "grad_norm": 0.7056296467781067,
      "learning_rate": 5.939849624060151e-06,
      "loss": 0.0313,
      "step": 4860
    },
    {
      "epoch": 1.2205513784461153,
      "grad_norm": 0.38322991132736206,
      "learning_rate": 5.931495405179616e-06,
      "loss": 0.0375,
      "step": 4870
    },
    {
      "epoch": 1.2230576441102756,
      "grad_norm": 0.8926964402198792,
      "learning_rate": 5.923141186299082e-06,
      "loss": 0.0416,
      "step": 4880
    },
    {
      "epoch": 1.225563909774436,
      "grad_norm": 0.5865698456764221,
      "learning_rate": 5.9147869674185465e-06,
      "loss": 0.03,
      "step": 4890
    },
    {
      "epoch": 1.2280701754385965,
      "grad_norm": 0.31545543670654297,
      "learning_rate": 5.906432748538012e-06,
      "loss": 0.0325,
      "step": 4900
    },
    {
      "epoch": 1.2305764411027569,
      "grad_norm": 0.5469878315925598,
      "learning_rate": 5.898078529657477e-06,
      "loss": 0.0293,
      "step": 4910
    },
    {
      "epoch": 1.2330827067669172,
      "grad_norm": 0.8019670844078064,
      "learning_rate": 5.889724310776943e-06,
      "loss": 0.0376,
      "step": 4920
    },
    {
      "epoch": 1.2355889724310778,
      "grad_norm": 0.6419510841369629,
      "learning_rate": 5.8813700918964075e-06,
      "loss": 0.0227,
      "step": 4930
    },
    {
      "epoch": 1.2380952380952381,
      "grad_norm": 0.5452134609222412,
      "learning_rate": 5.873015873015874e-06,
      "loss": 0.0365,
      "step": 4940
    },
    {
      "epoch": 1.2406015037593985,
      "grad_norm": 0.7734899520874023,
      "learning_rate": 5.864661654135339e-06,
      "loss": 0.0413,
      "step": 4950
    },
    {
      "epoch": 1.2431077694235588,
      "grad_norm": 0.713344395160675,
      "learning_rate": 5.856307435254805e-06,
      "loss": 0.0475,
      "step": 4960
    },
    {
      "epoch": 1.2456140350877192,
      "grad_norm": 0.5310373306274414,
      "learning_rate": 5.847953216374269e-06,
      "loss": 0.0451,
      "step": 4970
    },
    {
      "epoch": 1.2481203007518797,
      "grad_norm": 0.4203725755214691,
      "learning_rate": 5.839598997493735e-06,
      "loss": 0.0496,
      "step": 4980
    },
    {
      "epoch": 1.25062656641604,
      "grad_norm": 0.3941478431224823,
      "learning_rate": 5.8312447786132e-06,
      "loss": 0.0397,
      "step": 4990
    },
    {
      "epoch": 1.2531328320802004,
      "grad_norm": 0.528763473033905,
      "learning_rate": 5.822890559732666e-06,
      "loss": 0.0261,
      "step": 5000
    },
    {
      "epoch": 1.2531328320802004,
      "eval_loss": 0.03964664787054062,
      "eval_roc_auc_macro": 0.9860241704501984,
      "eval_runtime": 40.228,
      "eval_samples_per_second": 793.353,
      "eval_steps_per_second": 24.809,
      "step": 5000
    },
    {
      "epoch": 1.2531328320802004,
      "step": 5000,
      "train_loss": 0.03584406524896622,
      "train_roc_auc_macro": 0.9891382790092006,
      "train_runtime": 160.2507,
      "train_samples_per_second": 796.602,
      "train_steps_per_second": 24.898
    },
    {
      "epoch": 1.255639097744361,
      "grad_norm": 0.7131903767585754,
      "learning_rate": 5.8145363408521305e-06,
      "loss": 0.0324,
      "step": 5010
    },
    {
      "epoch": 1.2581453634085213,
      "grad_norm": 0.38319897651672363,
      "learning_rate": 5.806182121971596e-06,
      "loss": 0.0502,
      "step": 5020
    },
    {
      "epoch": 1.2606516290726817,
      "grad_norm": 0.4480935335159302,
      "learning_rate": 5.797827903091061e-06,
      "loss": 0.0285,
      "step": 5030
    },
    {
      "epoch": 1.263157894736842,
      "grad_norm": 0.5496437549591064,
      "learning_rate": 5.789473684210527e-06,
      "loss": 0.0436,
      "step": 5040
    },
    {
      "epoch": 1.2656641604010024,
      "grad_norm": 0.5979997515678406,
      "learning_rate": 5.7811194653299915e-06,
      "loss": 0.0396,
      "step": 5050
    },
    {
      "epoch": 1.268170426065163,
      "grad_norm": 0.1841614842414856,
      "learning_rate": 5.772765246449458e-06,
      "loss": 0.0334,
      "step": 5060
    },
    {
      "epoch": 1.2706766917293233,
      "grad_norm": 0.8262642621994019,
      "learning_rate": 5.764411027568922e-06,
      "loss": 0.0373,
      "step": 5070
    },
    {
      "epoch": 1.2731829573934836,
      "grad_norm": 0.38595667481422424,
      "learning_rate": 5.756056808688389e-06,
      "loss": 0.032,
      "step": 5080
    },
    {
      "epoch": 1.2756892230576442,
      "grad_norm": 0.42558929324150085,
      "learning_rate": 5.7477025898078535e-06,
      "loss": 0.0401,
      "step": 5090
    },
    {
      "epoch": 1.2781954887218046,
      "grad_norm": 0.30714839696884155,
      "learning_rate": 5.739348370927319e-06,
      "loss": 0.0283,
      "step": 5100
    },
    {
      "epoch": 1.280701754385965,
      "grad_norm": 0.48658615350723267,
      "learning_rate": 5.730994152046784e-06,
      "loss": 0.053,
      "step": 5110
    },
    {
      "epoch": 1.2832080200501252,
      "grad_norm": 0.2957853078842163,
      "learning_rate": 5.72263993316625e-06,
      "loss": 0.0338,
      "step": 5120
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 0.6087131500244141,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.0354,
      "step": 5130
    },
    {
      "epoch": 1.2882205513784462,
      "grad_norm": 0.4223099946975708,
      "learning_rate": 5.70593149540518e-06,
      "loss": 0.0358,
      "step": 5140
    },
    {
      "epoch": 1.2907268170426065,
      "grad_norm": 0.9180358648300171,
      "learning_rate": 5.697577276524645e-06,
      "loss": 0.0373,
      "step": 5150
    },
    {
      "epoch": 1.2932330827067668,
      "grad_norm": 0.1786094605922699,
      "learning_rate": 5.689223057644111e-06,
      "loss": 0.0386,
      "step": 5160
    },
    {
      "epoch": 1.2957393483709274,
      "grad_norm": 0.5626984238624573,
      "learning_rate": 5.6808688387635756e-06,
      "loss": 0.0245,
      "step": 5170
    },
    {
      "epoch": 1.2982456140350878,
      "grad_norm": 0.39133599400520325,
      "learning_rate": 5.672514619883041e-06,
      "loss": 0.0505,
      "step": 5180
    },
    {
      "epoch": 1.300751879699248,
      "grad_norm": 0.6246192455291748,
      "learning_rate": 5.664160401002506e-06,
      "loss": 0.0364,
      "step": 5190
    },
    {
      "epoch": 1.3032581453634084,
      "grad_norm": 0.558137834072113,
      "learning_rate": 5.655806182121973e-06,
      "loss": 0.0456,
      "step": 5200
    },
    {
      "epoch": 1.3057644110275688,
      "grad_norm": 0.39758574962615967,
      "learning_rate": 5.6474519632414375e-06,
      "loss": 0.0404,
      "step": 5210
    },
    {
      "epoch": 1.3082706766917294,
      "grad_norm": 0.6387336850166321,
      "learning_rate": 5.639097744360903e-06,
      "loss": 0.0493,
      "step": 5220
    },
    {
      "epoch": 1.3107769423558897,
      "grad_norm": 0.44316810369491577,
      "learning_rate": 5.630743525480368e-06,
      "loss": 0.0436,
      "step": 5230
    },
    {
      "epoch": 1.31328320802005,
      "grad_norm": 0.2908712923526764,
      "learning_rate": 5.622389306599834e-06,
      "loss": 0.0522,
      "step": 5240
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.4934121370315552,
      "learning_rate": 5.6140350877192985e-06,
      "loss": 0.0308,
      "step": 5250
    },
    {
      "epoch": 1.3157894736842106,
      "eval_loss": 0.04206966981291771,
      "eval_roc_auc_macro": 0.9865953325633511,
      "eval_runtime": 40.1922,
      "eval_samples_per_second": 794.06,
      "eval_steps_per_second": 24.831,
      "step": 5250
    },
    {
      "epoch": 1.3157894736842106,
      "step": 5250,
      "train_loss": 0.03830718249082565,
      "train_roc_auc_macro": 0.9897017955759656,
      "train_runtime": 160.0034,
      "train_samples_per_second": 797.833,
      "train_steps_per_second": 24.937
    },
    {
      "epoch": 1.318295739348371,
      "grad_norm": 0.33513179421424866,
      "learning_rate": 5.605680868838764e-06,
      "loss": 0.0295,
      "step": 5260
    },
    {
      "epoch": 1.3208020050125313,
      "grad_norm": 0.6574573516845703,
      "learning_rate": 5.597326649958229e-06,
      "loss": 0.0447,
      "step": 5270
    },
    {
      "epoch": 1.3233082706766917,
      "grad_norm": 0.2803061902523041,
      "learning_rate": 5.588972431077695e-06,
      "loss": 0.0369,
      "step": 5280
    },
    {
      "epoch": 1.325814536340852,
      "grad_norm": 0.420003741979599,
      "learning_rate": 5.58061821219716e-06,
      "loss": 0.0369,
      "step": 5290
    },
    {
      "epoch": 1.3283208020050126,
      "grad_norm": 0.4496005177497864,
      "learning_rate": 5.572263993316625e-06,
      "loss": 0.0362,
      "step": 5300
    },
    {
      "epoch": 1.330827067669173,
      "grad_norm": 0.4954705238342285,
      "learning_rate": 5.56390977443609e-06,
      "loss": 0.0393,
      "step": 5310
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.4314749836921692,
      "learning_rate": 5.555555555555557e-06,
      "loss": 0.0471,
      "step": 5320
    },
    {
      "epoch": 1.3358395989974938,
      "grad_norm": 0.3061811923980713,
      "learning_rate": 5.547201336675021e-06,
      "loss": 0.0332,
      "step": 5330
    },
    {
      "epoch": 1.3383458646616542,
      "grad_norm": 1.6301710605621338,
      "learning_rate": 5.538847117794487e-06,
      "loss": 0.0401,
      "step": 5340
    },
    {
      "epoch": 1.3408521303258145,
      "grad_norm": 0.20087657868862152,
      "learning_rate": 5.530492898913952e-06,
      "loss": 0.0359,
      "step": 5350
    },
    {
      "epoch": 1.3433583959899749,
      "grad_norm": 0.5196796655654907,
      "learning_rate": 5.522138680033418e-06,
      "loss": 0.0414,
      "step": 5360
    },
    {
      "epoch": 1.3458646616541352,
      "grad_norm": 0.3453580439090729,
      "learning_rate": 5.5137844611528826e-06,
      "loss": 0.0419,
      "step": 5370
    },
    {
      "epoch": 1.3483709273182958,
      "grad_norm": 0.5136286616325378,
      "learning_rate": 5.505430242272348e-06,
      "loss": 0.0469,
      "step": 5380
    },
    {
      "epoch": 1.3508771929824561,
      "grad_norm": 0.1720656156539917,
      "learning_rate": 5.497076023391813e-06,
      "loss": 0.0353,
      "step": 5390
    },
    {
      "epoch": 1.3533834586466165,
      "grad_norm": 0.49260419607162476,
      "learning_rate": 5.488721804511279e-06,
      "loss": 0.0372,
      "step": 5400
    },
    {
      "epoch": 1.355889724310777,
      "grad_norm": 0.3215458393096924,
      "learning_rate": 5.480367585630744e-06,
      "loss": 0.0317,
      "step": 5410
    },
    {
      "epoch": 1.3583959899749374,
      "grad_norm": 0.6177852749824524,
      "learning_rate": 5.472013366750209e-06,
      "loss": 0.0434,
      "step": 5420
    },
    {
      "epoch": 1.3609022556390977,
      "grad_norm": 0.6028414964675903,
      "learning_rate": 5.463659147869674e-06,
      "loss": 0.0303,
      "step": 5430
    },
    {
      "epoch": 1.363408521303258,
      "grad_norm": 0.3260034918785095,
      "learning_rate": 5.45530492898914e-06,
      "loss": 0.0328,
      "step": 5440
    },
    {
      "epoch": 1.3659147869674184,
      "grad_norm": 0.44532716274261475,
      "learning_rate": 5.446950710108605e-06,
      "loss": 0.0451,
      "step": 5450
    },
    {
      "epoch": 1.368421052631579,
      "grad_norm": 0.9451978802680969,
      "learning_rate": 5.438596491228071e-06,
      "loss": 0.0446,
      "step": 5460
    },
    {
      "epoch": 1.3709273182957393,
      "grad_norm": 0.212340846657753,
      "learning_rate": 5.430242272347536e-06,
      "loss": 0.0218,
      "step": 5470
    },
    {
      "epoch": 1.3734335839598997,
      "grad_norm": 0.4850262999534607,
      "learning_rate": 5.421888053467002e-06,
      "loss": 0.0397,
      "step": 5480
    },
    {
      "epoch": 1.3759398496240602,
      "grad_norm": 0.17490758001804352,
      "learning_rate": 5.413533834586467e-06,
      "loss": 0.0307,
      "step": 5490
    },
    {
      "epoch": 1.3784461152882206,
      "grad_norm": 0.6409964561462402,
      "learning_rate": 5.405179615705932e-06,
      "loss": 0.0443,
      "step": 5500
    },
    {
      "epoch": 1.3784461152882206,
      "eval_loss": 0.03968143090605736,
      "eval_roc_auc_macro": 0.9853457417871186,
      "eval_runtime": 40.1891,
      "eval_samples_per_second": 794.121,
      "eval_steps_per_second": 24.833,
      "step": 5500
    },
    {
      "epoch": 1.3784461152882206,
      "step": 5500,
      "train_loss": 0.035444796085357666,
      "train_roc_auc_macro": 0.9896011400768229,
      "train_runtime": 160.0856,
      "train_samples_per_second": 797.423,
      "train_steps_per_second": 24.924
    },
    {
      "epoch": 1.380952380952381,
      "grad_norm": 0.6114229559898376,
      "learning_rate": 5.396825396825397e-06,
      "loss": 0.0409,
      "step": 5510
    },
    {
      "epoch": 1.3834586466165413,
      "grad_norm": 0.23755857348442078,
      "learning_rate": 5.388471177944863e-06,
      "loss": 0.0305,
      "step": 5520
    },
    {
      "epoch": 1.3859649122807016,
      "grad_norm": 0.1919381022453308,
      "learning_rate": 5.380116959064328e-06,
      "loss": 0.0382,
      "step": 5530
    },
    {
      "epoch": 1.3884711779448622,
      "grad_norm": 0.19997845590114594,
      "learning_rate": 5.371762740183793e-06,
      "loss": 0.0394,
      "step": 5540
    },
    {
      "epoch": 1.3909774436090225,
      "grad_norm": 0.2228892296552658,
      "learning_rate": 5.363408521303258e-06,
      "loss": 0.0305,
      "step": 5550
    },
    {
      "epoch": 1.3934837092731829,
      "grad_norm": 0.26823103427886963,
      "learning_rate": 5.355054302422724e-06,
      "loss": 0.0379,
      "step": 5560
    },
    {
      "epoch": 1.3959899749373434,
      "grad_norm": 0.19619131088256836,
      "learning_rate": 5.346700083542189e-06,
      "loss": 0.0281,
      "step": 5570
    },
    {
      "epoch": 1.3984962406015038,
      "grad_norm": 1.0017380714416504,
      "learning_rate": 5.338345864661654e-06,
      "loss": 0.04,
      "step": 5580
    },
    {
      "epoch": 1.4010025062656641,
      "grad_norm": 0.5239142179489136,
      "learning_rate": 5.329991645781119e-06,
      "loss": 0.0461,
      "step": 5590
    },
    {
      "epoch": 1.4035087719298245,
      "grad_norm": 0.6179717183113098,
      "learning_rate": 5.321637426900586e-06,
      "loss": 0.0409,
      "step": 5600
    },
    {
      "epoch": 1.4060150375939848,
      "grad_norm": 0.40757161378860474,
      "learning_rate": 5.313283208020051e-06,
      "loss": 0.0327,
      "step": 5610
    },
    {
      "epoch": 1.4085213032581454,
      "grad_norm": 0.519496500492096,
      "learning_rate": 5.304928989139516e-06,
      "loss": 0.0332,
      "step": 5620
    },
    {
      "epoch": 1.4110275689223057,
      "grad_norm": 0.5821967720985413,
      "learning_rate": 5.296574770258981e-06,
      "loss": 0.038,
      "step": 5630
    },
    {
      "epoch": 1.413533834586466,
      "grad_norm": 0.4291169345378876,
      "learning_rate": 5.288220551378447e-06,
      "loss": 0.0219,
      "step": 5640
    },
    {
      "epoch": 1.4160401002506267,
      "grad_norm": 0.10337255150079727,
      "learning_rate": 5.279866332497912e-06,
      "loss": 0.0295,
      "step": 5650
    },
    {
      "epoch": 1.418546365914787,
      "grad_norm": 0.52571702003479,
      "learning_rate": 5.271512113617377e-06,
      "loss": 0.0462,
      "step": 5660
    },
    {
      "epoch": 1.4210526315789473,
      "grad_norm": 0.25505784153938293,
      "learning_rate": 5.263157894736842e-06,
      "loss": 0.0346,
      "step": 5670
    },
    {
      "epoch": 1.4235588972431077,
      "grad_norm": 0.6769277453422546,
      "learning_rate": 5.254803675856308e-06,
      "loss": 0.0364,
      "step": 5680
    },
    {
      "epoch": 1.426065162907268,
      "grad_norm": 0.4602262079715729,
      "learning_rate": 5.246449456975773e-06,
      "loss": 0.0408,
      "step": 5690
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 1.0045559406280518,
      "learning_rate": 5.2380952380952384e-06,
      "loss": 0.0393,
      "step": 5700
    },
    {
      "epoch": 1.431077694235589,
      "grad_norm": 0.7763682007789612,
      "learning_rate": 5.229741019214703e-06,
      "loss": 0.053,
      "step": 5710
    },
    {
      "epoch": 1.4335839598997493,
      "grad_norm": 0.481310099363327,
      "learning_rate": 5.22138680033417e-06,
      "loss": 0.0344,
      "step": 5720
    },
    {
      "epoch": 1.4360902255639099,
      "grad_norm": 0.17809134721755981,
      "learning_rate": 5.213032581453634e-06,
      "loss": 0.0343,
      "step": 5730
    },
    {
      "epoch": 1.4385964912280702,
      "grad_norm": 0.5606309771537781,
      "learning_rate": 5.2046783625731e-06,
      "loss": 0.0489,
      "step": 5740
    },
    {
      "epoch": 1.4411027568922306,
      "grad_norm": 0.3610530197620392,
      "learning_rate": 5.196324143692565e-06,
      "loss": 0.02,
      "step": 5750
    },
    {
      "epoch": 1.4411027568922306,
      "eval_loss": 0.039903976023197174,
      "eval_roc_auc_macro": 0.9845801075283869,
      "eval_runtime": 40.2045,
      "eval_samples_per_second": 793.817,
      "eval_steps_per_second": 24.823,
      "step": 5750
    },
    {
      "epoch": 1.4411027568922306,
      "step": 5750,
      "train_loss": 0.03538377583026886,
      "train_roc_auc_macro": 0.9896859767185009,
      "train_runtime": 160.2263,
      "train_samples_per_second": 796.723,
      "train_steps_per_second": 24.902
    },
    {
      "epoch": 1.443609022556391,
      "grad_norm": 0.6385169625282288,
      "learning_rate": 5.187969924812031e-06,
      "loss": 0.0369,
      "step": 5760
    },
    {
      "epoch": 1.4461152882205512,
      "grad_norm": 0.28732529282569885,
      "learning_rate": 5.179615705931496e-06,
      "loss": 0.0321,
      "step": 5770
    },
    {
      "epoch": 1.4486215538847118,
      "grad_norm": 0.3401712477207184,
      "learning_rate": 5.171261487050961e-06,
      "loss": 0.0335,
      "step": 5780
    },
    {
      "epoch": 1.4511278195488722,
      "grad_norm": 0.5479459166526794,
      "learning_rate": 5.162907268170426e-06,
      "loss": 0.0448,
      "step": 5790
    },
    {
      "epoch": 1.4536340852130325,
      "grad_norm": 0.5455952882766724,
      "learning_rate": 5.154553049289892e-06,
      "loss": 0.0291,
      "step": 5800
    },
    {
      "epoch": 1.456140350877193,
      "grad_norm": 0.5187066197395325,
      "learning_rate": 5.146198830409357e-06,
      "loss": 0.0337,
      "step": 5810
    },
    {
      "epoch": 1.4586466165413534,
      "grad_norm": 0.7873586416244507,
      "learning_rate": 5.1378446115288225e-06,
      "loss": 0.0308,
      "step": 5820
    },
    {
      "epoch": 1.4611528822055138,
      "grad_norm": 0.5845922827720642,
      "learning_rate": 5.129490392648287e-06,
      "loss": 0.0375,
      "step": 5830
    },
    {
      "epoch": 1.463659147869674,
      "grad_norm": 0.7200717329978943,
      "learning_rate": 5.121136173767753e-06,
      "loss": 0.0319,
      "step": 5840
    },
    {
      "epoch": 1.4661654135338344,
      "grad_norm": 0.46498605608940125,
      "learning_rate": 5.112781954887218e-06,
      "loss": 0.0295,
      "step": 5850
    },
    {
      "epoch": 1.468671679197995,
      "grad_norm": 0.4670170247554779,
      "learning_rate": 5.104427736006684e-06,
      "loss": 0.04,
      "step": 5860
    },
    {
      "epoch": 1.4711779448621554,
      "grad_norm": 0.6895639896392822,
      "learning_rate": 5.096073517126149e-06,
      "loss": 0.0318,
      "step": 5870
    },
    {
      "epoch": 1.4736842105263157,
      "grad_norm": 0.6767656803131104,
      "learning_rate": 5.087719298245615e-06,
      "loss": 0.0442,
      "step": 5880
    },
    {
      "epoch": 1.4761904761904763,
      "grad_norm": 0.20398837327957153,
      "learning_rate": 5.07936507936508e-06,
      "loss": 0.0327,
      "step": 5890
    },
    {
      "epoch": 1.4786967418546366,
      "grad_norm": 0.5957716703414917,
      "learning_rate": 5.0710108604845454e-06,
      "loss": 0.0323,
      "step": 5900
    },
    {
      "epoch": 1.481203007518797,
      "grad_norm": 0.6301584839820862,
      "learning_rate": 5.06265664160401e-06,
      "loss": 0.0407,
      "step": 5910
    },
    {
      "epoch": 1.4837092731829573,
      "grad_norm": 0.7761169672012329,
      "learning_rate": 5.054302422723476e-06,
      "loss": 0.0278,
      "step": 5920
    },
    {
      "epoch": 1.4862155388471177,
      "grad_norm": 0.15305182337760925,
      "learning_rate": 5.045948203842941e-06,
      "loss": 0.0407,
      "step": 5930
    },
    {
      "epoch": 1.4887218045112782,
      "grad_norm": 0.579551637172699,
      "learning_rate": 5.0375939849624065e-06,
      "loss": 0.0475,
      "step": 5940
    },
    {
      "epoch": 1.4912280701754386,
      "grad_norm": 0.11874359846115112,
      "learning_rate": 5.029239766081871e-06,
      "loss": 0.0404,
      "step": 5950
    },
    {
      "epoch": 1.493734335839599,
      "grad_norm": 0.30604618787765503,
      "learning_rate": 5.020885547201337e-06,
      "loss": 0.0247,
      "step": 5960
    },
    {
      "epoch": 1.4962406015037595,
      "grad_norm": 0.6977025866508484,
      "learning_rate": 5.012531328320802e-06,
      "loss": 0.0479,
      "step": 5970
    },
    {
      "epoch": 1.4987468671679198,
      "grad_norm": 0.28209009766578674,
      "learning_rate": 5.004177109440268e-06,
      "loss": 0.0284,
      "step": 5980
    },
    {
      "epoch": 1.5012531328320802,
      "grad_norm": 0.7520999908447266,
      "learning_rate": 4.995822890559732e-06,
      "loss": 0.0398,
      "step": 5990
    },
    {
      "epoch": 1.5037593984962405,
      "grad_norm": 1.1097023487091064,
      "learning_rate": 4.987468671679198e-06,
      "loss": 0.0358,
      "step": 6000
    },
    {
      "epoch": 1.5037593984962405,
      "eval_loss": 0.0409860834479332,
      "eval_roc_auc_macro": 0.9869567503056947,
      "eval_runtime": 40.1939,
      "eval_samples_per_second": 794.025,
      "eval_steps_per_second": 24.83,
      "step": 6000
    },
    {
      "epoch": 1.5037593984962405,
      "step": 6000,
      "train_loss": 0.037154607474803925,
      "train_roc_auc_macro": 0.9906417882081224,
      "train_runtime": 160.2934,
      "train_samples_per_second": 796.39,
      "train_steps_per_second": 24.892
    },
    {
      "epoch": 1.5062656641604009,
      "grad_norm": 0.3732151687145233,
      "learning_rate": 4.979114452798664e-06,
      "loss": 0.0328,
      "step": 6010
    },
    {
      "epoch": 1.5087719298245614,
      "grad_norm": 0.38838040828704834,
      "learning_rate": 4.970760233918129e-06,
      "loss": 0.0391,
      "step": 6020
    },
    {
      "epoch": 1.5112781954887218,
      "grad_norm": 0.5215326547622681,
      "learning_rate": 4.962406015037594e-06,
      "loss": 0.0354,
      "step": 6030
    },
    {
      "epoch": 1.5137844611528823,
      "grad_norm": 0.11613767594099045,
      "learning_rate": 4.954051796157059e-06,
      "loss": 0.039,
      "step": 6040
    },
    {
      "epoch": 1.5162907268170427,
      "grad_norm": 0.18948966264724731,
      "learning_rate": 4.945697577276525e-06,
      "loss": 0.0336,
      "step": 6050
    },
    {
      "epoch": 1.518796992481203,
      "grad_norm": 0.7747156620025635,
      "learning_rate": 4.93734335839599e-06,
      "loss": 0.0508,
      "step": 6060
    },
    {
      "epoch": 1.5213032581453634,
      "grad_norm": 0.19683896005153656,
      "learning_rate": 4.928989139515455e-06,
      "loss": 0.0432,
      "step": 6070
    },
    {
      "epoch": 1.5238095238095237,
      "grad_norm": 0.5484482645988464,
      "learning_rate": 4.920634920634921e-06,
      "loss": 0.0393,
      "step": 6080
    },
    {
      "epoch": 1.526315789473684,
      "grad_norm": 0.4558628797531128,
      "learning_rate": 4.912280701754386e-06,
      "loss": 0.0361,
      "step": 6090
    },
    {
      "epoch": 1.5288220551378446,
      "grad_norm": 0.1984216570854187,
      "learning_rate": 4.903926482873852e-06,
      "loss": 0.034,
      "step": 6100
    },
    {
      "epoch": 1.531328320802005,
      "grad_norm": 0.5402638912200928,
      "learning_rate": 4.8955722639933164e-06,
      "loss": 0.0403,
      "step": 6110
    },
    {
      "epoch": 1.5338345864661656,
      "grad_norm": 0.5949575901031494,
      "learning_rate": 4.887218045112782e-06,
      "loss": 0.043,
      "step": 6120
    },
    {
      "epoch": 1.536340852130326,
      "grad_norm": 0.5415880084037781,
      "learning_rate": 4.878863826232248e-06,
      "loss": 0.0369,
      "step": 6130
    },
    {
      "epoch": 1.5388471177944862,
      "grad_norm": 0.18126283586025238,
      "learning_rate": 4.870509607351713e-06,
      "loss": 0.0408,
      "step": 6140
    },
    {
      "epoch": 1.5413533834586466,
      "grad_norm": 0.41373786330223083,
      "learning_rate": 4.862155388471178e-06,
      "loss": 0.0312,
      "step": 6150
    },
    {
      "epoch": 1.543859649122807,
      "grad_norm": 0.3146141767501831,
      "learning_rate": 4.853801169590643e-06,
      "loss": 0.0358,
      "step": 6160
    },
    {
      "epoch": 1.5463659147869673,
      "grad_norm": 0.2629549205303192,
      "learning_rate": 4.845446950710109e-06,
      "loss": 0.0282,
      "step": 6170
    },
    {
      "epoch": 1.5488721804511278,
      "grad_norm": 0.7734293937683105,
      "learning_rate": 4.837092731829574e-06,
      "loss": 0.031,
      "step": 6180
    },
    {
      "epoch": 1.5513784461152882,
      "grad_norm": 0.24993814527988434,
      "learning_rate": 4.828738512949039e-06,
      "loss": 0.0495,
      "step": 6190
    },
    {
      "epoch": 1.5538847117794488,
      "grad_norm": 0.41118451952934265,
      "learning_rate": 4.820384294068505e-06,
      "loss": 0.0275,
      "step": 6200
    },
    {
      "epoch": 1.556390977443609,
      "grad_norm": 0.15836745500564575,
      "learning_rate": 4.81203007518797e-06,
      "loss": 0.0335,
      "step": 6210
    },
    {
      "epoch": 1.5588972431077694,
      "grad_norm": 0.3075869381427765,
      "learning_rate": 4.803675856307436e-06,
      "loss": 0.0405,
      "step": 6220
    },
    {
      "epoch": 1.5614035087719298,
      "grad_norm": 0.3796432316303253,
      "learning_rate": 4.7953216374269005e-06,
      "loss": 0.0294,
      "step": 6230
    },
    {
      "epoch": 1.5639097744360901,
      "grad_norm": 0.513130784034729,
      "learning_rate": 4.786967418546366e-06,
      "loss": 0.0352,
      "step": 6240
    },
    {
      "epoch": 1.5664160401002505,
      "grad_norm": 0.7986907362937927,
      "learning_rate": 4.778613199665831e-06,
      "loss": 0.0403,
      "step": 6250
    },
    {
      "epoch": 1.5664160401002505,
      "eval_loss": 0.03996559605002403,
      "eval_roc_auc_macro": 0.9865041726222806,
      "eval_runtime": 40.2255,
      "eval_samples_per_second": 793.403,
      "eval_steps_per_second": 24.81,
      "step": 6250
    },
    {
      "epoch": 1.5664160401002505,
      "step": 6250,
      "train_loss": 0.03547932580113411,
      "train_roc_auc_macro": 0.9908730499439128,
      "train_runtime": 160.0863,
      "train_samples_per_second": 797.42,
      "train_steps_per_second": 24.924
    },
    {
      "epoch": 1.568922305764411,
      "grad_norm": 0.623877227306366,
      "learning_rate": 4.770258980785297e-06,
      "loss": 0.0427,
      "step": 6260
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.6432142853736877,
      "learning_rate": 4.761904761904762e-06,
      "loss": 0.0367,
      "step": 6270
    },
    {
      "epoch": 1.573934837092732,
      "grad_norm": 0.306066632270813,
      "learning_rate": 4.753550543024227e-06,
      "loss": 0.0343,
      "step": 6280
    },
    {
      "epoch": 1.5764411027568923,
      "grad_norm": 0.4886915683746338,
      "learning_rate": 4.745196324143693e-06,
      "loss": 0.0405,
      "step": 6290
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 0.14046582579612732,
      "learning_rate": 4.736842105263158e-06,
      "loss": 0.0341,
      "step": 6300
    },
    {
      "epoch": 1.581453634085213,
      "grad_norm": 0.345184326171875,
      "learning_rate": 4.7284878863826234e-06,
      "loss": 0.0306,
      "step": 6310
    },
    {
      "epoch": 1.5839598997493733,
      "grad_norm": 0.41988348960876465,
      "learning_rate": 4.720133667502088e-06,
      "loss": 0.0355,
      "step": 6320
    },
    {
      "epoch": 1.5864661654135337,
      "grad_norm": 0.264298677444458,
      "learning_rate": 4.711779448621554e-06,
      "loss": 0.0262,
      "step": 6330
    },
    {
      "epoch": 1.5889724310776943,
      "grad_norm": 0.9342249631881714,
      "learning_rate": 4.70342522974102e-06,
      "loss": 0.0399,
      "step": 6340
    },
    {
      "epoch": 1.5914786967418546,
      "grad_norm": 0.5841417908668518,
      "learning_rate": 4.6950710108604845e-06,
      "loss": 0.0324,
      "step": 6350
    },
    {
      "epoch": 1.5939849624060152,
      "grad_norm": 0.31177687644958496,
      "learning_rate": 4.68671679197995e-06,
      "loss": 0.0315,
      "step": 6360
    },
    {
      "epoch": 1.5964912280701755,
      "grad_norm": 0.1346481442451477,
      "learning_rate": 4.678362573099415e-06,
      "loss": 0.0383,
      "step": 6370
    },
    {
      "epoch": 1.5989974937343359,
      "grad_norm": 0.279551237821579,
      "learning_rate": 4.670008354218881e-06,
      "loss": 0.0199,
      "step": 6380
    },
    {
      "epoch": 1.6015037593984962,
      "grad_norm": 1.107265830039978,
      "learning_rate": 4.661654135338346e-06,
      "loss": 0.0406,
      "step": 6390
    },
    {
      "epoch": 1.6040100250626566,
      "grad_norm": 0.3139740526676178,
      "learning_rate": 4.653299916457811e-06,
      "loss": 0.032,
      "step": 6400
    },
    {
      "epoch": 1.606516290726817,
      "grad_norm": 0.16418316960334778,
      "learning_rate": 4.644945697577277e-06,
      "loss": 0.0384,
      "step": 6410
    },
    {
      "epoch": 1.6090225563909775,
      "grad_norm": 0.4688531160354614,
      "learning_rate": 4.636591478696742e-06,
      "loss": 0.0308,
      "step": 6420
    },
    {
      "epoch": 1.6115288220551378,
      "grad_norm": 0.6823702454566956,
      "learning_rate": 4.6282372598162075e-06,
      "loss": 0.0411,
      "step": 6430
    },
    {
      "epoch": 1.6140350877192984,
      "grad_norm": 0.5115843415260315,
      "learning_rate": 4.619883040935672e-06,
      "loss": 0.0317,
      "step": 6440
    },
    {
      "epoch": 1.6165413533834587,
      "grad_norm": 0.5331199169158936,
      "learning_rate": 4.611528822055138e-06,
      "loss": 0.0367,
      "step": 6450
    },
    {
      "epoch": 1.619047619047619,
      "grad_norm": 0.36198949813842773,
      "learning_rate": 4.603174603174604e-06,
      "loss": 0.0433,
      "step": 6460
    },
    {
      "epoch": 1.6215538847117794,
      "grad_norm": 0.7380414605140686,
      "learning_rate": 4.5948203842940685e-06,
      "loss": 0.0389,
      "step": 6470
    },
    {
      "epoch": 1.6240601503759398,
      "grad_norm": 0.249741330742836,
      "learning_rate": 4.586466165413534e-06,
      "loss": 0.0385,
      "step": 6480
    },
    {
      "epoch": 1.6265664160401,
      "grad_norm": 1.1020216941833496,
      "learning_rate": 4.578111946532999e-06,
      "loss": 0.0421,
      "step": 6490
    },
    {
      "epoch": 1.6290726817042607,
      "grad_norm": 0.5480701923370361,
      "learning_rate": 4.569757727652465e-06,
      "loss": 0.0388,
      "step": 6500
    },
    {
      "epoch": 1.6290726817042607,
      "eval_loss": 0.03850414976477623,
      "eval_roc_auc_macro": 0.9869917532228362,
      "eval_runtime": 40.1846,
      "eval_samples_per_second": 794.21,
      "eval_steps_per_second": 24.835,
      "step": 6500
    },
    {
      "epoch": 1.6290726817042607,
      "step": 6500,
      "train_loss": 0.033969055861234665,
      "train_roc_auc_macro": 0.990847973085244,
      "train_runtime": 160.2121,
      "train_samples_per_second": 796.794,
      "train_steps_per_second": 24.904
    },
    {
      "epoch": 1.631578947368421,
      "grad_norm": 0.2786504030227661,
      "learning_rate": 4.56140350877193e-06,
      "loss": 0.031,
      "step": 6510
    },
    {
      "epoch": 1.6340852130325816,
      "grad_norm": 0.23724599182605743,
      "learning_rate": 4.553049289891395e-06,
      "loss": 0.0412,
      "step": 6520
    },
    {
      "epoch": 1.636591478696742,
      "grad_norm": 0.31841418147087097,
      "learning_rate": 4.544695071010861e-06,
      "loss": 0.0334,
      "step": 6530
    },
    {
      "epoch": 1.6390977443609023,
      "grad_norm": 0.18745490908622742,
      "learning_rate": 4.536340852130326e-06,
      "loss": 0.0309,
      "step": 6540
    },
    {
      "epoch": 1.6416040100250626,
      "grad_norm": 0.1537451446056366,
      "learning_rate": 4.5279866332497915e-06,
      "loss": 0.0326,
      "step": 6550
    },
    {
      "epoch": 1.644110275689223,
      "grad_norm": 0.4966470003128052,
      "learning_rate": 4.519632414369256e-06,
      "loss": 0.0489,
      "step": 6560
    },
    {
      "epoch": 1.6466165413533833,
      "grad_norm": 0.6892217993736267,
      "learning_rate": 4.511278195488722e-06,
      "loss": 0.0339,
      "step": 6570
    },
    {
      "epoch": 1.6491228070175439,
      "grad_norm": 0.22660768032073975,
      "learning_rate": 4.502923976608187e-06,
      "loss": 0.0315,
      "step": 6580
    },
    {
      "epoch": 1.6516290726817042,
      "grad_norm": 0.35209041833877563,
      "learning_rate": 4.4945697577276526e-06,
      "loss": 0.0293,
      "step": 6590
    },
    {
      "epoch": 1.6541353383458648,
      "grad_norm": 0.1429436355829239,
      "learning_rate": 4.486215538847118e-06,
      "loss": 0.0351,
      "step": 6600
    },
    {
      "epoch": 1.6566416040100251,
      "grad_norm": 0.33598875999450684,
      "learning_rate": 4.477861319966583e-06,
      "loss": 0.0383,
      "step": 6610
    },
    {
      "epoch": 1.6591478696741855,
      "grad_norm": 0.42905673384666443,
      "learning_rate": 4.469507101086049e-06,
      "loss": 0.0395,
      "step": 6620
    },
    {
      "epoch": 1.6616541353383458,
      "grad_norm": 0.5816851258277893,
      "learning_rate": 4.461152882205514e-06,
      "loss": 0.0358,
      "step": 6630
    },
    {
      "epoch": 1.6641604010025062,
      "grad_norm": 0.8874650001525879,
      "learning_rate": 4.452798663324979e-06,
      "loss": 0.04,
      "step": 6640
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.31470227241516113,
      "learning_rate": 4.444444444444444e-06,
      "loss": 0.0313,
      "step": 6650
    },
    {
      "epoch": 1.669172932330827,
      "grad_norm": 1.2099616527557373,
      "learning_rate": 4.43609022556391e-06,
      "loss": 0.0384,
      "step": 6660
    },
    {
      "epoch": 1.6716791979949874,
      "grad_norm": 0.7847307324409485,
      "learning_rate": 4.4277360066833755e-06,
      "loss": 0.039,
      "step": 6670
    },
    {
      "epoch": 1.674185463659148,
      "grad_norm": 0.25032296776771545,
      "learning_rate": 4.41938178780284e-06,
      "loss": 0.036,
      "step": 6680
    },
    {
      "epoch": 1.6766917293233083,
      "grad_norm": 0.31715109944343567,
      "learning_rate": 4.411027568922306e-06,
      "loss": 0.0405,
      "step": 6690
    },
    {
      "epoch": 1.6791979949874687,
      "grad_norm": 0.36699408292770386,
      "learning_rate": 4.402673350041771e-06,
      "loss": 0.043,
      "step": 6700
    },
    {
      "epoch": 1.681704260651629,
      "grad_norm": 0.1925535351037979,
      "learning_rate": 4.394319131161237e-06,
      "loss": 0.0302,
      "step": 6710
    },
    {
      "epoch": 1.6842105263157894,
      "grad_norm": 0.16316968202590942,
      "learning_rate": 4.385964912280702e-06,
      "loss": 0.0412,
      "step": 6720
    },
    {
      "epoch": 1.6867167919799497,
      "grad_norm": 0.44337719678878784,
      "learning_rate": 4.377610693400167e-06,
      "loss": 0.0399,
      "step": 6730
    },
    {
      "epoch": 1.6892230576441103,
      "grad_norm": 0.4889162480831146,
      "learning_rate": 4.369256474519633e-06,
      "loss": 0.0336,
      "step": 6740
    },
    {
      "epoch": 1.6917293233082706,
      "grad_norm": 0.41122356057167053,
      "learning_rate": 4.360902255639098e-06,
      "loss": 0.0336,
      "step": 6750
    },
    {
      "epoch": 1.6917293233082706,
      "eval_loss": 0.0385599248111248,
      "eval_roc_auc_macro": 0.9860290959646326,
      "eval_runtime": 40.1905,
      "eval_samples_per_second": 794.094,
      "eval_steps_per_second": 24.832,
      "step": 6750
    },
    {
      "epoch": 1.6917293233082706,
      "step": 6750,
      "train_loss": 0.033677976578474045,
      "train_roc_auc_macro": 0.9910401252872538,
      "train_runtime": 160.3175,
      "train_samples_per_second": 796.27,
      "train_steps_per_second": 24.888
    },
    {
      "epoch": 1.6942355889724312,
      "grad_norm": 0.39795732498168945,
      "learning_rate": 4.352548036758563e-06,
      "loss": 0.0322,
      "step": 6760
    },
    {
      "epoch": 1.6967418546365916,
      "grad_norm": 0.5792114734649658,
      "learning_rate": 4.344193817878028e-06,
      "loss": 0.0364,
      "step": 6770
    },
    {
      "epoch": 1.699248120300752,
      "grad_norm": 1.0155675411224365,
      "learning_rate": 4.335839598997494e-06,
      "loss": 0.0457,
      "step": 6780
    },
    {
      "epoch": 1.7017543859649122,
      "grad_norm": 0.3896421790122986,
      "learning_rate": 4.3274853801169596e-06,
      "loss": 0.023,
      "step": 6790
    },
    {
      "epoch": 1.7042606516290726,
      "grad_norm": 0.6774685382843018,
      "learning_rate": 4.319131161236424e-06,
      "loss": 0.0335,
      "step": 6800
    },
    {
      "epoch": 1.706766917293233,
      "grad_norm": 0.4003881812095642,
      "learning_rate": 4.31077694235589e-06,
      "loss": 0.0266,
      "step": 6810
    },
    {
      "epoch": 1.7092731829573935,
      "grad_norm": 0.2672128677368164,
      "learning_rate": 4.302422723475355e-06,
      "loss": 0.0362,
      "step": 6820
    },
    {
      "epoch": 1.7117794486215538,
      "grad_norm": 0.9825907349586487,
      "learning_rate": 4.294068504594821e-06,
      "loss": 0.0325,
      "step": 6830
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.4313049614429474,
      "learning_rate": 4.2857142857142855e-06,
      "loss": 0.0305,
      "step": 6840
    },
    {
      "epoch": 1.7167919799498748,
      "grad_norm": 0.1517827808856964,
      "learning_rate": 4.277360066833751e-06,
      "loss": 0.0224,
      "step": 6850
    },
    {
      "epoch": 1.719298245614035,
      "grad_norm": 0.22557076811790466,
      "learning_rate": 4.269005847953217e-06,
      "loss": 0.0223,
      "step": 6860
    },
    {
      "epoch": 1.7218045112781954,
      "grad_norm": 0.40069228410720825,
      "learning_rate": 4.260651629072682e-06,
      "loss": 0.0345,
      "step": 6870
    },
    {
      "epoch": 1.7243107769423558,
      "grad_norm": 0.5456804633140564,
      "learning_rate": 4.252297410192147e-06,
      "loss": 0.0388,
      "step": 6880
    },
    {
      "epoch": 1.7268170426065161,
      "grad_norm": 0.6847155690193176,
      "learning_rate": 4.243943191311612e-06,
      "loss": 0.0477,
      "step": 6890
    },
    {
      "epoch": 1.7293233082706767,
      "grad_norm": 0.6736956238746643,
      "learning_rate": 4.235588972431078e-06,
      "loss": 0.0366,
      "step": 6900
    },
    {
      "epoch": 1.731829573934837,
      "grad_norm": 0.25453633069992065,
      "learning_rate": 4.227234753550543e-06,
      "loss": 0.0333,
      "step": 6910
    },
    {
      "epoch": 1.7343358395989976,
      "grad_norm": 0.7473525404930115,
      "learning_rate": 4.2188805346700084e-06,
      "loss": 0.0329,
      "step": 6920
    },
    {
      "epoch": 1.736842105263158,
      "grad_norm": 0.5353887677192688,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.0361,
      "step": 6930
    },
    {
      "epoch": 1.7393483709273183,
      "grad_norm": 0.2824464738368988,
      "learning_rate": 4.202172096908939e-06,
      "loss": 0.0356,
      "step": 6940
    },
    {
      "epoch": 1.7418546365914787,
      "grad_norm": 0.6912839412689209,
      "learning_rate": 4.193817878028405e-06,
      "loss": 0.0474,
      "step": 6950
    },
    {
      "epoch": 1.744360902255639,
      "grad_norm": 0.8895100355148315,
      "learning_rate": 4.1854636591478695e-06,
      "loss": 0.036,
      "step": 6960
    },
    {
      "epoch": 1.7468671679197993,
      "grad_norm": 0.2643527388572693,
      "learning_rate": 4.177109440267335e-06,
      "loss": 0.0336,
      "step": 6970
    },
    {
      "epoch": 1.74937343358396,
      "grad_norm": 0.44645246863365173,
      "learning_rate": 4.1687552213868e-06,
      "loss": 0.0374,
      "step": 6980
    },
    {
      "epoch": 1.7518796992481203,
      "grad_norm": 0.4498557448387146,
      "learning_rate": 4.160401002506266e-06,
      "loss": 0.0332,
      "step": 6990
    },
    {
      "epoch": 1.7543859649122808,
      "grad_norm": 0.5519342422485352,
      "learning_rate": 4.152046783625731e-06,
      "loss": 0.0332,
      "step": 7000
    },
    {
      "epoch": 1.7543859649122808,
      "eval_loss": 0.039333634078502655,
      "eval_roc_auc_macro": 0.987154482371082,
      "eval_runtime": 40.2286,
      "eval_samples_per_second": 793.341,
      "eval_steps_per_second": 24.808,
      "step": 7000
    },
    {
      "epoch": 1.7543859649122808,
      "step": 7000,
      "train_loss": 0.034433066844940186,
      "train_roc_auc_macro": 0.9911183225521388,
      "train_runtime": 160.2723,
      "train_samples_per_second": 796.495,
      "train_steps_per_second": 24.895
    },
    {
      "epoch": 1.7568922305764412,
      "grad_norm": 0.5754247307777405,
      "learning_rate": 4.143692564745196e-06,
      "loss": 0.0438,
      "step": 7010
    },
    {
      "epoch": 1.7593984962406015,
      "grad_norm": 0.7984102368354797,
      "learning_rate": 4.135338345864662e-06,
      "loss": 0.0354,
      "step": 7020
    },
    {
      "epoch": 1.7619047619047619,
      "grad_norm": 0.3438659608364105,
      "learning_rate": 4.126984126984127e-06,
      "loss": 0.0285,
      "step": 7030
    },
    {
      "epoch": 1.7644110275689222,
      "grad_norm": 0.5824138522148132,
      "learning_rate": 4.1186299081035925e-06,
      "loss": 0.0335,
      "step": 7040
    },
    {
      "epoch": 1.7669172932330826,
      "grad_norm": 0.43718498945236206,
      "learning_rate": 4.110275689223058e-06,
      "loss": 0.0309,
      "step": 7050
    },
    {
      "epoch": 1.7694235588972431,
      "grad_norm": 0.310053288936615,
      "learning_rate": 4.101921470342523e-06,
      "loss": 0.0336,
      "step": 7060
    },
    {
      "epoch": 1.7719298245614035,
      "grad_norm": 0.37151405215263367,
      "learning_rate": 4.093567251461989e-06,
      "loss": 0.029,
      "step": 7070
    },
    {
      "epoch": 1.774436090225564,
      "grad_norm": 0.5748044848442078,
      "learning_rate": 4.0852130325814535e-06,
      "loss": 0.0322,
      "step": 7080
    },
    {
      "epoch": 1.7769423558897244,
      "grad_norm": 0.3768613338470459,
      "learning_rate": 4.076858813700919e-06,
      "loss": 0.038,
      "step": 7090
    },
    {
      "epoch": 1.7794486215538847,
      "grad_norm": 0.5275532007217407,
      "learning_rate": 4.068504594820384e-06,
      "loss": 0.045,
      "step": 7100
    },
    {
      "epoch": 1.781954887218045,
      "grad_norm": 0.36466285586357117,
      "learning_rate": 4.06015037593985e-06,
      "loss": 0.038,
      "step": 7110
    },
    {
      "epoch": 1.7844611528822054,
      "grad_norm": 0.5388576984405518,
      "learning_rate": 4.0517961570593154e-06,
      "loss": 0.0439,
      "step": 7120
    },
    {
      "epoch": 1.7869674185463658,
      "grad_norm": 0.621105432510376,
      "learning_rate": 4.04344193817878e-06,
      "loss": 0.037,
      "step": 7130
    },
    {
      "epoch": 1.7894736842105263,
      "grad_norm": 0.403563916683197,
      "learning_rate": 4.035087719298246e-06,
      "loss": 0.0202,
      "step": 7140
    },
    {
      "epoch": 1.7919799498746867,
      "grad_norm": 0.6635428071022034,
      "learning_rate": 4.026733500417711e-06,
      "loss": 0.0348,
      "step": 7150
    },
    {
      "epoch": 1.7944862155388472,
      "grad_norm": 0.2956397831439972,
      "learning_rate": 4.0183792815371765e-06,
      "loss": 0.0364,
      "step": 7160
    },
    {
      "epoch": 1.7969924812030076,
      "grad_norm": 0.36858925223350525,
      "learning_rate": 4.010025062656641e-06,
      "loss": 0.0415,
      "step": 7170
    },
    {
      "epoch": 1.799498746867168,
      "grad_norm": 0.3606097996234894,
      "learning_rate": 4.001670843776107e-06,
      "loss": 0.0349,
      "step": 7180
    },
    {
      "epoch": 1.8020050125313283,
      "grad_norm": 0.4064440131187439,
      "learning_rate": 3.993316624895573e-06,
      "loss": 0.0378,
      "step": 7190
    },
    {
      "epoch": 1.8045112781954886,
      "grad_norm": 0.21226529777050018,
      "learning_rate": 3.9849624060150376e-06,
      "loss": 0.0314,
      "step": 7200
    },
    {
      "epoch": 1.807017543859649,
      "grad_norm": 0.5447867512702942,
      "learning_rate": 3.976608187134503e-06,
      "loss": 0.0402,
      "step": 7210
    },
    {
      "epoch": 1.8095238095238095,
      "grad_norm": 0.40880149602890015,
      "learning_rate": 3.968253968253968e-06,
      "loss": 0.0524,
      "step": 7220
    },
    {
      "epoch": 1.8120300751879699,
      "grad_norm": 0.8225607872009277,
      "learning_rate": 3.959899749373434e-06,
      "loss": 0.0336,
      "step": 7230
    },
    {
      "epoch": 1.8145363408521304,
      "grad_norm": 1.1445162296295166,
      "learning_rate": 3.951545530492899e-06,
      "loss": 0.0434,
      "step": 7240
    },
    {
      "epoch": 1.8170426065162908,
      "grad_norm": 0.4239141345024109,
      "learning_rate": 3.943191311612364e-06,
      "loss": 0.0332,
      "step": 7250
    },
    {
      "epoch": 1.8170426065162908,
      "eval_loss": 0.04019097983837128,
      "eval_roc_auc_macro": 0.9880445828616647,
      "eval_runtime": 39.9357,
      "eval_samples_per_second": 799.159,
      "eval_steps_per_second": 24.99,
      "step": 7250
    },
    {
      "epoch": 1.8170426065162908,
      "step": 7250,
      "train_loss": 0.035307783633470535,
      "train_roc_auc_macro": 0.9917737133151144,
      "train_runtime": 160.3826,
      "train_samples_per_second": 795.947,
      "train_steps_per_second": 24.878
    },
    {
      "epoch": 1.8195488721804511,
      "grad_norm": 0.37140199542045593,
      "learning_rate": 3.93483709273183e-06,
      "loss": 0.0479,
      "step": 7260
    },
    {
      "epoch": 1.8220551378446115,
      "grad_norm": 0.33364954590797424,
      "learning_rate": 3.926482873851295e-06,
      "loss": 0.0395,
      "step": 7270
    },
    {
      "epoch": 1.8245614035087718,
      "grad_norm": 0.46026527881622314,
      "learning_rate": 3.9181286549707605e-06,
      "loss": 0.0431,
      "step": 7280
    },
    {
      "epoch": 1.8270676691729322,
      "grad_norm": 0.7550706267356873,
      "learning_rate": 3.909774436090225e-06,
      "loss": 0.0289,
      "step": 7290
    },
    {
      "epoch": 1.8295739348370927,
      "grad_norm": 0.49704405665397644,
      "learning_rate": 3.901420217209691e-06,
      "loss": 0.0441,
      "step": 7300
    },
    {
      "epoch": 1.832080200501253,
      "grad_norm": 0.20518547296524048,
      "learning_rate": 3.893065998329157e-06,
      "loss": 0.0354,
      "step": 7310
    },
    {
      "epoch": 1.8345864661654137,
      "grad_norm": 0.1978973150253296,
      "learning_rate": 3.884711779448622e-06,
      "loss": 0.029,
      "step": 7320
    },
    {
      "epoch": 1.837092731829574,
      "grad_norm": 0.3084384500980377,
      "learning_rate": 3.876357560568087e-06,
      "loss": 0.0416,
      "step": 7330
    },
    {
      "epoch": 1.8395989974937343,
      "grad_norm": 0.09160854667425156,
      "learning_rate": 3.868003341687552e-06,
      "loss": 0.0301,
      "step": 7340
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 0.7290158271789551,
      "learning_rate": 3.859649122807018e-06,
      "loss": 0.0286,
      "step": 7350
    },
    {
      "epoch": 1.844611528822055,
      "grad_norm": 0.6984517574310303,
      "learning_rate": 3.851294903926483e-06,
      "loss": 0.0443,
      "step": 7360
    },
    {
      "epoch": 1.8471177944862154,
      "grad_norm": 1.1083577871322632,
      "learning_rate": 3.842940685045948e-06,
      "loss": 0.0356,
      "step": 7370
    },
    {
      "epoch": 1.849624060150376,
      "grad_norm": 0.18684859573841095,
      "learning_rate": 3.834586466165414e-06,
      "loss": 0.0331,
      "step": 7380
    },
    {
      "epoch": 1.8521303258145363,
      "grad_norm": 0.3677446246147156,
      "learning_rate": 3.826232247284879e-06,
      "loss": 0.033,
      "step": 7390
    },
    {
      "epoch": 1.8546365914786969,
      "grad_norm": 0.5955118536949158,
      "learning_rate": 3.8178780284043446e-06,
      "loss": 0.0415,
      "step": 7400
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.27619555592536926,
      "learning_rate": 3.80952380952381e-06,
      "loss": 0.0346,
      "step": 7410
    },
    {
      "epoch": 1.8596491228070176,
      "grad_norm": 0.33676645159721375,
      "learning_rate": 3.801169590643275e-06,
      "loss": 0.0487,
      "step": 7420
    },
    {
      "epoch": 1.862155388471178,
      "grad_norm": 0.33786049485206604,
      "learning_rate": 3.7928153717627403e-06,
      "loss": 0.0304,
      "step": 7430
    },
    {
      "epoch": 1.8646616541353382,
      "grad_norm": 0.057621072977781296,
      "learning_rate": 3.7844611528822056e-06,
      "loss": 0.0289,
      "step": 7440
    },
    {
      "epoch": 1.8671679197994986,
      "grad_norm": 0.4765535295009613,
      "learning_rate": 3.776106934001671e-06,
      "loss": 0.0487,
      "step": 7450
    },
    {
      "epoch": 1.8696741854636592,
      "grad_norm": 0.7126294374465942,
      "learning_rate": 3.767752715121136e-06,
      "loss": 0.0432,
      "step": 7460
    },
    {
      "epoch": 1.8721804511278195,
      "grad_norm": 0.7053080797195435,
      "learning_rate": 3.7593984962406014e-06,
      "loss": 0.0463,
      "step": 7470
    },
    {
      "epoch": 1.87468671679198,
      "grad_norm": 0.3389771580696106,
      "learning_rate": 3.751044277360067e-06,
      "loss": 0.0347,
      "step": 7480
    },
    {
      "epoch": 1.8771929824561404,
      "grad_norm": 0.6043955683708191,
      "learning_rate": 3.7426900584795324e-06,
      "loss": 0.0399,
      "step": 7490
    },
    {
      "epoch": 1.8796992481203008,
      "grad_norm": 0.6188459396362305,
      "learning_rate": 3.7343358395989976e-06,
      "loss": 0.0327,
      "step": 7500
    },
    {
      "epoch": 1.8796992481203008,
      "eval_loss": 0.03914690390229225,
      "eval_roc_auc_macro": 0.9877684736252029,
      "eval_runtime": 40.2314,
      "eval_samples_per_second": 793.286,
      "eval_steps_per_second": 24.806,
      "step": 7500
    },
    {
      "epoch": 1.8796992481203008,
      "step": 7500,
      "train_loss": 0.03373509272933006,
      "train_roc_auc_macro": 0.9919208701840562,
      "train_runtime": 160.011,
      "train_samples_per_second": 797.795,
      "train_steps_per_second": 24.936
    },
    {
      "epoch": 1.882205513784461,
      "grad_norm": 0.5819851160049438,
      "learning_rate": 3.725981620718463e-06,
      "loss": 0.0367,
      "step": 7510
    },
    {
      "epoch": 1.8847117794486214,
      "grad_norm": 0.2282605916261673,
      "learning_rate": 3.717627401837928e-06,
      "loss": 0.0352,
      "step": 7520
    },
    {
      "epoch": 1.8872180451127818,
      "grad_norm": 0.14462342858314514,
      "learning_rate": 3.7092731829573934e-06,
      "loss": 0.0186,
      "step": 7530
    },
    {
      "epoch": 1.8897243107769424,
      "grad_norm": 0.507776141166687,
      "learning_rate": 3.700918964076859e-06,
      "loss": 0.0394,
      "step": 7540
    },
    {
      "epoch": 1.8922305764411027,
      "grad_norm": 0.5039414763450623,
      "learning_rate": 3.6925647451963244e-06,
      "loss": 0.0245,
      "step": 7550
    },
    {
      "epoch": 1.8947368421052633,
      "grad_norm": 0.9705212116241455,
      "learning_rate": 3.6842105263157896e-06,
      "loss": 0.0293,
      "step": 7560
    },
    {
      "epoch": 1.8972431077694236,
      "grad_norm": 0.4363962709903717,
      "learning_rate": 3.675856307435255e-06,
      "loss": 0.0326,
      "step": 7570
    },
    {
      "epoch": 1.899749373433584,
      "grad_norm": 0.9740127325057983,
      "learning_rate": 3.66750208855472e-06,
      "loss": 0.0424,
      "step": 7580
    },
    {
      "epoch": 1.9022556390977443,
      "grad_norm": 0.6791045665740967,
      "learning_rate": 3.6591478696741854e-06,
      "loss": 0.0414,
      "step": 7590
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 0.5835479497909546,
      "learning_rate": 3.6507936507936507e-06,
      "loss": 0.0486,
      "step": 7600
    },
    {
      "epoch": 1.907268170426065,
      "grad_norm": 0.3101331293582916,
      "learning_rate": 3.6424394319131164e-06,
      "loss": 0.0378,
      "step": 7610
    },
    {
      "epoch": 1.9097744360902256,
      "grad_norm": 0.07869750261306763,
      "learning_rate": 3.6340852130325817e-06,
      "loss": 0.0363,
      "step": 7620
    },
    {
      "epoch": 1.912280701754386,
      "grad_norm": 0.34946611523628235,
      "learning_rate": 3.625730994152047e-06,
      "loss": 0.0304,
      "step": 7630
    },
    {
      "epoch": 1.9147869674185465,
      "grad_norm": 0.2790440618991852,
      "learning_rate": 3.617376775271512e-06,
      "loss": 0.04,
      "step": 7640
    },
    {
      "epoch": 1.9172932330827068,
      "grad_norm": 0.41934582591056824,
      "learning_rate": 3.6090225563909775e-06,
      "loss": 0.036,
      "step": 7650
    },
    {
      "epoch": 1.9197994987468672,
      "grad_norm": 0.6116755604743958,
      "learning_rate": 3.6006683375104427e-06,
      "loss": 0.0497,
      "step": 7660
    },
    {
      "epoch": 1.9223057644110275,
      "grad_norm": 0.5966601967811584,
      "learning_rate": 3.5923141186299084e-06,
      "loss": 0.0571,
      "step": 7670
    },
    {
      "epoch": 1.9248120300751879,
      "grad_norm": 0.3574742376804352,
      "learning_rate": 3.5839598997493737e-06,
      "loss": 0.0436,
      "step": 7680
    },
    {
      "epoch": 1.9273182957393482,
      "grad_norm": 0.3035542368888855,
      "learning_rate": 3.575605680868839e-06,
      "loss": 0.0431,
      "step": 7690
    },
    {
      "epoch": 1.9298245614035088,
      "grad_norm": 0.43786248564720154,
      "learning_rate": 3.567251461988304e-06,
      "loss": 0.0258,
      "step": 7700
    },
    {
      "epoch": 1.9323308270676691,
      "grad_norm": 0.5606793165206909,
      "learning_rate": 3.5588972431077695e-06,
      "loss": 0.0411,
      "step": 7710
    },
    {
      "epoch": 1.9348370927318297,
      "grad_norm": 0.9703726768493652,
      "learning_rate": 3.5505430242272347e-06,
      "loss": 0.0373,
      "step": 7720
    },
    {
      "epoch": 1.93734335839599,
      "grad_norm": 0.29692161083221436,
      "learning_rate": 3.5421888053467e-06,
      "loss": 0.037,
      "step": 7730
    },
    {
      "epoch": 1.9398496240601504,
      "grad_norm": 0.7929244041442871,
      "learning_rate": 3.5338345864661657e-06,
      "loss": 0.0356,
      "step": 7740
    },
    {
      "epoch": 1.9423558897243107,
      "grad_norm": 0.5058033466339111,
      "learning_rate": 3.525480367585631e-06,
      "loss": 0.0394,
      "step": 7750
    },
    {
      "epoch": 1.9423558897243107,
      "eval_loss": 0.04181496053934097,
      "eval_roc_auc_macro": 0.9880679963839937,
      "eval_runtime": 40.2081,
      "eval_samples_per_second": 793.745,
      "eval_steps_per_second": 24.821,
      "step": 7750
    },
    {
      "epoch": 1.9423558897243107,
      "step": 7750,
      "train_loss": 0.037195198237895966,
      "train_roc_auc_macro": 0.9919198028223649,
      "train_runtime": 160.1327,
      "train_samples_per_second": 797.189,
      "train_steps_per_second": 24.917
    },
    {
      "epoch": 1.944862155388471,
      "grad_norm": 0.8302964568138123,
      "learning_rate": 3.5171261487050962e-06,
      "loss": 0.0369,
      "step": 7760
    },
    {
      "epoch": 1.9473684210526314,
      "grad_norm": 0.25175222754478455,
      "learning_rate": 3.5087719298245615e-06,
      "loss": 0.046,
      "step": 7770
    },
    {
      "epoch": 1.949874686716792,
      "grad_norm": 0.5508130192756653,
      "learning_rate": 3.5004177109440267e-06,
      "loss": 0.043,
      "step": 7780
    },
    {
      "epoch": 1.9523809523809523,
      "grad_norm": 0.2407107949256897,
      "learning_rate": 3.492063492063492e-06,
      "loss": 0.0317,
      "step": 7790
    },
    {
      "epoch": 1.954887218045113,
      "grad_norm": 0.31682440638542175,
      "learning_rate": 3.4837092731829573e-06,
      "loss": 0.0372,
      "step": 7800
    },
    {
      "epoch": 1.9573934837092732,
      "grad_norm": 0.2816420793533325,
      "learning_rate": 3.475355054302423e-06,
      "loss": 0.0358,
      "step": 7810
    },
    {
      "epoch": 1.9598997493734336,
      "grad_norm": 0.6042706966400146,
      "learning_rate": 3.4670008354218882e-06,
      "loss": 0.043,
      "step": 7820
    },
    {
      "epoch": 1.962406015037594,
      "grad_norm": 0.42703282833099365,
      "learning_rate": 3.4586466165413535e-06,
      "loss": 0.0316,
      "step": 7830
    },
    {
      "epoch": 1.9649122807017543,
      "grad_norm": 0.2475942075252533,
      "learning_rate": 3.4502923976608188e-06,
      "loss": 0.0419,
      "step": 7840
    },
    {
      "epoch": 1.9674185463659146,
      "grad_norm": 0.3078071177005768,
      "learning_rate": 3.441938178780284e-06,
      "loss": 0.0316,
      "step": 7850
    },
    {
      "epoch": 1.9699248120300752,
      "grad_norm": 0.124386727809906,
      "learning_rate": 3.4335839598997493e-06,
      "loss": 0.0255,
      "step": 7860
    },
    {
      "epoch": 1.9724310776942355,
      "grad_norm": 0.41704440116882324,
      "learning_rate": 3.425229741019215e-06,
      "loss": 0.02,
      "step": 7870
    },
    {
      "epoch": 1.974937343358396,
      "grad_norm": 0.6131624579429626,
      "learning_rate": 3.4168755221386802e-06,
      "loss": 0.03,
      "step": 7880
    },
    {
      "epoch": 1.9774436090225564,
      "grad_norm": 0.41482093930244446,
      "learning_rate": 3.4085213032581455e-06,
      "loss": 0.019,
      "step": 7890
    },
    {
      "epoch": 1.9799498746867168,
      "grad_norm": 0.8273254036903381,
      "learning_rate": 3.4001670843776108e-06,
      "loss": 0.0417,
      "step": 7900
    },
    {
      "epoch": 1.9824561403508771,
      "grad_norm": 0.35632508993148804,
      "learning_rate": 3.391812865497076e-06,
      "loss": 0.0309,
      "step": 7910
    },
    {
      "epoch": 1.9849624060150375,
      "grad_norm": 1.475885033607483,
      "learning_rate": 3.3834586466165413e-06,
      "loss": 0.0355,
      "step": 7920
    },
    {
      "epoch": 1.9874686716791978,
      "grad_norm": 0.3678402006626129,
      "learning_rate": 3.3751044277360066e-06,
      "loss": 0.0353,
      "step": 7930
    },
    {
      "epoch": 1.9899749373433584,
      "grad_norm": 0.9259978532791138,
      "learning_rate": 3.3667502088554723e-06,
      "loss": 0.0411,
      "step": 7940
    },
    {
      "epoch": 1.9924812030075187,
      "grad_norm": 0.31765300035476685,
      "learning_rate": 3.3583959899749375e-06,
      "loss": 0.0331,
      "step": 7950
    },
    {
      "epoch": 1.9949874686716793,
      "grad_norm": 0.22731582820415497,
      "learning_rate": 3.350041771094403e-06,
      "loss": 0.0261,
      "step": 7960
    },
    {
      "epoch": 1.9974937343358397,
      "grad_norm": 0.2852756381034851,
      "learning_rate": 3.341687552213868e-06,
      "loss": 0.0342,
      "step": 7970
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.798645555973053,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.035,
      "step": 7980
    },
    {
      "epoch": 2.0025062656641603,
      "grad_norm": 0.33416324853897095,
      "learning_rate": 3.3249791144527986e-06,
      "loss": 0.0348,
      "step": 7990
    },
    {
      "epoch": 2.0050125313283207,
      "grad_norm": 0.41155171394348145,
      "learning_rate": 3.3166248955722643e-06,
      "loss": 0.0457,
      "step": 8000
    },
    {
      "epoch": 2.0050125313283207,
      "eval_loss": 0.03864157572388649,
      "eval_roc_auc_macro": 0.9879865243027983,
      "eval_runtime": 40.2007,
      "eval_samples_per_second": 793.891,
      "eval_steps_per_second": 24.825,
      "step": 8000
    },
    {
      "epoch": 2.0050125313283207,
      "step": 8000,
      "train_loss": 0.0331236831843853,
      "train_roc_auc_macro": 0.991856446854832,
      "train_runtime": 160.3449,
      "train_samples_per_second": 796.134,
      "train_steps_per_second": 24.884
    },
    {
      "epoch": 2.007518796992481,
      "grad_norm": 0.07343663275241852,
      "learning_rate": 3.3082706766917295e-06,
      "loss": 0.0263,
      "step": 8010
    },
    {
      "epoch": 2.0100250626566414,
      "grad_norm": 0.2945287823677063,
      "learning_rate": 3.299916457811195e-06,
      "loss": 0.0362,
      "step": 8020
    },
    {
      "epoch": 2.012531328320802,
      "grad_norm": 0.589309573173523,
      "learning_rate": 3.29156223893066e-06,
      "loss": 0.0336,
      "step": 8030
    },
    {
      "epoch": 2.0150375939849625,
      "grad_norm": 0.6265830397605896,
      "learning_rate": 3.2832080200501253e-06,
      "loss": 0.0335,
      "step": 8040
    },
    {
      "epoch": 2.017543859649123,
      "grad_norm": 0.6202108860015869,
      "learning_rate": 3.2748538011695906e-06,
      "loss": 0.0349,
      "step": 8050
    },
    {
      "epoch": 2.020050125313283,
      "grad_norm": 0.41021397709846497,
      "learning_rate": 3.266499582289056e-06,
      "loss": 0.0367,
      "step": 8060
    },
    {
      "epoch": 2.0225563909774436,
      "grad_norm": 0.20042431354522705,
      "learning_rate": 3.2581453634085216e-06,
      "loss": 0.0237,
      "step": 8070
    },
    {
      "epoch": 2.025062656641604,
      "grad_norm": 0.33471208810806274,
      "learning_rate": 3.249791144527987e-06,
      "loss": 0.027,
      "step": 8080
    },
    {
      "epoch": 2.0275689223057642,
      "grad_norm": 0.5925634503364563,
      "learning_rate": 3.241436925647452e-06,
      "loss": 0.0479,
      "step": 8090
    },
    {
      "epoch": 2.030075187969925,
      "grad_norm": 0.5944806933403015,
      "learning_rate": 3.2330827067669174e-06,
      "loss": 0.0352,
      "step": 8100
    },
    {
      "epoch": 2.0325814536340854,
      "grad_norm": 0.25145620107650757,
      "learning_rate": 3.2247284878863826e-06,
      "loss": 0.021,
      "step": 8110
    },
    {
      "epoch": 2.0350877192982457,
      "grad_norm": 0.4276849627494812,
      "learning_rate": 3.216374269005848e-06,
      "loss": 0.0259,
      "step": 8120
    },
    {
      "epoch": 2.037593984962406,
      "grad_norm": 0.4147335886955261,
      "learning_rate": 3.2080200501253136e-06,
      "loss": 0.0374,
      "step": 8130
    },
    {
      "epoch": 2.0401002506265664,
      "grad_norm": 0.2553918659687042,
      "learning_rate": 3.199665831244779e-06,
      "loss": 0.0243,
      "step": 8140
    },
    {
      "epoch": 2.0426065162907268,
      "grad_norm": 0.0886923298239708,
      "learning_rate": 3.191311612364244e-06,
      "loss": 0.0324,
      "step": 8150
    },
    {
      "epoch": 2.045112781954887,
      "grad_norm": 0.1432231366634369,
      "learning_rate": 3.1829573934837094e-06,
      "loss": 0.0307,
      "step": 8160
    },
    {
      "epoch": 2.0476190476190474,
      "grad_norm": 0.5106646418571472,
      "learning_rate": 3.1746031746031746e-06,
      "loss": 0.0396,
      "step": 8170
    },
    {
      "epoch": 2.050125313283208,
      "grad_norm": 0.6346425414085388,
      "learning_rate": 3.16624895572264e-06,
      "loss": 0.0342,
      "step": 8180
    },
    {
      "epoch": 2.0526315789473686,
      "grad_norm": 0.4760935604572296,
      "learning_rate": 3.157894736842105e-06,
      "loss": 0.0232,
      "step": 8190
    },
    {
      "epoch": 2.055137844611529,
      "grad_norm": 0.7325589060783386,
      "learning_rate": 3.149540517961571e-06,
      "loss": 0.0407,
      "step": 8200
    },
    {
      "epoch": 2.0576441102756893,
      "grad_norm": 0.3478146493434906,
      "learning_rate": 3.141186299081036e-06,
      "loss": 0.0266,
      "step": 8210
    },
    {
      "epoch": 2.0601503759398496,
      "grad_norm": 0.4769018590450287,
      "learning_rate": 3.1328320802005014e-06,
      "loss": 0.0308,
      "step": 8220
    },
    {
      "epoch": 2.06265664160401,
      "grad_norm": 0.2678593099117279,
      "learning_rate": 3.1244778613199666e-06,
      "loss": 0.0403,
      "step": 8230
    },
    {
      "epoch": 2.0651629072681703,
      "grad_norm": 0.41777288913726807,
      "learning_rate": 3.116123642439432e-06,
      "loss": 0.0346,
      "step": 8240
    },
    {
      "epoch": 2.0676691729323307,
      "grad_norm": 0.16031953692436218,
      "learning_rate": 3.107769423558897e-06,
      "loss": 0.0378,
      "step": 8250
    },
    {
      "epoch": 2.0676691729323307,
      "eval_loss": 0.03895419463515282,
      "eval_roc_auc_macro": 0.9876395574499148,
      "eval_runtime": 40.2619,
      "eval_samples_per_second": 792.684,
      "eval_steps_per_second": 24.788,
      "step": 8250
    },
    {
      "epoch": 2.0676691729323307,
      "step": 8250,
      "train_loss": 0.03304128721356392,
      "train_roc_auc_macro": 0.9919541973584924,
      "train_runtime": 160.4218,
      "train_samples_per_second": 795.752,
      "train_steps_per_second": 24.872
    },
    {
      "epoch": 2.0701754385964914,
      "grad_norm": 0.435983806848526,
      "learning_rate": 3.0994152046783624e-06,
      "loss": 0.0272,
      "step": 8260
    },
    {
      "epoch": 2.072681704260652,
      "grad_norm": 0.7471334934234619,
      "learning_rate": 3.091060985797828e-06,
      "loss": 0.0423,
      "step": 8270
    },
    {
      "epoch": 2.075187969924812,
      "grad_norm": 0.5572287440299988,
      "learning_rate": 3.0827067669172934e-06,
      "loss": 0.0442,
      "step": 8280
    },
    {
      "epoch": 2.0776942355889725,
      "grad_norm": 0.608857274055481,
      "learning_rate": 3.0743525480367587e-06,
      "loss": 0.0295,
      "step": 8290
    },
    {
      "epoch": 2.080200501253133,
      "grad_norm": 0.09266266971826553,
      "learning_rate": 3.065998329156224e-06,
      "loss": 0.0309,
      "step": 8300
    },
    {
      "epoch": 2.082706766917293,
      "grad_norm": 0.7989411950111389,
      "learning_rate": 3.057644110275689e-06,
      "loss": 0.0268,
      "step": 8310
    },
    {
      "epoch": 2.0852130325814535,
      "grad_norm": 0.37868186831474304,
      "learning_rate": 3.0492898913951545e-06,
      "loss": 0.0243,
      "step": 8320
    },
    {
      "epoch": 2.087719298245614,
      "grad_norm": 0.2393697053194046,
      "learning_rate": 3.04093567251462e-06,
      "loss": 0.0311,
      "step": 8330
    },
    {
      "epoch": 2.090225563909774,
      "grad_norm": 0.6900424957275391,
      "learning_rate": 3.0325814536340854e-06,
      "loss": 0.0302,
      "step": 8340
    },
    {
      "epoch": 2.092731829573935,
      "grad_norm": 1.0599830150604248,
      "learning_rate": 3.0242272347535507e-06,
      "loss": 0.0246,
      "step": 8350
    },
    {
      "epoch": 2.0952380952380953,
      "grad_norm": 0.502278208732605,
      "learning_rate": 3.015873015873016e-06,
      "loss": 0.0258,
      "step": 8360
    },
    {
      "epoch": 2.0977443609022557,
      "grad_norm": 0.4887383282184601,
      "learning_rate": 3.007518796992481e-06,
      "loss": 0.0409,
      "step": 8370
    },
    {
      "epoch": 2.100250626566416,
      "grad_norm": 0.6154584288597107,
      "learning_rate": 2.9991645781119465e-06,
      "loss": 0.0277,
      "step": 8380
    },
    {
      "epoch": 2.1027568922305764,
      "grad_norm": 0.664921224117279,
      "learning_rate": 2.9908103592314117e-06,
      "loss": 0.0243,
      "step": 8390
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 0.7872081995010376,
      "learning_rate": 2.9824561403508774e-06,
      "loss": 0.0327,
      "step": 8400
    },
    {
      "epoch": 2.107769423558897,
      "grad_norm": 0.474018394947052,
      "learning_rate": 2.9741019214703427e-06,
      "loss": 0.0411,
      "step": 8410
    },
    {
      "epoch": 2.110275689223058,
      "grad_norm": 0.6525957584381104,
      "learning_rate": 2.965747702589808e-06,
      "loss": 0.0348,
      "step": 8420
    },
    {
      "epoch": 2.112781954887218,
      "grad_norm": 0.20475979149341583,
      "learning_rate": 2.9573934837092732e-06,
      "loss": 0.0311,
      "step": 8430
    },
    {
      "epoch": 2.1152882205513786,
      "grad_norm": 0.5813153386116028,
      "learning_rate": 2.9490392648287385e-06,
      "loss": 0.0335,
      "step": 8440
    },
    {
      "epoch": 2.117794486215539,
      "grad_norm": 0.556253969669342,
      "learning_rate": 2.9406850459482038e-06,
      "loss": 0.0449,
      "step": 8450
    },
    {
      "epoch": 2.1203007518796992,
      "grad_norm": 0.2717169225215912,
      "learning_rate": 2.9323308270676694e-06,
      "loss": 0.0361,
      "step": 8460
    },
    {
      "epoch": 2.1228070175438596,
      "grad_norm": 0.753215491771698,
      "learning_rate": 2.9239766081871347e-06,
      "loss": 0.0582,
      "step": 8470
    },
    {
      "epoch": 2.12531328320802,
      "grad_norm": 0.35090792179107666,
      "learning_rate": 2.9156223893066e-06,
      "loss": 0.0242,
      "step": 8480
    },
    {
      "epoch": 2.1278195488721803,
      "grad_norm": 0.3704504072666168,
      "learning_rate": 2.9072681704260652e-06,
      "loss": 0.0337,
      "step": 8490
    },
    {
      "epoch": 2.1303258145363406,
      "grad_norm": 0.24869702756404877,
      "learning_rate": 2.8989139515455305e-06,
      "loss": 0.0276,
      "step": 8500
    },
    {
      "epoch": 2.1303258145363406,
      "eval_loss": 0.03896990790963173,
      "eval_roc_auc_macro": 0.988334434064107,
      "eval_runtime": 40.248,
      "eval_samples_per_second": 792.958,
      "eval_steps_per_second": 24.796,
      "step": 8500
    },
    {
      "epoch": 2.1303258145363406,
      "step": 8500,
      "train_loss": 0.033290814608335495,
      "train_roc_auc_macro": 0.9922105263172072,
      "train_runtime": 160.3161,
      "train_samples_per_second": 796.277,
      "train_steps_per_second": 24.888
    }
  ],
  "logging_steps": 10,
  "max_steps": 11970,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 250,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 4,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.5778715380301824e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
